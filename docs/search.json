[
  {
    "objectID": "index.html#our-objective",
    "href": "index.html#our-objective",
    "title": "GAP Production Data Documentation",
    "section": "Our Objective",
    "text": "Our Objective\nAs part of our commitment to open science and transparency, we provide this interactive metadata guide to compliment our public-domain data. Please refer to our Draft Data Changes Brief. Once finalized, this language will be included here.\n\n\n\nSorting and weighing fish on deck on the 2022 Bering Sea groundfish survey aboard the F/V Alaska Knight. Credit: Emily Markowitz/NOAA Fisheries."
  },
  {
    "objectID": "index.html#user-resources",
    "href": "index.html#user-resources",
    "title": "GAP Production Data Documentation",
    "section": "User Resources",
    "text": "User Resources\n\nGroundfish Assessment Program Bottom Trawl Surveys\nAFSC’s Resource Assessment and Conservation Engineering Division\nSurvey code books\nPublications and Data Reports\nResearch Surveys conducted at AFSC"
  },
  {
    "objectID": "index.html#background-of-the-gap_products-repo",
    "href": "index.html#background-of-the-gap_products-repo",
    "title": "GAP Production Data Documentation",
    "section": "Background of the gap_products repo",
    "text": "Background of the gap_products repo\nThis work is the result of the massive efforts of three concurrent GAP working groups:\n\nIndex Computation Working Group: consolidation of the methods used to produced design-based estimates of abundance and size/age composition between the Bering Sea and AI/GOA survey regions.\nData Processes Working Group: reorganization of the Oracle data infrastructure that houses the standard data products produced by GAP.\nGulf of Alaska Survey Restratification Working Group: implementation of a new stratified random survey design in the Gulf of Alaska bottom trawl survey.\n\nWe began this effort in collaboration with the Status of Stocks team (SSMA) to present both the orientation and opportunity to interact with Gulf of Alaska data from the restratified survey design that we will be implementing in the 2025 field season. As that part of the project evolved, the Data Processes Working Group identified the opportunity and need for gaining efficiencies by redesigning and consolidating the Oracle objects (tables and materialized views) that have historically served these data. The Index Computation Working Group also identified an opportunity to gain efficiencies by consolidating the various scripts that were developed independently by both survey region groups into a workflow that was more accessible and documented.\nThe Index Computation Working Group developed the gapindex R package, a code repository that consolidates the code that calculates the various standard GAP products (e.g., CPUE, total biomass, size/age composition) for both the Bering Sea and AIGOA survey regions. The Data Processes Working Group was responsible for compiling the data structures needed to support data product tables that were consistent across all of the AFSC GAP survey regions as well as the creation of the GAP_PRODUCTS oracle schema that will house these consolidated products in the future.\nThis gap_products GitHub repository houses the code that will conduct the “standard production run” that produces the new data tables via the gapindex R package and upload those tables to the GAP_PRODUCTS Oracle schema."
  },
  {
    "objectID": "index.html#major-advantages",
    "href": "index.html#major-advantages",
    "title": "GAP Production Data Documentation",
    "section": "Major Advantages",
    "text": "Major Advantages\n\nConsolidated production tables include all standard data products for all surveys. Data will be provided in the same format, with the same units, and created using the same mathematical methodology. This should limit data pulls, reduce complexity for data access, and reduce complicated secondary data wrangling.\nConsistent naming conventions for schemata, tables, and column metadata. Columns across all tables will use the same naming conventions, units, and data types. Restricting standard data product table content to absolutely necessary columns.\nRemoval of redundant data columns that can be acquired by joining to reference tables is key for providing consistent and up-to-date data while limiting data table sizes.\nConsolidation and repurposing of Oracle schemata. This will help the GAP team limit unnecessary access to unprocessed or problematic data by outside users.\nVetted data methods. All code and data inclusion decisions and wrangling are documented in the {gapindex} R package. Streamlined and rapid data production. Improved and consolidated data creation and documentation provide data creators and users with greater confidence in the data products and enhanced ability to share the data."
  },
  {
    "objectID": "content/intro-survey-background.html#what-is-the-research-objective",
    "href": "content/intro-survey-background.html#what-is-the-research-objective",
    "title": "Survey background",
    "section": "What is the research objective?",
    "text": "What is the research objective?\nThe objectives of these surveys are to:\n\nmonitor trends in the marine ecosystem of the Bering Sea, Aleutian Islands, and Gulf of Alaska\nproduce fishery-independent biomass and abundance estimates for commercially important fish and crab species\ncollect biological and environmental data for use in ecosystem-based fishery management.\n\nLearn more about the program"
  },
  {
    "objectID": "content/intro-survey-background.html#who-is-conducting-the-research",
    "href": "content/intro-survey-background.html#who-is-conducting-the-research",
    "title": "Survey background",
    "section": "Who is conducting the research?",
    "text": "Who is conducting the research?\nScientists from the Alaska Fisheries Science Center conduct these bottom trawl surveys with participation from the Alaska Department of Fish & Game (ADF&G), the International Pacific Halibut Commission (IPHC), and universities. This research is conducted on chartered fishing vessels."
  },
  {
    "objectID": "content/intro-survey-background.html#bottom-trawl-surveys-and-regions",
    "href": "content/intro-survey-background.html#bottom-trawl-surveys-and-regions",
    "title": "Survey background",
    "section": "Bottom trawl surveys and regions",
    "text": "Bottom trawl surveys and regions\n\nEach survey conducted by the Groundfish Assessment Program are multispecies bottom trawl surveys. We collect environmental and biological data to assess how climate variability and loss of sea ice are affecting bottom-dwelling marine life on the Bering Sea shelf. We monitor trends in the distribution (location and movement patterns) and abundance of groundfish and crab species as well as oceanographic data (e.g., water temperature, depth). We collect biological information such as organism weight, length, stomachs to learn about diets, and otoliths to determine fish ages. We use this information in annual stock assessments and to assess the state of the ecosystem. This research is conducted on fishing industry contract vessels.\n\n\n\nSurvey summary statsSurveySurvey Definition IDYearsDepth (m)Area (km2)# Statistical Areas# Possible StationsAleutian Islands Bottom Trawl Survey522022 - 1980 (16)1 - 50064,415.0801,312Eastern Bering Sea Slope Bottom Trawl Survey782016 - 2002 (6)201 - 80021,134.24Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey982023 - 1982 (41)1 - 200492,989.929515Gulf of Alaska Bottom Trawl Survey472023 - 1984 (18)1 - 1,000314,087.4396,939Northern Bering Sea Crab/Groundfish Survey - Eastern Bering Sea Shelf Survey Extension1432023 - 2010 (6)1 - 100198,866.84144\n\n\n\nAleutian Islands\n(Von Szalay and Raring, 2020)\n\nUpper Continental Slope of the Aleutian Islands from Unimak Pass to Stalemate Bank\nTriennial (1990s)/Biennial since 2000 in even years, since 1992\nModified Index-Stratified Random of Successful Stations Survey Design\nImportant commercial fish species include Atka mackerel, Pacific ocean perch, walleye pollock, Pacific cod, sablefish, and other rockfish species.\n\n\n\nGulf of Alaska\n(Von Szalay and Raring, 2018)\n\nContinental Shelf and Upper Slope of the Gulf of Alaska extending from the Islands of Four Mountains 2,300 km east to Dixon Entrance\nTriennial (1990s)/Biennial since 2001 in odd years, since 1991\nStratified Random Survey Design\nImportant commercial species in the Gulf of Alaska include Pacific ocean perch, walleye pollock, Pacific cod, flatfish, and other rockfish species.\n\n\n\nEastern Bering Sea Shelf\n(Markowitz et al., 2023)\n\nThe continental shelf of the eastern Bering Sea from the Aleutian Islands to the Bering Strait\nConducted annually since 1982.\nUses a stratified systematic sampling survey design with fixed stations at center of 20 x 20 nm grid.\nSimilar in design to the northern Bering Sea shelf bottom trawl survey.\nFocus species for the Bering Sea include walleye pollock, Pacific cod, Greenland turbot, yellowfin sole, northern rock sole, red king crab, and snow and Tanner crabs.\n\n\n\n\n\n\nStrata used in the Eastern Bering Sea Survey.\n\n\n\n\n\n\nNorthern Bering Sea\n(Markowitz et al., 2023)\n\nThe continental shelf of the northern Bering Sea, including the area north of St. Lawrence Island and Norton Sound\nBiennial/Annual; conducted intermittently since 2010\nUses a stratified systematic sampling survey design with fixed stations at center of 20 x 20 nm grid.\nSimilar in design to the eastern Bering Sea shelf bottom trawl survey.\n\n\n\nEastern Bering Sea Upper Continental Slope\n(Hoff, 2016)\n\nThe eastern Bering Sea upper continental slope survey area extends from Unalaska and Akutan Islands to the U.S.-Russian Maritime Boundary at 61° N near the International Date Line (166° E to 180° W) at depths from 200 to 1,200 m\nConducted intermittently since 2002 (funding dependent)\nModified Index-Stratified Random of Successful Stations Survey Design\nFocus species for the Bering Sea slope include giant grenadier, Pacific ocean perch, popeye grenadier, walleye pollock, and arrowtooth flounder.\n\n\n\n\n\n\nStrata used in the Bering Sea Slope Survey.\n\n\n\n\n\n\n\n\nHoff, G. R. (2016). Results of the 2016 eastern Bering Sea upper continental slope survey of groundfishes and invertebrate resources (NOAA Tech. Memo. NOAA-AFSC-339). U.S. Dep. Commer. https://doi.org/10.7289/V5/TM-AFSC-339\n\n\nMarkowitz, E. H., Dawson, E. J., Anderson, A. B., Rohan, S. K., Charriere, N. E., Prohaska, B. K., and Stevenson, D. E. (2023). Results of the 2022 eastern and northern Bering Sea continental shelf bottom trawl survey of groundfish and invertebrate fauna (NOAA Tech. Memo. NMFS-AFSC-469; p. 213). U.S. Dep. Commer.\n\n\nVon Szalay, P. G., and Raring, N. W. (2018). Data report: 2017 Gulf of Alaska bottom trawl survey (NOAA Tech. Memo. NMFS-AFSC-374). U.S. Dep. Commer. https://doi.org/10.7289/V5/TM-AFSC-374\n\n\nVon Szalay, P. G., and Raring, N. W. (2020). Data report: 2018 Aleutian Islands bottom trawl survey (NOAA Tech. Memo. NMFS-AFSC-409). U.S. Dep. Commer. https://doi.org/10.25923/qe5v-fz70"
  },
  {
    "objectID": "content/intro-workflow.html#data-workflow-from-boat-to-production",
    "href": "content/intro-workflow.html#data-workflow-from-boat-to-production",
    "title": "Workflow",
    "section": "Data workflow from boat to production",
    "text": "Data workflow from boat to production\n\n\n\n\n\n\nflowchart LR\n  A[Catch data\\ncollection tablet] --&gt; B[METIS]\n  A1[Length data\\ncollection tablets] --&gt; B\n  A2[Specimen data\\ncollection tablet] --&gt; B\n  A3[Wheelhouse\\nhaul data] --&gt; C[GIDES and Oracle]\n  B --&gt; C\n  C --&gt; D[RACEBASE and RACE_DATA\\nOracle schema]\n  D --&gt; E[gapindex\\nR package]\n  D --&gt; F[gap_products\\nR scripts]\n  E --&gt; F\n  F --&gt; G[Prodcution tables\\nin GAP_PRODUCTS\\nOracle schema]\n  E --&gt; G\n  G --&gt; H[Data process\\nreports &\\npresentations]\n  G --&gt; I[AKFN]\n  G --&gt; J[FOSS]\n  \n\n\nFigure 2.1: Simplified data workflow from boat to production."
  },
  {
    "objectID": "content/intro-workflow.html#organization",
    "href": "content/intro-workflow.html#organization",
    "title": "Workflow",
    "section": "Organization",
    "text": "Organization\nThe code/run.R script houses the sequence of programs that calculate the standard data products resulting from the NOAA AFSC GAP bottom trawl surveys. Standard data products are the CPUE, BIOMASS, SIZECOMP, and AGECOMP tables in the GAP_PRODUCTS Oracle schema. The tables are slated to be updated twice a year, once after the survey season following finalization of that summer’s bottom trawl survey data to incorporate the new catch, size, and effort data and once prior to an upcoming survey to incorporate new age data that were processed after the prior summer’s survey season ended. This second pre-survey production run will also incorporate changes in the data due to the specimen voucher process as well as other post-hoc changes in the survey data.\nBelow is a summary of the workflow:\n\nImport versions of the tables in GAP_PRODUCTS locally within the gap_products repository to compare with the updated production tables. Any changes to a production table will be compared and checked to make sure those changes are intentional and documented.\nUse the gapindex R package to calculate the four major standard data products: CPUE, BIOMASS, SIZECOMP, AGECOMP. These tables are compared and checked to their respective locally saved copies and any changes to the tables are vetted and documented. These tables are then uploaded to the GAP_PRODUCTS Oracle schema.\nCalculate the various materialized views for AKFIN and FOSS purposes. Since these are derivative of the tables in GAP_PRODUCTS as well as other base tables in RACEBASE and RACE_DATA, it is not necessary to check these views in addition to the data checks done in the previous steps."
  },
  {
    "objectID": "content/intro-workflow.html#data-levels",
    "href": "content/intro-workflow.html#data-levels",
    "title": "Workflow",
    "section": "Data levels",
    "text": "Data levels\nGAP produces numerous data products that are subjected to different levels of processing, ranging from raw to highly-derived. The suitability of these data products for analysis varies and there is ambiguity about which data products can be used for which purpose. This ambiguity can create challenges in communicating about data products and potentially lead to misunderstanding and misuse of data. One approach to communicating about the level of processing applied to data products and their suitability for analysis is to describe data products using a Data Processing Level system. Data Processing Level systems are widely used in earth system sciences to characterize the extent of processing that has been applied to data products. For example, the NOAA National Centers for Environmental Information (NCEI) Satellite Program uses a Data Processing Level system to describe data on a scale of 0-4, where Level 0 is raw data and Level 4 is model output or results from analysis. Example of how NASA remote sensing data products are shared through a public data portal with levels of data processing and documentation.\nFor more information, see Sean Rohan’s October 2022 SCRUGS presentation on the topic.\n\nLevel 0: Raw and unprocessed data. Ex: Data on the G drive, some tables in RACE_DATA\nLevel 1A: Data products with QA/QC applied that may or may not be expanded to analysis units, but either not georeferenced or does not include full metadata. Ex: Some tables in RACE_DATA and RACEBASE\nLevel 2: Analysis-ready data products that are derived for a standardized extent and account for zeros and missing/bad data. Ex: CPUE tables, some data products in public-facing archives and repositories\nLevel 3: Data products that are synthesized across a standardized extent, often inputs in a higher-level analytical product. Ex: Abundance indices, some data products in public-facing archives and repositories\nLevel 4: Analytically generated data products that are derived from lower-level data, often to inform management. Ex: Biological reference points from stock assessments, Essential Fish Habitat layers, indicators in Ecosystem Status Reports and Ecosystem and Socioeconomic Profiles"
  },
  {
    "objectID": "content/intro-news.html#future-plans",
    "href": "content/intro-news.html#future-plans",
    "title": "News",
    "section": "Future plans",
    "text": "Future plans\n\nGOA 2025 Restratification – Mock Data for Testing\nThe plan will be, once all are satisfied with the new GAP_PRODUCTS schema and tables, to sunset the historic product tables in 2024 and proceed with only GAP_PRODUCTS for the 2024 post-survey stock assessment season.\n\nDecember 2023 - March 2024: Meeting between GAP and stock assessment groups in early December 2023 to update progress on the GAP_PRODUCTS testing phase. Deadline for Comments and Feedback on GAP_PRODUCTS data structures is March 8, 2024.\nSeptember 2024: GAP will only release data products according to the new standard. Current, historical data product tables will be archived in a new schema called \"GAP_ARCHIVE\"."
  },
  {
    "objectID": "content/intro-news.html#previous-updates",
    "href": "content/intro-news.html#previous-updates",
    "title": "News",
    "section": "Previous updates",
    "text": "Previous updates\n\nSeptember 2023: Provisional data product tables – CPUE, BIOMASS, SIZECOMP, and AGECOMP – as well as provisional support tables – AREA, STRATUM_GROUPS, METADATA_COLUMN, SPECIES_YEAR, SURVEY_DESIGN – are available in the GAP_PRODUCTS Oracle schema with updated 2023 GOA and EBS survey data.\n\nAdditionally, the inclusion of mock data for the under the new 2025 GOA stratified random survey (labeled in the GAP_PRODUCTS tables as YEAR 2025) will provide stock authors with the opportunity to interact with data from the new survey design to be implemented in 2025.\nProvisional AKFIN and FOSS tables are also available in the GAP_PRODUCTS Oracle schema. These include: AKFIN_AGECOMP, AKFIN_AREA, AKFIN_BIOMASS, AKFIN_CATCH, AKFIN_CPUE, AKFIN_CRUISE, AKFIN_HAUL, AKFIN_LENGTH, AKFIN_METADATA_COLUMN, AKFIN_SIZECOMP, AKFIN_SPECIMEN, AKFIN_SURVEY_DESIGN, AKFIN_STRATUM_GROUPS, FOSS_CATCH, FOSS_CPUE_PRESONLY, FOSS_HAUL, and FOSS_TAXON_GROUP.\n\nMay 2023: Release of new, draft, standard data product tables, including restratified GOA data. Stock assessment authors will have the opportunity to explore differences between datasets, test workflows, and provide comments and issues during summer 2023.\nFebruary 2023: Decision was made to include the mock restratified GOA data with the development of the new consolidated standard data products.\nDecember 2022: GAP and SSMA discuss integration of the restratification of the GOA survey design into standard data products.\n\nStock assessors requested a \"dry run\" test to work with new mock restratified GOA survey data before implementation of the new survey design.\nThis prompted the postponement of the restratified GOA design to 2025.\n\nOctober 2022: The data processes and index computation working group convened to address the development of standard survey data products (e.g., biomass/abundance, size composition, age composition, CPUE).\n\nIndex Computation Working Group: consolidation of index computation methods between the Bering Sea and AI-GOA regions.\nData Processes Working Group: consolidation, clean up, and reorganization of survey oracle schemata, tables, and other data for all surveys."
  },
  {
    "objectID": "content/product-intro.html#data-description",
    "href": "content/product-intro.html#data-description",
    "title": "GAP Production Data",
    "section": "Data Description",
    "text": "Data Description\nThe Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC) conducts fisheries-independent bottom trawl surveys to monitor the condition of the demersal fish and crab stocks of Alaska. These data are developed to describe the temporal distribution and abundance of commercially and ecologically important groundfish species, examine the changes in the species composition of the fauna over time and space, and describe the physical environment of the groundfish habitat. These data are created using the gapindex R package v2.1.0.\nUsers must read and fully comprehend the metadata prior to use. Data should not be used beyond the limits of the source scale. Acknowledgement of NOAA, as the source from which these data were obtained, in any publications and/or other representations of these data, is suggested. These data are compiled and approved annually after each summer survey season. The data from previous years are unlikely to change substantially once published. Some survey data are excluded, such as non-standard stations, surveys completed in earlier years using different/non-standard gear, and special tows and non-standard data collections."
  },
  {
    "objectID": "content/product-intro.html#cite-this-data",
    "href": "content/product-intro.html#cite-this-data",
    "title": "GAP Production Data",
    "section": "Cite this data",
    "text": "Cite this data\nUse the below bibtext citations, as cited in our group’s citation repository for citing the data created and maintained in this repo (NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program, 2023). Add “note = {Accessed: mm/dd/yyyy}” to append the day this data was accessed.\n\n\n@misc{GAPProducts,\n  author = {{NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program}},\n  year = {2023}, \n  title = {AFSC Goundfish Assessment Program Design-Based Production Data},\n  howpublished = {https://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys},\n  publisher = {{U.S. Dep. Commer.}},\n  copyright = {Public Domain} \n}\n\n\n\n\n\n\nNOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program. (2023). AFSC goundfish assessment program design-based production data. https://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys; U.S. Dep. Commer."
  },
  {
    "objectID": "content/product-metadata.html#data-tables",
    "href": "content/product-metadata.html#data-tables",
    "title": "Data description",
    "section": "Data tables",
    "text": "Data tables\n\nAGECOMP\nRegion-level age compositions by sex/length bin.\nNumber of rows: 533,785\nNumber of columns: 9\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAGE\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\nAREA_ID\n\n\nArea ID code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nArea ID code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nLENGTH_MM_MEAN\n\n\nMean length at age weighted by numbers at length\n\n\nnumeric\n\n\nNUMBER(38,3)\n\n\nMean length (millimeters)\n\n\n\n\nLENGTH_MM_SD\n\n\nStandard deviation of length at age weighted by numbers at length\n\n\nnumeric\n\n\nNUMBER(38,3)\n\n\nVariance of mean length.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nAREA\nThis is a table\nNumber of rows: 473\nNumber of columns: 10\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nArea ID code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nAREA_KM2\n\n\nArea (km2)\n\n\nkilometers squared\n\n\nNUMBER(38,3)\n\n\nArea in square kilometers.\n\n\n\n\nAREA_NAME\n\n\nArea ID name\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescriptive name of each AREA_ID. These names often identify the region, depth ranges, or other regional information for the area ID.\n\n\n\n\nCRS\n\n\nCoordinate reference system\n\n\nID code\n\n\nVARCHAR2(255 BYTE)\n\n\nThe coordinate reference system (CRS) that shapefiles were created in or areas (like AREA_KM2) are calculated in, as defined by https://spatialreference.org/ (e.g., “+proj=longlat”, “EPSG:3338”).\n\n\n\n\nDEPTH_MAX_M\n\n\nArea ID maximum depth (m)\n\n\nmeters\n\n\nNUMBER(38,3)\n\n\nMaximum depth (meters).\n\n\n\n\nDEPTH_MIN_M\n\n\nArea ID minimum depth (m)\n\n\nmeters\n\n\nNUMBER(38,3)\n\n\nMinimum depth (meters).\n\n\n\n\nDESCRIPTION\n\n\nDescription\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescription of row observation.\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nTYPE\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\n\n\n\nBIOMASS\nStratum/subarea/region-level mean CPUE (weight and numbers), total biomass, and total abundance with associated variances.\nNumber of rows: 4,569,717\nNumber of columns: 16\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nArea ID code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nBIOMASS_MT\n\n\nEstimated biomass\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated total biomass.\n\n\n\n\nBIOMASS_VAR\n\n\nEstimated biomass variance\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated variance associated with the total biomass.\n\n\n\n\nCPUE_KGKM2_MEAN\n\n\nMean weight CPUE\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).\n\n\n\n\nCPUE_KGKM2_VAR\n\n\nVariance of the mean weight CPUE\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe variance of mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).\n\n\n\n\nCPUE_NOKM2_MEAN\n\n\nMean numberic CPUE\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe mean of numerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2_VAR\n\n\nVariance of the mean numeric CPUE\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe variance of mean numerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nN_COUNT\n\n\nHauls with taxon counts\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with positive count data.\n\n\n\n\nN_HAUL\n\n\nValid hauls\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls.\n\n\n\n\nN_LENGTH\n\n\nHauls with taxon lengths\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with length data.\n\n\n\n\nN_WEIGHT\n\n\nHauls with catch\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with positive catch biomass.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nPOPULATION_VAR\n\n\nEstimated population variance\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated population variance caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nCPUE\nHaul-level zero-filled weight and numerical catch-per-unit-effort.\nNumber of rows: 37,905,115\nNumber of columns: 7\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_SWEPT_KM2\n\n\nArea swept (km)\n\n\nkilometers\n\n\nNUMBER(38,6)\n\n\nThe area the net covered while the net was fishing (kilometers squared), defined as the distance fished times the net width.\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul.\n\n\n\n\nCPUE_KGKM2\n\n\nWeight CPUE (kg/km2)\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nCatch weight (kilograms) per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2\n\n\nNumber CPUE (no/km2)\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nNumerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\n\n\n\nSURVEY_DESIGN\nThis is a table\nNumber of rows: 126\nNumber of columns: 4\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSURVEY\n\n\nSurvey Name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName and description of survey. The column ‘survey’ is associated with the ‘srvy’ and ‘survey_id’ columns.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nMETADATA_TABLE\nThese columns provide the table metadata for all of the tables and views in GAP_PRODUCTS. These tables are created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated October 12, 2023. There are no legal restrictions on access to the data. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).\nNumber of rows: 8\nNumber of columns: 3\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nMETADATA_SENTENCE\n\n\nSentence\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nTable metadata sentence.\n\n\n\n\nMETADATA_SENTENCE_NAME\n\n\nMetadata sentence name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName of table metadata sentence.\n\n\n\n\nMETADATA_SENTENCE_TYPE\n\n\nSentence type\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nType of sentence to have in table metadata.\n\n\n\n\n\n\n\nSTRATUM_GROUPS\nThis is a table\nNumber of rows: 774\nNumber of columns: 4\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nArea ID code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\n\n\n\nSIZECOMP\nStratum/subarea/region-level size compositions by sex. This table was created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated September 25, 2023.\nNumber of rows: 3,134,121\nNumber of columns: 7\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nArea ID code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nLENGTH_MM\n\n\nLength of a specimen\n\n\nmillimeters\n\n\nNUMBER(10,0)\n\n\nLength bin in millimeters.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected."
  },
  {
    "objectID": "content/akfin-intro.html#the-alaska-fisheries-information-network",
    "href": "content/akfin-intro.html#the-alaska-fisheries-information-network",
    "title": "AKFIN",
    "section": "The Alaska Fisheries Information Network",
    "text": "The Alaska Fisheries Information Network\nThe Alaska Fisheries Information Network (AKFIN) is a regional program that consolidates and supports the collection, processing, analysis, and reporting of fisheries statistics for North Pacific and Alaskan fisheries. AKFIN integrates this information into a single data management system using consistent methods and standardized formats. The Network then reports this information on its website, in various publications, and to researchers. The resulting data enables fishery managers, scientists, and associated agencies to supervise fisheries resources more effectively and efficiently.\nIf you are an AFSC employee with access to data through our internal database Oracle server, use this guide to access our data. If not, reach out to AKFIN for a user account."
  },
  {
    "objectID": "content/akfin-intro.html#cite-this-data",
    "href": "content/akfin-intro.html#cite-this-data",
    "title": "AKFIN",
    "section": "Cite this data",
    "text": "Cite this data\nUse the below bibtext citations, as cited in our group’s citation repository for citing the data created and maintained in this repo (Alaska Fisheries Information Network (AKFIN), 2023). Add “note = {Accessed: mm/dd/yyyy}” to append the day this data was accessed.\n\n\n@misc{GAPakfin,\n  author = {{Alaska Fisheries Information Network (AKFIN)}}, \n  institution = {{NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program}},\n  year = {2023}, \n  title = {AFSC Goundfish Assessment Program Design-Based Production Data},\n  howpublished = {https://www.psmfc.org/program/alaska-fisheries-information-network-akfin},\n  publisher = {{U.S. Dep. Commer.}},\n  copyright = {Public Domain} \n}\n\n\n\n\n\n\nAlaska Fisheries Information Network (AKFIN). (2023). AFSC goundfish assessment program design-based production data. NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program; https://www.psmfc.org/program/alaska-fisheries-information-network-akfin; U.S. Dep. Commer."
  },
  {
    "objectID": "content/akfin-metadata.html#data-description",
    "href": "content/akfin-metadata.html#data-description",
    "title": "Data description",
    "section": "Data description",
    "text": "Data description\n[OUTDATED] AKFIN Answers https://akfin.psmfc.org/akfin-answers/ is an Oracle BI tool used for distributing data to stock assessors and other users. Usernames and passwords are distinct from direct akfin database credentials (though they may be identical). RACE data on the AKFIN Answers stock assessment dashboard is located on the “RACE Survey” tab for groundfish and the “Crab” tab for crab surveys. More detailed descriptions of each report are included within that report."
  },
  {
    "objectID": "content/akfin-metadata.html#data-tables",
    "href": "content/akfin-metadata.html#data-tables",
    "title": "Data description",
    "section": "Data tables",
    "text": "Data tables\n\nAKFIN_AGECOMP\nThis table is a copy of GAP_PRODUCTS.AGECOMP and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated September 26, 2023.\nNumber of rows: 533,785\nNumber of columns: 9\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAGE\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\nAREA_ID\n\n\nArea ID code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nArea ID code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nLENGTH_MM_MEAN\n\n\nMean length at age weighted by numbers at length\n\n\nnumeric\n\n\nNUMBER(38,3)\n\n\nMean length (millimeters)\n\n\n\n\nLENGTH_MM_SD\n\n\nStandard deviation of length at age weighted by numbers at length\n\n\nnumeric\n\n\nNUMBER(38,3)\n\n\nVariance of mean length.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nAKFIN_AREA\nThis table is a copy of GAP_PRODUCTS.AREA and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated September 26, 2023.\nNumber of rows: 473\nNumber of columns: 10\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nArea ID code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nAREA_KM2\n\n\nArea (km2)\n\n\nkilometers squared\n\n\nNUMBER(38,3)\n\n\nArea in square kilometers.\n\n\n\n\nAREA_NAME\n\n\nArea ID name\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescriptive name of each AREA_ID. These names often identify the region, depth ranges, or other regional information for the area ID.\n\n\n\n\nCRS\n\n\nCoordinate reference system\n\n\nID code\n\n\nVARCHAR2(255 BYTE)\n\n\nThe coordinate reference system (CRS) that shapefiles were created in or areas (like AREA_KM2) are calculated in, as defined by https://spatialreference.org/ (e.g., “+proj=longlat”, “EPSG:3338”).\n\n\n\n\nDEPTH_MAX_M\n\n\nArea ID maximum depth (m)\n\n\nmeters\n\n\nNUMBER(38,3)\n\n\nMaximum depth (meters).\n\n\n\n\nDEPTH_MIN_M\n\n\nArea ID minimum depth (m)\n\n\nmeters\n\n\nNUMBER(38,3)\n\n\nMinimum depth (meters).\n\n\n\n\nDESCRIPTION\n\n\nDescription\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescription of row observation.\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nTYPE\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\n\n\n\nAKFIN_BIOMASS\nThis table is a copy of GAP_PRODUCTS.BIOMASS and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated October 04, 2023.\nNumber of rows: 4,569,717\nNumber of columns: 16\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nArea ID code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nBIOMASS_MT\n\n\nEstimated biomass\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated total biomass.\n\n\n\n\nBIOMASS_VAR\n\n\nEstimated biomass variance\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated variance associated with the total biomass.\n\n\n\n\nCPUE_KGKM2_MEAN\n\n\nMean weight CPUE\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).\n\n\n\n\nCPUE_KGKM2_VAR\n\n\nVariance of the mean weight CPUE\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe variance of mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).\n\n\n\n\nCPUE_NOKM2_MEAN\n\n\nMean numberic CPUE\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe mean of numerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2_VAR\n\n\nVariance of the mean numeric CPUE\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe variance of mean numerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nN_COUNT\n\n\nHauls with taxon counts\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with positive count data.\n\n\n\n\nN_HAUL\n\n\nValid hauls\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls.\n\n\n\n\nN_LENGTH\n\n\nHauls with taxon lengths\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with length data.\n\n\n\n\nN_WEIGHT\n\n\nHauls with catch\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with positive catch biomass.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nPOPULATION_VAR\n\n\nEstimated population variance\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated population variance caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nAKFIN_CATCH\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_CATCH\nNumber of rows: 989,351\nNumber of columns: 6\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCATCHJOIN\n\n\nCatch observation ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nUnique interger ID assigned to each survey, vessel, year, and catch observation combination.\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul.\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nUnique interger ID assigned to each survey, vessel, and year combination.\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\n\n\n\nAKFIN_CPUE\nThis table is a copy of GAP_PRODUCTS.CPUE and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated September 26, 2023.\nNumber of rows: 37,905,115\nNumber of columns: 7\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_SWEPT_KM2\n\n\nArea swept (km)\n\n\nkilometers\n\n\nNUMBER(38,6)\n\n\nThe area the net covered while the net was fishing (kilometers squared), defined as the distance fished times the net width.\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul.\n\n\n\n\nCPUE_KGKM2\n\n\nWeight CPUE (kg/km2)\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nCatch weight (kilograms) per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2\n\n\nNumber CPUE (no/km2)\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nNumerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\n\n\n\nAKFIN_CRUISE\nThis is the cruise data table. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated September 26, 2023.\nNumber of rows: 187\nNumber of columns: 10\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCRUISE\n\n\nCruise ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis is a six-digit integer identifying the cruise number of the form: YYYY99 (where YYYY = year of the cruise; 99 = 2-digit number and is sequential; 01 denotes the first cruise that vessel made in this year, 02 is the second, etc.).\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nUnique interger ID assigned to each survey, vessel, and year combination.\n\n\n\n\nDATE_END\n\n\nEnd date\n\n\nYYYY-MM-DD\n\n\nDATE\n\n\nThe date (YYYY-MM-DD) of the end of the event (e.g., cruise).\n\n\n\n\nDATE_START\n\n\nStart date\n\n\nYYYY-MM-DD\n\n\nDATE\n\n\nThe date (YYYY-MM-DD) of the beginning of the event (e.g., cruise).\n\n\n\n\nSPONSOR_ACRONYM\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nSURVEY_NAME\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\nVESSEL_ID\n\n\nVessel ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nID number of the vessel used to collect data for that haul. The column ‘vessel_id’ is associated with the ‘vessel_name’ column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID codes, review the code books.\n\n\n\n\nVESSEL_NAME\n\n\nVessel name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName of the vessel used to collect data for that haul. The column ‘vessel_name’ is associated with the ‘vessel_id’ column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID codes, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nAKFIN_HAUL\nThis table is created by subsetting the RACEBASE.HAUL table to only hauls with ABUNDANCE_HAUL = ‘Y’. These are the hauls that are used for the standard production tables in GAP_PRODUCTS. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated September 26, 2023\nNumber of rows: 36,114\nNumber of columns: 25\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nACCESSORIES\n\n\nType of gear accessories used on the net\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nType of accessories used on net. For a complete list of accessories ID codes, review the code books.\n\n\n\n\nBOTTOM_TYPE\n\n\nSeafloor bottom type code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nBottom type on sea floor at haul location. For a complete list of bottom type ID codes, review the code books.\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nUnique interger ID assigned to each survey, vessel, and year combination.\n\n\n\n\nDATE_TIME_START\n\n\nStart date and time\n\n\nMM/DD/YYYY HH::MM\n\n\nDATE\n\n\nThe date (MM/DD/YYYY) and time (HH:MM) of the beginning of the haul.\n\n\n\n\nDEPTH_GEAR_M\n\n\nDepth of gear (m)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nDepth of gear (meters).\n\n\n\n\nDEPTH_M\n\n\nDepth (m)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nBottom depth (meters).\n\n\n\n\nDISTANCE_FISHED_KM\n\n\nDistance fished (km)\n\n\ndegrees Celsius\n\n\nNUMBER(38,3)\n\n\nDistance the net fished (thousandths of kilometers).\n\n\n\n\nDURATION_HR\n\n\nTow duration (decimal hr)\n\n\nhours\n\n\nNUMBER(38,1)\n\n\nThis is the elapsed time between start and end of a haul (decimal hours).\n\n\n\n\nGEAR\n\n\nType of gear used on the net\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nType of gear used on net. For a complete list of gear ID codes, review the code books.\n\n\n\n\nGEAR_TEMPERATURE_C\n\n\nGear temperature (Degrees Celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nTemperature recorded by net gear (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nHAUL\n\n\nHaul number\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a sampling event (haul) within a cruise. It is a sequential number, in chronological order of occurrence.\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nHAUL_TYPE\n\n\nHaul sampling type\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nType of haul sampling method. For a complete list of haul type ID codes, review the code books.\n\n\n\n\nLATITUDE_DD_END\n\n\nEnd latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nLATITUDE_DD_START\n\n\nStart latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nLONGITUDE_DD_END\n\n\nEnd longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nLONGITUDE_DD_START\n\n\nStart longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nNET_HEIGHT_M\n\n\nNet height (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between footrope and headrope of the trawl.\n\n\n\n\nNET_MEASURED\n\n\nNet measured during haul\n\n\nlogical\n\n\nBINARY_DOUBLE\n\n\nLogical, describing if the net was measured (TRUE) or not (FALSE) by wheelhouse and marport programs during the haul.\n\n\n\n\nNET_WIDTH_M\n\n\nNet width (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between wingtips of the trawl.\n\n\n\n\nPERFORMANCE\n\n\nHaul performance code\n\n\ncategory\n\n\nNUMBER(38,0)\n\n\nThis denotes what, if any, issues arose during the haul. For more information, review the code books.\n\n\n\n\nSTATION\n\n\nStation ID\n\n\nID code\n\n\nVARCHAR2(255 BYTE)\n\n\nAlpha-numeric designation for the station established in the design of a survey.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\nSURFACE_TEMPERATURE_C\n\n\nSurface temperature (Degrees Celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nSurface temperature (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nWIRE_LENGTH_M\n\n\nTrawl wire length\n\n\nmeters\n\n\nNUMBER(38,0)\n\n\nLength of wire deployed during a given haul in meters.\n\n\n\n\n\n\n\nAKFIN_LENGTH\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_LENGTH\nNumber of rows: 2,587,694\nNumber of columns: 7\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nFREQUENCY\n\n\nCount of observation\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nFrequency, or count, of an observation.\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nLENGTH_MM\n\n\nLength of a specimen\n\n\nmillimeters\n\n\nNUMBER(10,0)\n\n\nLength bin in millimeters.\n\n\n\n\nLENGTH_TYPE\n\n\nLength type\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nHow the taxon was measured (e.g., fork length, carapace width). For a complete list of length_type ID codes, review the code books.\n\n\n\n\nSAMPLE_TYPE\n\n\nSample type\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nSampling information on how the taxon was sampled. For a complete list of length_type ID codes, review the code books.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\n\n\n\nAKFIN_METADATA_COLUMN\nThis table is a copy of GAP_PRODUCTS.METADATA_COLUMN and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated September 26, 2023.\nNumber of rows: 128\nNumber of columns: 5\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nMETADATA_COLNAME\n\n\nColumn name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName of the column in a table.\n\n\n\n\nMETADATA_COLNAME_DESC\n\n\ncolumn description\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescritpion of the column.\n\n\n\n\nMETADATA_COLNAME_LONG\n\n\nColumn name spelled out\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLong name for the column.\n\n\n\n\nMETADATA_DATATYPE\n\n\nOracle datatype code\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nOracle data type of data column.\n\n\n\n\nMETADATA_UNITS\n\n\nUnits\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nUnits of the column.\n\n\n\n\n\n\n\nAKFIN_SIZECOMP\nThis table is a copy of GAP_PRODUCTS.SIZECOMP and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated September 26, 2023.\nNumber of rows: 3,134,121\nNumber of columns: 7\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nArea ID code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nLENGTH_MM\n\n\nLength of a specimen\n\n\nmillimeters\n\n\nNUMBER(10,0)\n\n\nLength bin in millimeters.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nAKFIN_SPECIMEN\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_SPECIMEN\nNumber of rows: 360,602\nNumber of columns: 13\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAGE_DETERMINATION_METHOD\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\nAGE_YEARS\n\n\nAge bin of taxon\n\n\nyear\n\n\nNUMBER(38,0)\n\n\nAge bin of a taxon in years estimated by the age comp estimate.\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nUnique interger ID assigned to each survey, vessel, and year combination.\n\n\n\n\nGONAD_G\n\n\nWeight of gonads (g)\n\n\ngrams\n\n\nNUMBER(38,1)\n\n\nWeight of specimen gonads (grams).\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nLENGTH_MM\n\n\nLength of a specimen\n\n\nmillimeters\n\n\nNUMBER(10,0)\n\n\nLength bin in millimeters.\n\n\n\n\nMATURITY\n\n\nSpecimen maturity code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe maturity code or the condition identified by the maturity code.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSPECIMEN_ID\n\n\nSpecimen unique ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nEach individual examined must have a number assigned to it that is unique within each haul (0001 to 9999), though specimen numbers may be repeated between hauls\n\n\n\n\nSPECIMEN_SAMPLE_TYPE\n\n\nSpecimen sample type\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nFor a complete list of Specimen sample type ID codes, review the code books.\n\n\n\n\nSPECIMEN_SUBSAMPLE_METHOD\n\n\nSpecimen subsample method\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nFor a complete list of specimen subsample method ID codes, review the code books.\n\n\n\n\nWEIGHT_G\n\n\nSpecimen weight (g)\n\n\ngrams\n\n\nNUMBER(38,1)\n\n\nWeight of specimen (grams).\n\n\n\n\n\n\n\nAKFIN_STRATUM_GROUPS\nThis table is a copy of GAP_PRODUCTS.STRATUM_GROUPS and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated September 26, 2023.\nNumber of rows: 774\nNumber of columns: 4\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nArea ID code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\n\n\n\nAKFIN_SURVEY_DESIGN\nThis table is a copy of GAP_PRODUCTS.SURVEY_DESIGN and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated September 26, 2023.\nNumber of rows: 126\nNumber of columns: 4\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSURVEY\n\n\nSurvey Name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName and description of survey. The column ‘survey’ is associated with the ‘srvy’ and ‘survey_id’ columns.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nAKFIN_TAXONOMIC_CLASSIFICATION\nNAThese data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated September 26, 2023.\nNumber of rows: 2,757\nNumber of columns: 19\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCLASS_TAXON\n\n\nClass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of class of a given species.\n\n\n\n\nCOMMON_NAME\n\n\nTaxon common name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe common name of the marine organism associated with the ‘scientific_name’ and ‘species_code’ columns. For a complete species list, review the code books.\n\n\n\n\nDATABASE\n\n\nDatabase source\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nTaxonomic database source, either ITIS or WoRMS.\n\n\n\n\nDATABASE_ID\n\n\nSpecies ID in database\n\n\nID code\n\n\nVARCHAR2(255 BYTE)\n\n\nSpecies ID code of a species in the taxonomic “DATABASE” source.\n\n\n\n\nFAMILY_TAXON\n\n\nFamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of family of a given species.\n\n\n\n\nGENUS_TAXON\n\n\nGenus phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of genus of a given species.\n\n\n\n\nID_RANK\n\n\nLowest taxonomic rank\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLowest taxonomic rank of a given species entry.\n\n\n\n\nKINGDOM_TAXON\n\n\nKingdom phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of kingdom of a given species.\n\n\n\n\nORDER_TAXON\n\n\nOrder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of order of a given species.\n\n\n\n\nPHYLUM_TAXON\n\n\nPhylum phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of phylum of a given species.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSPECIES_NAME\n\n\nScientific name of species\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nScientific name of species.\n\n\n\n\nSUBCLASS_TAXON\n\n\nSubclass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subclass of a given species.\n\n\n\n\nSUBFAMILY_TAXON\n\n\nSubfamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subfamily of a given species.\n\n\n\n\nSUBORDER_TAXON\n\n\nSuborder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of suborder of a given species.\n\n\n\n\nSUBPHYLUM_TAXON\n\n\nSubphylum phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subphylum of a given species.\n\n\n\n\nSUPERCLASS_TAXON\n\n\nSuperclass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superclass of a given species.\n\n\n\n\nSUPERFAMILY_TAXON\n\n\nSuperfamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superfamily of a given species.\n\n\n\n\nSUPERORDER_TAXON\n\n\nSuperorder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superorder of a given species.\n\n\n\n\nSUPERORDER_TAXON\n\n\nSuperorder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superorder of a given species."
  },
  {
    "objectID": "content/akfin-oracle-sql-r.html#access-data-via-oracle-afsc-only",
    "href": "content/akfin-oracle-sql-r.html#access-data-via-oracle-afsc-only",
    "title": "Access data",
    "section": "Access data via Oracle (AFSC only)",
    "text": "Access data via Oracle (AFSC only)\nAFSC Oracle users can access the database via SQL developer to view and pull the production data directly from the GAP_PRODUCTS Oracle schema. The user can also use SQL developer to view and pull the GAP Products data directly from the GAP_PRODUCTS Oracle schema.\n\nConnect to Oracle from R\nMany users will want to access the data from Oracle using R. The user will need to install the RODBC R package and ask OFIS (IT) connect R to Oracle. Then, use the following code in R to establish a connection from R to Oracle:\nHere, the user can establish the oracle connection by entering their username and password in the channel &lt;- gapindex::oracle_connect() function. Never save usernames or passwords in scripts that may be intentionally or unintentionally shared with others. If no username and password is entered in the function, pop-ups will appear on the screen asking for the username and password."
  },
  {
    "objectID": "content/akfin-oracle-sql-r.html#data-sql-query-examples",
    "href": "content/akfin-oracle-sql-r.html#data-sql-query-examples",
    "title": "Access data",
    "section": "Data SQL Query Examples:",
    "text": "Data SQL Query Examples:\n\nEx. 0: Select all data from a table\nYou can download all of the tables locally using a variation of the code below. Once connected, pull and save the tables of interest into the R environment.\n\nlocations &lt;- c(\n  \"GAP_PRODUCTS.AKFIN_AGECOMP\", \n  \"GAP_PRODUCTS.AKFIN_AREA\", \n  \"GAP_PRODUCTS.AKFIN_BIOMASS\", \n  \"GAP_PRODUCTS.AKFIN_CATCH\", \n  \"GAP_PRODUCTS.AKFIN_CPUE\", \n  \"GAP_PRODUCTS.AKFIN_CRUISE\", \n  \"GAP_PRODUCTS.AKFIN_HAUL\", \n  \"GAP_PRODUCTS.AKFIN_LENGTH\", \n  \"GAP_PRODUCTS.AKFIN_METADATA_COLUMN\", \n  \"GAP_PRODUCTS.AKFIN_SIZECOMP\", \n  \"GAP_PRODUCTS.AKFIN_SPECIMEN\", \n  \"GAP_PRODUCTS.AKFIN_STRATUM_GROUPS\", \n  \"GAP_PRODUCTS.AKFIN_SURVEY_DESIGN\", \n  \"GAP_PRODUCTS.AKFIN_TAXONOMIC_CLASSIFICATION\"\n)\n\nfor (i in 1:length(locations)) {\n  print(locations[i])\n  a &lt;- RODBC::sqlQuery(channel, paste0(\"SELECT * FROM \", locations[i]))\n  write.csv(x = a, file = here::here(\"data\", paste0(locations[i], \".csv\")))\n}\n\n\n\nEx. 1: GOA Pacific Ocean perch biomass and abundance\nBiomass and abundance for Pacific Ocean perch from 1990 – 2023 for the western/central/eastern GOA management areas as well as for the entire region.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n\"WITH FILTERED_STRATA AS (\nSELECT AREA_ID, DESCRIPTION FROM GAP_PRODUCTS.AKFIN_AREA\nWHERE TYPE in ('REGULATORY_AREA', 'REGION') \nAND SURVEY_DEFINITION_ID = 47)\nSELECT \nBIOMASS_MT,\nPOPULATION_COUNT, \nYEAR, \nDESCRIPTION\nFROM GAP_PRODUCTS.AKFIN_BIOMASS BIOMASS\nJOIN FILTERED_STRATA STRATA \nON STRATA.AREA_ID = BIOMASS.AREA_ID\nWHERE BIOMASS.SURVEY_DEFINITION_ID IN 47 \nAND BIOMASS.SPECIES_CODE = 30060\")\n\n\ndat0 &lt;- dat %&gt;% \n  janitor::clean_names() %&gt;% \n  dplyr::select(biomass_mt, population_count, year, area = description) %&gt;%\n  pivot_longer(cols = c(\"biomass_mt\", \"population_count\"), \n               names_to = \"var\", \n               values_to = \"val\") %&gt;% \n  dplyr::mutate(\n    val = ifelse(var == \"biomass_mt\", val/1e6, val/1e9), \n    var = ifelse(var == \"biomass_mt\", \"Biomass (Mmt)\", \"Population (B)\"), \n    area = gsub(x = area, pattern = \" - \", replacement = \"\\n\"), \n    area = gsub(x = area, pattern = \": \", replacement = \"\\n\"), \n    type = sapply(X = strsplit(x = area, split = \"\\n\", fixed = TRUE), `[[`, 2))  %&gt;% \n  dplyr::arrange(type) %&gt;% \n  dplyr::mutate(\n    area = factor(area, levels = unique(area), labels = unique(area), ordered = TRUE))\n\nflextable::flextable(head(dat)) %&gt;% \n  theme_zebra() %&gt;%\n  flextable::colformat_num(x = ., j = \"YEAR\", big.mark = \"\")\n\n\nEx. 1: GOA Pacific Ocean perch biomass and abundance.BIOMASS_MTPOPULATION_COUNTYEARDESCRIPTION483,622.6833,902,1611993GOA Region: All Strata483,622.6833,902,1611993GOA Region: All Strata771,412.81,252,616,6031996GOA Region: All Strata771,412.81,252,616,6031996GOA Region: All Strata727,063.51,212,034,9131999GOA Region: All Strata727,063.51,212,034,9131999GOA Region: All Strata\n\n\n\n# install.packages(\"scales\")\nlibrary(scales)\nfigure &lt;- ggplot2::ggplot(\n  dat = dat0, \n  mapping = aes(x = year, y = val, color = type)) +\n  ggplot2::geom_point(size = 3) + \n  ggplot2::facet_grid(cols = vars(area), rows = vars(var), scales = \"free_y\") + \n  ggplot2::scale_x_continuous(name = \"Year\", n.breaks = 3) +\n  ggplot2::scale_y_continuous(name = \"Estimate\", labels = comma) +\n  ggplot2::labs(title = 'GOA Pacific Ocean perch biomass and abundance 1990 – 2023')  + \n  ggplot2::guides(color=guide_legend(title = \"Region Type\"))+\n  ggplot2::scale_color_grey() +\n  ggplot2::theme_bw() +\n  ggplot2::theme(legend.direction = \"horizontal\", \n                 legend.position = \"bottom\")\n\nfigure\n\n\n\n\nEx. 1: GOA Pacific Ocean perch biomass and abundance.\n\n\n\n\n\n\nEx. 2: AI Rock sole size compositions and ridge plot\nNorthern and Southern rock sole size composition data from 1991 – 2022 for the Aleutian Islands, with Ridge plot from ggridges.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n\"WITH FILTERED_STRATA AS (\nSELECT \nAREA_ID, \nDESCRIPTION \nFROM GAP_PRODUCTS.AKFIN_AREA\nWHERE TYPE = 'REGION' \nAND SURVEY_DEFINITION_ID = 52)\nSELECT \nLENGTH_MM, \nYEAR\nFROM GAP_PRODUCTS.AKFIN_SIZECOMP SIZECOMP\nJOIN FILTERED_STRATA STRATA \nON STRATA.AREA_ID = SIZECOMP.AREA_ID\nWHERE SIZECOMP.SURVEY_DEFINITION_ID IN 52 \nAND SIZECOMP.SPECIES_CODE IN (10261, 10262)\")\n\n\ndat0 &lt;- dat %&gt;% \n  janitor::clean_names() %&gt;% \n  dplyr::mutate(length_cm = length_mm/10)\nflextable::flextable(head(dat)) %&gt;% \n  theme_zebra() %&gt;%\n    flextable::colformat_num(x = ., j = \"YEAR\", big.mark = \"\")\n\n\nEx. 2: AI Rock sole size compositions and ridge plot.LENGTH_MMYEAR180201419020142002014210201422020142302014\n\n\n\n# install.packages(\"ggridges\")\nlibrary(ggridges)\nfigure &lt;- \n  ggplot2::ggplot(\n    data = dat0, \n    mapping = aes(x = length_cm, y = as.factor(year), fill = stat(x))) +\n  ggridges::theme_ridges(center_axis_labels = TRUE) + \n  ggridges::geom_density_ridges_gradient(scale = 4, show.legend = FALSE) + \n  ggplot2::scale_y_discrete(name = \"Year\", expand = c(0.01, 0)) +\n  ggplot2::scale_x_continuous(name = \"Length (cm)\", expand = c(0.01, 0)) +\n  # ggplot2::scale_fill_grey() +\n  ggplot2::labs(title = 'AI Rock sole Size Compositions 1991 – 2022') \n\nfigure\n\n\n\n\nEx. 2: AI Rock sole size compositions and ridge plot.\n\n\n\n\n\n\nEx. 3: EBS Walleye Pollock Age Compositions and Age Pyramid\nWalleye pollock age composition for the EBS Standard Area from 1982 – 2022 and the EBS + NW Area from 1987 – 2022, with age pyramid plot.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n\"WITH FILTERED_STRATA AS (\nSELECT \nAREA_ID, \nDESCRIPTION \nFROM GAP_PRODUCTS.AKFIN_AREA\nWHERE TYPE = 'REGION' AND \nSURVEY_DEFINITION_ID = 98)\nSELECT \nAGECOMP.AGE, \nAGECOMP.POPULATION_COUNT, \nAGECOMP.SEX\nFROM GAP_PRODUCTS.AKFIN_AGECOMP AGECOMP\nJOIN FILTERED_STRATA STRATA \nON STRATA.AREA_ID = AGECOMP.AREA_ID\nWHERE SURVEY_DEFINITION_ID = 98 \nAND SPECIES_CODE = 21740\nAND AGE &gt;= 0\")\n\n\ndat0 &lt;- dat %&gt;% \n  janitor::clean_names() %&gt;% \n  dplyr::filter(sex %in% c(1,2)) %&gt;%\n  dplyr::mutate(\n    sex = ifelse(sex == 1, \"M\", \"F\"),\n    population_count = # change male population to negative\n      ifelse(sex==\"M\", population_count*(-1), population_count*1)/1e9) \n\nflextable::flextable(head(dat)) %&gt;% theme_zebra()\n\n\nEx. 3: EBS Walleye Pollock Age Compositions and Age Pyramid.AGEPOPULATION_COUNTSEX939,37131032,15631115,2003129,9763131,95731131,950,3431\n\n\n\nfigure &lt;- ggplot2::ggplot(\n  data = dat0, \n  mapping = \n                 aes(x = age,\n                     y = population_count, \n                     fill = sex)) +\n  ggplot2::scale_fill_grey() +\n  ggplot2::geom_bar(stat = \"identity\") +\n  ggplot2::coord_flip() +\n  ggplot2::scale_x_continuous(name = \"Age\") +\n  ggplot2::scale_y_continuous(name = \"Population (billions)\", labels = abs) +\n  ggplot2::ggtitle(label = \"EBS Walleye Pollock Age Compositions 1982 – 2022\")  + \n  ggplot2::guides(fill = guide_legend(title = \"Sex\"))+\n  ggplot2::theme_bw()\n\nfigure\n\n\n\n\nEx. 3: EBS Walleye Pollock Age Compositions and Age Pyramid.\n\n\n\n\n\n\nEx. 4: NBS Pacific cod biomass and abundance\nPacific cod biomass and abundance data for the NBS by stratum.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n\"WITH FILTERED_STRATA AS (\nSELECT \nAREA_ID, \nAREA_NAME, \nDESCRIPTION \nFROM GAP_PRODUCTS.AKFIN_AREA\nWHERE TYPE in ('STRATUM') AND \nSURVEY_DEFINITION_ID = 143) \nSELECT \nBIOMASS.BIOMASS_MT, \nBIOMASS.POPULATION_COUNT, \nBIOMASS.YEAR, \nSTRATA.AREA_NAME\nFROM GAP_PRODUCTS.AKFIN_BIOMASS BIOMASS \nJOIN FILTERED_STRATA STRATA \nON STRATA.AREA_ID = BIOMASS.AREA_ID\nWHERE BIOMASS.SURVEY_DEFINITION_ID IN 143 \nAND BIOMASS.SPECIES_CODE = 21720\")\n\n\ndat0 &lt;- dat %&gt;% \n  janitor::clean_names() %&gt;% \n  dplyr::select(biomass_mt, population_count, year, area = area_name) %&gt;%\n  pivot_longer(cols = c(\"biomass_mt\", \"population_count\"), \n               names_to = \"var\", \n               values_to = \"val\") %&gt;% \n  dplyr::mutate(\n    val = ifelse(var == \"biomass_mt\", val/1e6, val/1e9), \n    var = ifelse(var == \"biomass_mt\", \"Biomass (Mmt)\", \"Population (B)\"), \n    area = factor(area, levels = unique(area), labels = unique(area), ordered = TRUE))\nflextable::flextable(head(dat)) %&gt;% \n  theme_zebra() %&gt;%\n  flextable::colformat_num(x = ., j = \"YEAR\", big.mark = \"\")\n\n\nEx. 4: NBS Pacific cod biomass and abundance.BIOMASS_MTPOPULATION_COUNTYEARAREA_NAME95,849.98368,767,4982021Inner Domain107,096.730102,734,1422019Inner Domain76,708.43339,605,8602023Inner Domain132,490.15266,187,2452017Inner Domain96,500.69760,433,1352022Inner Domain7,462.5594,724,1532010Inner Domain\n\n\n\nfigure &lt;- ggplot2::ggplot(\n  dat = dat0, \n  mapping = aes(y = val, x = year, fill = area))  + \n  ggplot2::geom_bar(position=\"stack\", stat=\"identity\") +  \n  ggplot2::facet_grid(rows = vars(var), scales = \"free_y\") +\n  ggplot2::scale_y_continuous(name = \"Estimate\", labels = comma) +\n  ggplot2::scale_x_continuous(name = \"Year\", breaks = unique(dat0$year)) +\n  ggplot2::labs(title = 'NBS Pacific cod biomass and abundance by stratum')  + \n  ggplot2::guides(fill=guide_legend(title = \"Region Type\"))+\n  ggplot2::scale_fill_grey() +\n  ggplot2::theme_bw() +\n  ggplot2::theme(legend.direction = \"horizontal\", \n                 legend.position = \"bottom\")\n\nfigure\n\n\n\n\nEx. 4: NBS Pacific cod biomass and abundance.\n\n\n\n\n\n\nEx. 5: GOA Pacific Ocean perch biomass and line plot\nPacific Ocean perch biomass totals for GOA between 1984-2021 from GAP_PRODUCTS.AKFIN_BIOMASS\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n\"SELECT \nSURVEY_DEFINITION_ID, \nBIOMASS_MT, \nBIOMASS_VAR, \nYEAR\nFROM GAP_PRODUCTS.AKFIN_BIOMASS\nWHERE SPECIES_CODE = 30060 \nAND SURVEY_DEFINITION_ID = 47 \nAND AREA_ID = 99903 \nAND YEAR BETWEEN 1984 AND 2023;\") %&gt;% \n  janitor::clean_names() %&gt;% \n  dplyr::mutate(biomass_kmt = biomass_mt/1000, \n                # **approximate** 95% confidence interval\n                biomass_kci_up = (biomass_mt + (2*sqrt(biomass_var)))/1000, \n                biomass_kci_dw = (biomass_mt - (2*sqrt(biomass_var)))/1000) \n\n\nflextable::flextable(head(dat)) %&gt;%\n  theme_zebra() %&gt;%\n  flextable::colformat_num(x = ., j = \"year\", big.mark = \"\")\n\n\nEx. 5: GOA Pacific Ocean perch biomass and line plot.survey_definition_idbiomass_mtbiomass_varyearbiomass_kmtbiomass_kci_upbiomass_kci_dw47483,622.611,803,384,7871993483.6226700.9093266.3358147771,412.841,434,152,2021996771.41281,178.5204364.3051547727,063.5150,983,542,1781999727.06351,504.1955-50.0685447673,155.149,285,342,9222001673.15511,117.1611229.1490147457,421.65,186,126,5292003457.4216601.4511313.3920447764,901.421,499,807,0102005764.90141,058.1577471.64517\n\n\n\na_mean &lt;- dat %&gt;% \n  dplyr::group_by(survey_definition_id) %&gt;% \n  dplyr::summarise(biomass_kmt = mean(biomass_kmt, na.rm = TRUE), \n                   minyr = min(year, na.rm = TRUE), \n                   maxyr = max(year, na.rm = TRUE)) \n\nfigure &lt;-\n  ggplot(data = dat, \n         mapping = aes(x = year, \n                       y = biomass_kmt)) +\n  ggplot2::geom_point(size = 2.5, color = \"grey40\") + \n  ggplot2::scale_x_continuous(\n    name = \"Year\", \n    labels = scales::label_number(\n      accuracy = 1, \n      big.mark = \"\"))   +\n  ggplot2::scale_y_continuous(\n    name = \"Biomass (Kmt)\", \n    labels = comma) +\n  ggplot2::geom_segment(\n    data = a_mean,\n    mapping = aes(x = minyr, \n                  xend = maxyr, \n                  y = biomass_kmt, \n                  yend = biomass_kmt),\n    linetype = \"dashed\", \n    linewidth = 2) +\n  ggplot2::geom_errorbar(\n    mapping = aes(ymin = biomass_kci_dw, ymax = biomass_kci_up),\n                 position = position_dodge(.9),\n    alpha = 0.5, width=.2) +\n  ggplot2::ggtitle(\n    label = \"GOA Pacific Ocean Perch Biomass 1984-2021\", \n    subtitle = paste0(\"Mean = \", \n                      formatC(x = a_mean$biomass_kmt, \n                              digits = 2, \n                              big.mark = \",\", \n                              format = \"f\"), \n                      \" Kmt\")) +\n  ggplot2::theme_bw()\n\nfigure\n\n\n\n\nEx. 5: GOA Pacific Ocean perch biomass and line plot.\n\n\n\n\n\n\nEx. 6: EBS Pacific Ocean perch CPUE and akgfmaps map\nPacific Ocean perch catch-per-unit-effort estimates for EBS in 2021 from GAP_PRODUCTS.AKFIN_CPUE and map constructed using akgfmaps. Here, we’ll use AKFIN HAUL and CRUISES data also included in this repo, for convenience, though they are very similar to their RACEBASE analogs.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n\"SELECT \n(cp.CPUE_KGKM2/100) CPUE_KGHA, -- akgfmaps is expecting hectares\nhh.LATITUDE_DD_START LATITUDE,\nhh.LONGITUDE_DD_START LONGITUDE\n\nFROM GAP_PRODUCTS.AKFIN_CPUE cp\n\n-- Use HAUL data to obtain LATITUDE & LONGITUDE and connect to cruisejoin\nLEFT JOIN GAP_PRODUCTS.AKFIN_HAUL hh\nON cp.HAULJOIN = hh.HAULJOIN\n\n-- Use CRUISES data to obtain YEAR and SURVEY_DEFINITION_ID\nLEFT JOIN GAP_PRODUCTS.AKFIN_CRUISE cc\nON hh.CRUISEJOIN = cc.CRUISEJOIN\n\nWHERE cp.SPECIES_CODE = 30060 \nAND cc.SURVEY_DEFINITION_ID = 98 \nAND cc.YEAR = 2021;\")\n\n\nflextable::flextable(head(dat)) %&gt;% theme_zebra()\n\n\nEx. 6: EBS Pacific Ocean perch CPUE and akgfmaps\nmap.CPUE_KGHALATITUDELONGITUDE0.000000058.75863-174.92850.281353357.32545-173.32170.000000057.64161-172.79630.000000059.67831-172.57540.000000060.96936-174.87600.000000058.64012-173.5922\n\n\n\n# devtools::install_github(\"afsc-gap-products/akgfmaps\", build_vignettes = TRUE)\nlibrary(akgfmaps)\n\nfigure &lt;- akgfmaps::make_idw_map(\n  x = dat, # Pass data as a data frame\n  region = \"bs.south\", # Predefined EBS area\n  set.breaks = \"jenks\", # Gets Jenks breaks from classint::classIntervals()\n  in.crs = \"+proj=longlat\", # Set input coordinate reference system\n  out.crs = \"EPSG:3338\", # Set output coordinate reference system\n  grid.cell = c(20000, 20000), # 20x20km grid\n  key.title = \"Pacific Ocean perch\") # Include in the legend title\n\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n\nfigure$plot + \n  ggplot2::guides(fill=guide_legend(title = \"Pacific Ocean perch\\nCPUE (kg/km2)\"))  |&gt;   \n  change_fill_color(new.scheme = \"grey\", show.plot = FALSE)\n\n\n\n\nEx. 6: EBS Pacific Ocean perch CPUE and akgfmaps map."
  },
  {
    "objectID": "content/akfin-api-r.html#ex.-1-load-lingcod-data",
    "href": "content/akfin-api-r.html#ex.-1-load-lingcod-data",
    "title": "Access API data using R",
    "section": "Ex. 1: Load lingcod data",
    "text": "Ex. 1: Load lingcod data\n\nlingcod_biomass &lt;- get_gap_biomass(area_id=c(40, 41), species_code=21910)\nflextable::flextable(head(lingcod_biomass)) %&gt;%\n  flextable::theme_zebra()"
  },
  {
    "objectID": "content/foss-intro.html",
    "href": "content/foss-intro.html",
    "title": "Public Data (FOSS)",
    "section": "",
    "text": "Collaborators and data users\nBelow are a few packages and products currently using this data. If you have developed a product, performed an analysis, or exhibited this data in any way, reach out so we can showcase your hard work."
  },
  {
    "objectID": "content/foss-intro.html#cite-this-data",
    "href": "content/foss-intro.html#cite-this-data",
    "title": "Public Data (FOSS)",
    "section": "Cite this data",
    "text": "Cite this data\nUse the below bibtext citations, as cited in our group’s citation repository for citing the data created and maintained in this repo (NOAA Fisheries Alaska Fisheries Science Center, 2023). Add “note = {Accessed: mm/dd/yyyy}” to append the day this data was accessed.\n\n\n@misc{FOSSAFSCData,\n  author = {{NOAA Fisheries Alaska Fisheries Science Center}},\n  year = {2023}, \n  title = {Fisheries One Stop Shop Public Data: RACE Division Bottom Trawl Survey Data Query},\n  howpublished = {https://www.fisheries.noaa.gov/foss},\n  publisher = {{U.S. Dep. Commer.}},\n  copyright = {Public Domain} \n}\n\n\n\n\n\n\nNOAA Fisheries Alaska Fisheries Science Center. (2023). Fisheries one stop shop public data: RACE division bottom trawl survey data query. https://www.fisheries.noaa.gov/foss; U.S. Dep. Commer."
  },
  {
    "objectID": "content/foss-metadata.html#data-tables",
    "href": "content/foss-metadata.html#data-tables",
    "title": "Data description",
    "section": "Data tables",
    "text": "Data tables\n\nFOSS_CATCH\nThese datasets, FOSS_CATCH, FOSS_CPUE_PRESONLY, FOSS_HAUL, and FOSS_SPECIES, when full joined by the HAULJOIN variable, includes zero-filled (presence and absence) observations and catch-per-unit-effort (CPUE) estimates for all identified species at for index stations. These tables were created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated October 17, 2023.\nNumber of rows: 928,931\nNumber of columns: 7\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul.\n\n\n\n\nCPUE_KGKM2\n\n\nWeight CPUE (kg/km2)\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nCatch weight (kilograms) per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2\n\n\nNumber CPUE (no/km2)\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nNumerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nTAXON_CONFIDENCE\n\n\nTaxon confidence rating\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nConfidence in the ability of the survey team to correctly identify the taxon to the specified level, based solely on identification skill (e.g., not likelihood of a taxon being caught at that station on a location-by-location basis). Quality codes follow: ‘High’: High confidence and consistency. Taxonomy is stable and reliable at this level, and field identification characteristics are well known and reliable. ‘Moderate’: Moderate confidence. Taxonomy may be questionable at this level, or field identification characteristics may be variable and difficult to assess consistently. ‘Low’: Low confidence. Taxonomy is incompletely known, or reliable field identification characteristics are unknown. Documentation: Species identification confidence in the eastern Bering Sea shelf survey (1982-2008), Species identification confidence in the eastern Bering Sea slope survey (1976-2010), and Species identification confidence in the Gulf of Alaska and Aleutian Islands surveys (1980-2011).\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\n\n\n\nFOSS_CPUE_PRESONLY\nThese datasets, FOSS_CATCH, FOSS_CPUE_PRESONLY, FOSS_HAUL, and FOSS_SPECIES, when full joined by the HAULJOIN variable, includes zero-filled (presence and absence) observations and catch-per-unit-effort (CPUE) estimates for all identified species at for index stations. These tables were created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated October 17, 2023.\nNumber of rows: 928,931\nNumber of columns: 38\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_SWEPT_KM2\n\n\nArea swept (km)\n\n\nkilometers\n\n\nNUMBER(38,6)\n\n\nThe area the net covered while the net was fishing (kilometers squared), defined as the distance fished times the net width.\n\n\n\n\nBOTTOM_TEMPERATURE_C\n\n\nBottom temperature (degrees celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nBottom temperature (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nCOMMON_NAME\n\n\nTaxon common name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe common name of the marine organism associated with the ‘scientific_name’ and ‘species_code’ columns. For a complete species list, review the code books.\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul.\n\n\n\n\nCPUE_KGKM2\n\n\nWeight CPUE (kg/km2)\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nCatch weight (kilograms) per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2\n\n\nNumber CPUE (no/km2)\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nNumerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCRUISE\n\n\nCruise ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis is a six-digit integer identifying the cruise number of the form: YYYY99 (where YYYY = year of the cruise; 99 = 2-digit number and is sequential; 01 denotes the first cruise that vessel made in this year, 02 is the second, etc.).\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nUnique interger ID assigned to each survey, vessel, and year combination.\n\n\n\n\nDATE_TIME\n\n\nDate and time\n\n\nMM/DD/YYYY HH::MM\n\n\nDATE\n\n\nThe date (MM/DD/YYYY) and time (HH:MM) of the haul.\n\n\n\n\nDEPTH_M\n\n\nDepth (m)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nBottom depth (meters).\n\n\n\n\nDISTANCE_FISHED_KM\n\n\nDistance fished (km)\n\n\ndegrees Celsius\n\n\nNUMBER(38,3)\n\n\nDistance the net fished (thousandths of kilometers).\n\n\n\n\nDURATION_HR\n\n\nTow duration (decimal hr)\n\n\nhours\n\n\nNUMBER(38,1)\n\n\nThis is the elapsed time between start and end of a haul (decimal hours).\n\n\n\n\nHAUL\n\n\nHaul number\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a sampling event (haul) within a cruise. It is a sequential number, in chronological order of occurrence.\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nID_RANK\n\n\nLowest taxonomic rank\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLowest taxonomic rank of a given species entry.\n\n\n\n\nITIS\n\n\nITIS taxonomic serial number\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nSpecies code as identified in the Integrated Taxonomic Information System (https://itis.gov/).\n\n\n\n\nLATITUDE_DD_END\n\n\nEnd latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nLATITUDE_DD_START\n\n\nStart latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nLONGITUDE_DD_END\n\n\nEnd longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nLONGITUDE_DD_START\n\n\nStart longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nNET_HEIGHT_M\n\n\nNet height (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between footrope and headrope of the trawl.\n\n\n\n\nNET_WIDTH_M\n\n\nNet width (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between wingtips of the trawl.\n\n\n\n\nPERFORMANCE\n\n\nHaul performance code\n\n\ncategory\n\n\nNUMBER(38,0)\n\n\nThis denotes what, if any, issues arose during the haul. For more information, review the code books.\n\n\n\n\nSCIENTIFIC_NAME\n\n\nTaxon scientific name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe scientific name of the organism associated with the ‘common_name’ and ‘species_code’ columns. For a complete taxon list, review the code books.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSRVY\n\n\nSurvey\n\n\ntext abbreviated\n\n\nVARCHAR2(255 BYTE)\n\n\nAbbreviated survey names. The column ‘srvy’ is associated with the ‘survey’ and ‘survey_id’ columns. Northern Bering Sea (NBS), Southeastern Bering Sea (EBS), Bering Sea Slope (BSS), Gulf of Alaska (GOA), Aleutian Islands (AI).\n\n\n\n\nSTATION\n\n\nStation ID\n\n\nID code\n\n\nVARCHAR2(255 BYTE)\n\n\nAlpha-numeric designation for the station established in the design of a survey.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\nSURFACE_TEMPERATURE_C\n\n\nSurface temperature (Degrees Celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nSurface temperature (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nSURVEY\n\n\nSurvey Name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName and description of survey. The column ‘survey’ is associated with the ‘srvy’ and ‘survey_id’ columns.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nSURVEY_NAME\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\nTAXON_CONFIDENCE\n\n\nTaxon confidence rating\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nConfidence in the ability of the survey team to correctly identify the taxon to the specified level, based solely on identification skill (e.g., not likelihood of a taxon being caught at that station on a location-by-location basis). Quality codes follow: ‘High’: High confidence and consistency. Taxonomy is stable and reliable at this level, and field identification characteristics are well known and reliable. ‘Moderate’: Moderate confidence. Taxonomy may be questionable at this level, or field identification characteristics may be variable and difficult to assess consistently. ‘Low’: Low confidence. Taxonomy is incompletely known, or reliable field identification characteristics are unknown. Documentation: Species identification confidence in the eastern Bering Sea shelf survey (1982-2008), Species identification confidence in the eastern Bering Sea slope survey (1976-2010), and Species identification confidence in the Gulf of Alaska and Aleutian Islands surveys (1980-2011).\n\n\n\n\nVESSEL_ID\n\n\nVessel ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nID number of the vessel used to collect data for that haul. The column ‘vessel_id’ is associated with the ‘vessel_name’ column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID codes, review the code books.\n\n\n\n\nVESSEL_NAME\n\n\nVessel name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName of the vessel used to collect data for that haul. The column ‘vessel_name’ is associated with the ‘vessel_id’ column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID codes, review the code books.\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\nWORMS\n\n\nWorld Register of Marine Species Taxonomic Serial Number\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nSpecies code as identified in the World Register of Marine Species (WoRMS) (https://www.marinespecies.org/).\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nFOSS_HAUL\nThese datasets, FOSS_CATCH, FOSS_CPUE_PRESONLY, FOSS_HAUL, and FOSS_SPECIES, when full joined by the HAULJOIN variable, includes zero-filled (presence and absence) observations and catch-per-unit-effort (CPUE) estimates for all identified species at for index stations. These tables were created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated October 17, 2023.\nNumber of rows: 32,626\nNumber of columns: 27\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_SWEPT_KM2\n\n\nArea swept (km)\n\n\nkilometers\n\n\nNUMBER(38,6)\n\n\nThe area the net covered while the net was fishing (kilometers squared), defined as the distance fished times the net width.\n\n\n\n\nBOTTOM_TEMPERATURE_C\n\n\nBottom temperature (degrees celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nBottom temperature (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nCRUISE\n\n\nCruise ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis is a six-digit integer identifying the cruise number of the form: YYYY99 (where YYYY = year of the cruise; 99 = 2-digit number and is sequential; 01 denotes the first cruise that vessel made in this year, 02 is the second, etc.).\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nUnique interger ID assigned to each survey, vessel, and year combination.\n\n\n\n\nDATE_TIME\n\n\nDate and time\n\n\nMM/DD/YYYY HH::MM\n\n\nDATE\n\n\nThe date (MM/DD/YYYY) and time (HH:MM) of the haul.\n\n\n\n\nDEPTH_M\n\n\nDepth (m)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nBottom depth (meters).\n\n\n\n\nDISTANCE_FISHED_KM\n\n\nDistance fished (km)\n\n\ndegrees Celsius\n\n\nNUMBER(38,3)\n\n\nDistance the net fished (thousandths of kilometers).\n\n\n\n\nDURATION_HR\n\n\nTow duration (decimal hr)\n\n\nhours\n\n\nNUMBER(38,1)\n\n\nThis is the elapsed time between start and end of a haul (decimal hours).\n\n\n\n\nHAUL\n\n\nHaul number\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a sampling event (haul) within a cruise. It is a sequential number, in chronological order of occurrence.\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nLATITUDE_DD_END\n\n\nEnd latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nLATITUDE_DD_START\n\n\nStart latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nLONGITUDE_DD_END\n\n\nEnd longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nLONGITUDE_DD_START\n\n\nStart longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nNET_HEIGHT_M\n\n\nNet height (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between footrope and headrope of the trawl.\n\n\n\n\nNET_WIDTH_M\n\n\nNet width (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between wingtips of the trawl.\n\n\n\n\nPERFORMANCE\n\n\nHaul performance code\n\n\ncategory\n\n\nNUMBER(38,0)\n\n\nThis denotes what, if any, issues arose during the haul. For more information, review the code books.\n\n\n\n\nSRVY\n\n\nSurvey\n\n\ntext abbreviated\n\n\nVARCHAR2(255 BYTE)\n\n\nAbbreviated survey names. The column ‘srvy’ is associated with the ‘survey’ and ‘survey_id’ columns. Northern Bering Sea (NBS), Southeastern Bering Sea (EBS), Bering Sea Slope (BSS), Gulf of Alaska (GOA), Aleutian Islands (AI).\n\n\n\n\nSTATION\n\n\nStation ID\n\n\nID code\n\n\nVARCHAR2(255 BYTE)\n\n\nAlpha-numeric designation for the station established in the design of a survey.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\nSURFACE_TEMPERATURE_C\n\n\nSurface temperature (Degrees Celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nSurface temperature (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nSURVEY\n\n\nSurvey Name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName and description of survey. The column ‘survey’ is associated with the ‘srvy’ and ‘survey_id’ columns.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nSURVEY_NAME\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\nVESSEL_ID\n\n\nVessel ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nID number of the vessel used to collect data for that haul. The column ‘vessel_id’ is associated with the ‘vessel_name’ column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID codes, review the code books.\n\n\n\n\nVESSEL_NAME\n\n\nVessel name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName of the vessel used to collect data for that haul. The column ‘vessel_name’ is associated with the ‘vessel_id’ column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID codes, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nFOSS_SPECIES\nThese datasets, FOSS_CATCH, FOSS_CPUE_PRESONLY, FOSS_HAUL, and FOSS_SPECIES, when full joined by the HAULJOIN variable, includes zero-filled (presence and absence) observations and catch-per-unit-effort (CPUE) estimates for all identified species at for index stations. These tables were created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated October 17, 2023.\nNumber of rows: 1,936\nNumber of columns: 6\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCOMMON_NAME\n\n\nTaxon common name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe common name of the marine organism associated with the ‘scientific_name’ and ‘species_code’ columns. For a complete species list, review the code books.\n\n\n\n\nID_RANK\n\n\nLowest taxonomic rank\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLowest taxonomic rank of a given species entry.\n\n\n\n\nITIS\n\n\nITIS taxonomic serial number\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nSpecies code as identified in the Integrated Taxonomic Information System (https://itis.gov/).\n\n\n\n\nSCIENTIFIC_NAME\n\n\nTaxon scientific name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe scientific name of the organism associated with the ‘common_name’ and ‘species_code’ columns. For a complete taxon list, review the code books.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nWORMS\n\n\nWorld Register of Marine Species Taxonomic Serial Number\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nSpecies code as identified in the World Register of Marine Species (WoRMS) (https://www.marinespecies.org/).\n\n\n\n\n\n\n\nFOSS_SURVEY_SPECIES\nThis reference dataset contains the full list of species by survey to be used to zero-fill FOSS_CATCH and FOSS_HAUL for each survey. These tables were created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated October 17, 2023.\nNumber of rows: 5,025\nNumber of columns: 2\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a survey. Name and description of survey. The column ‘survey_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\n\n\n\nFOSS_TAXON_GROUP\nThis reference dataset contains suggested search groups for simplifying species selection in the FOSS data platform so users can better search through FOSS_CATCH. These tables were created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated October 17, 2023.\nNumber of rows: 37,606\nNumber of columns: 3\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCLASSIFICATION\n\n\nTaxonomic classification rank group\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic classification group rank for a given species.\n\n\n\n\nRANK_ID\n\n\nTaxonomic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nThe taxonomic rank of a taxon identification.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books."
  },
  {
    "objectID": "content/foss-platform.html#select-and-filter",
    "href": "content/foss-platform.html#select-and-filter",
    "title": "Using the FOSS platform",
    "section": "Select and filter",
    "text": "Select and filter\nSelect, filter, and package this and other NOAA Fisheries data from the Fisheries One Stop Shop (FOSS) platform. A user guide for the FOSS platform can be found here. To begin a report, select options from the boxes what you need data for.\nFor a given box, select one or a few options from the “options box” (list on the left) to query by highlighting them. To select multiple options, hold down the CTRL key while clicking on the options of interest, or click and drag down the list. Once the options you wish to be included in your query are highlighted, click the right-pointing arrow (&gt;) to move them into the “selection box” (list on the right). If you accidentally select an option that you do not want to query, simply select the unwanted option from the selection box and click the left-pointing arrow (&lt;).\nIf you wish to select all options from the options box and send them to the selection box, simply click the double right-pointing arrow (&gt;&gt;). If you want to unselect all options from the selection box, use the double left-pointing arrow (&lt;&lt;) or the reset icon.\nTo find a specific species or group more quickly you can use the Search Species option to quickly narrow the options. Search for parts of species common names in the Search Species box by entering a term and clicking the search button. The platform will return a shorter list in the Speices options box of only species that contain a match to that search term.\nUse the Reset All Parameters button to reset all parameters for entire form.\n\n\n\n\n\nDiagram of selection and search tools available on the FOSS platofrom.\n\n\n\n\nFilter options:\n\nSurvey: Each survey has different in design, time series, and history. More information on each survey and their designs can be found in our annual data reports.\nYear: Surveys are not conducted in all years, so only data from the years for which the survey was conducted will be returned.\nSpecies: Common name of all species ever encountered in the survey. Find more information about these species in our survey code books.\n\n\nIn this example, we’ll select for 2022 eastern Bering Sea Pacific cod data. Here, we used the Search Species box to search for species with the term “cod” in their common names and selected “Pacific cod” from that shortened list.\n\n\n\n\n\n\nDiagram of selection and search tools available on the FOSS platofrom."
  },
  {
    "objectID": "content/foss-platform.html#select-data-format",
    "href": "content/foss-platform.html#select-data-format",
    "title": "Using the FOSS platform",
    "section": "Select data format",
    "text": "Select data format\nSelect from the below radio list of pre-designed output tables. Once you run the report, the user can further specify filter data and select columns of interest. The tables below will only include data from the selections made in the previous step.\n\nAll Data Fields: Presence and Absence (zero-filled): The most complete version of the data, including species, catch, haul, and environmental data. This data will include catch data for where species were caught and zeros for where the species were not caught. This is important for calculating catch-per-unit-effort data, preparing distribution plots (e.g., using the akgfmaps R package), and many statistical analyses.\nAll Data Fields: Presence-only (non-zero): The second most complete version of the data, including species, catch, haul, and environmental data. However, this data only includes catch data for where species were caught and does not include zeros for where the species were not caught. This will return smaller, more focused data and can be useful for quickly assessing how many species were caught or how many stations species were caught at.\nCatch data: Presence and Absence (zero-filled): This data set is similar to All Data Fields: Presence and Absence (zero-filled), but only includes catch and species data columns.\nCatch data: Presence-only (non-zero): This data set is similar to All Data Fields: Presence-only (non-zero), but only includes catch and species data columns.\nHaul Data: This data set only includes haul and environmental data collected from the survey. This data will only include one observation per haul event/station.\n\n\nIn this example, we’ll select All Data Fields: Presence and Absence (zero-filled).\n\n\n\n\n\n\nDiagram of the pre-set data format options."
  },
  {
    "objectID": "content/foss-platform.html#run-report",
    "href": "content/foss-platform.html#run-report",
    "title": "Using the FOSS platform",
    "section": "Run report",
    "text": "Run report\nClick the RUN REPORT button. Below the select and filter area, the results of your query will appear below the page in the format you selected. To change the format, make a different selection and run the report again. Further modifications to your results can be made by clicking on the Actions button above your data. Here you can download your data, select columns included in your results, and apply a variety of filters and mathematical tools.\n\n\n\n\n\nExample data returned from running the report."
  },
  {
    "objectID": "content/foss-api-r.html#ex.-1-load-the-first-25-rows-default-of-data",
    "href": "content/foss-api-r.html#ex.-1-load-the-first-25-rows-default-of-data",
    "title": "Access via API and R",
    "section": "Ex. 1: Load the first 25 rows (default) of data",
    "text": "Ex. 1: Load the first 25 rows (default) of data\n\n # install.packages(c(\"httr\", \"jsonlite\"))\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(dplyr)\n\n # link to the API\napi_link &lt;- \"https://apps-st.fisheries.noaa.gov/ods/foss/afsc_groundfish_survey/\"\n\nres &lt;- httr::GET(url = api_link)\n # res # Test connection\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\n # names(data)\ntibble::as_tibble(data$items) %&gt;% \n  dplyr::mutate_if(is.character, type.convert, as.is = TRUE) %&gt;%\n  dplyr::mutate(across(where(is.numeric), round, 3)) %&gt;%\n  head(3) %&gt;%\nflextable::flextable() %&gt;%\n    flextable::theme_zebra() %&gt;%\n    flextable::colformat_num(x = ., j = c(\"year\", \"cruise\", \"species_code\", \"tsn\", \"ak_survey_id\"), big.mark = \"\")\n\n\nEx. 1: Load the first 25 rows (default) of data.yearsrvysurveysurvey_idcruisehaulstratumstationvessel_namevessel_iddate_timelatitude_ddlongitude_ddspecies_codecommon_namescientific_nametaxon_confidencecpue_kghacpue_kgkm2cpue_kg1000km2cpue_nohacpue_nokm2cpue_no1000km2weight_kgcountbottom_temperature_csurface_temperature_cdepth_mdistance_fished_kmnet_width_mnet_height_marea_swept_haduration_hrtsnak_survey_idlinks2002AIAleutian Islands Bottom Trawl Survey522002016722307-63Vesteraalen9405/17/2002 18:56:5853.737-167.01695020feathery bryozoanEucratea loricataLow0.0171.7491,749.4450.04404.15.31871.56116.1127.252.5150.281558091917453[[data.frame]]2002AIAleutian Islands Bottom Trawl Survey522002016722307-63Vesteraalen9405/17/2002 18:56:5853.737-167.01679000squid unid.DecapodiformesHigh0.0222.2272,226.5673.181318.081318,080.930.05684.15.31871.56116.1127.252.5150.281917454[[data.frame]]2002AIAleutian Islands Bottom Trawl Survey522002016722307-63Vesteraalen9405/17/2002 18:56:5853.737-167.01624191shortfin eelpoutLycodes brevipesHigh0.0363.5783,578.4100.79579.52079,520.230.09024.15.31871.56116.1127.252.5150.281652581917455[[data.frame]]"
  },
  {
    "objectID": "content/foss-api-r.html#ex.-2-load-the-first-10000-rows-of-data",
    "href": "content/foss-api-r.html#ex.-2-load-the-first-10000-rows-of-data",
    "title": "Access via API and R",
    "section": "Ex. 2: Load the first 10000 rows of data",
    "text": "Ex. 2: Load the first 10000 rows of data\n\n# Not run because too big:\nres &lt;- httr::GET(url = paste0(api_link, \"?offset=0&limit=10000\"))\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\nprint(paste0(\"rows: \", dim(data$items)[1], \"; cols: \", dim(data$items)[2]))\n\n[1] \"rows: 10000; cols: 36\""
  },
  {
    "objectID": "content/foss-api-r.html#ex.-3-filter-by-year",
    "href": "content/foss-api-r.html#ex.-3-filter-by-year",
    "title": "Access via API and R",
    "section": "Ex. 3: Filter by Year",
    "text": "Ex. 3: Filter by Year\nShow all the data greater than the year 2020.\n\nres &lt;- httr::GET(url = paste0(api_link, '?q={\"year\":{\"$gt\":2020}}'))\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\n\nas_tibble(data$items) %&gt;% \n  mutate_if(is.character, type.convert, as.is = TRUE) %&gt;%\n  head(3) %&gt;%\n  dplyr::mutate(across(where(is.numeric), round, 3)) %&gt;%\n  dplyr::select(year, srvy, stratum, species_code, cpue_kgkm2) %&gt;%\nflextable::flextable() %&gt;%\n    flextable::theme_zebra() %&gt;%\n    flextable::colformat_num(x = ., j = c(\"year\", \"species_code\"), big.mark = \"\") \n\n\nEx. 3: Filter by Year.yearsrvystratumspecies_codecpue_kgkm22022AI793805400.3612022AI7934010.9032022AI793200061.661"
  },
  {
    "objectID": "content/foss-api-r.html#ex.-4-filter-by-species-name",
    "href": "content/foss-api-r.html#ex.-4-filter-by-species-name",
    "title": "Access via API and R",
    "section": "Ex. 4: Filter by species name",
    "text": "Ex. 4: Filter by species name\nShow all the data where the product name contains pollock Please note that here the word pollock is case sensitive.\nThe notation for finding a string is to use % around it. Since % is a reserved character in a URL, you have to replace % with %25.\n\nres &lt;- httr::GET(\n  url = paste0(api_link, '?q={\"common_name\":{\"$like\":\"%25pollock%25\"}}'))\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\n\nas_tibble(data$items) %&gt;% \n  mutate_if(is.character, type.convert, as.is = TRUE) %&gt;%\n  head(3) %&gt;%\n  dplyr::mutate(across(where(is.numeric), round, 3)) %&gt;%\n  dplyr::select(year, srvy, stratum, species_code, cpue_kgkm2) %&gt;%\nflextable::flextable() %&gt;%\n    flextable::theme_zebra() %&gt;%\n    flextable::colformat_num(x = ., j = c(\"year\", \"species_code\"), big.mark = \"\") \n\n\nEx. 4: Filter by species name.yearsrvystratumspecies_codecpue_kgkm22002AI72221740775.3222002AI7222174010,685.8062002AI721217400.640"
  },
  {
    "objectID": "content/foss-api-r.html#ex.-5-combination-of-year-and-name-filters",
    "href": "content/foss-api-r.html#ex.-5-combination-of-year-and-name-filters",
    "title": "Access via API and R",
    "section": "Ex. 5: Combination of year and name filters",
    "text": "Ex. 5: Combination of year and name filters\nShow all the data where years &gt; 2020 and the product name contains pollock\n\nres &lt;- httr::GET(\n  url = paste0(api_link, \n               '?q={\"year\":{\"$gt\":2020},\"common_name\":{\"$like\":\"%25pollock%25\"}}'))\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\n\nas_tibble(data$items) %&gt;% \n  mutate_if(is.character, type.convert, as.is = TRUE) %&gt;%\n  head(3) %&gt;%\n  dplyr::mutate(across(where(is.numeric), round, 3)) %&gt;%\n  dplyr::select(year, srvy, stratum, species_code, cpue_kgkm2) %&gt;%\nflextable::flextable() %&gt;%\n    flextable::theme_zebra() %&gt;%\n    flextable::colformat_num(x = ., j = c(\"year\", \"species_code\"), big.mark = \"\") \n\n\nEx. 5: Combination of year and name filters.yearsrvystratumspecies_codecpue_kgkm22022AI793217407,853.6322022AI721217407,235.0102022AI7222174022,754.334"
  },
  {
    "objectID": "content/foss-api-r.html#ex.-6-combination-of-year-srvy-stratum",
    "href": "content/foss-api-r.html#ex.-6-combination-of-year-srvy-stratum",
    "title": "Access via API and R",
    "section": "Ex. 6: Combination of year, srvy, stratum",
    "text": "Ex. 6: Combination of year, srvy, stratum\nShow all the data where year = 1989, srvy = “EBS”, and stratum is not equal to 81\n\nres &lt;- httr::GET(\n  url = paste0(api_link, '?q={\"year\":1989,\"srvy\":\"EBS\",\"stratum\":{\"$ne\":\"81\"}}'))\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\n\nas_tibble(data$items) %&gt;% \n  mutate_if(is.character, type.convert, as.is = TRUE) %&gt;%\n  head(3) %&gt;%\n  dplyr::mutate(across(where(is.numeric), round, 3)) %&gt;%\n  dplyr::select(year, srvy, stratum, species_code, cpue_kgkm2) %&gt;%\nflextable::flextable() %&gt;%\n    flextable::theme_zebra() %&gt;%\n    flextable::colformat_num(x = ., j = c(\"year\", \"species_code\"), big.mark = \"\") \n\n\nEx. 6: Combination of year, srvy, stratum.yearsrvystratumspecies_codecpue_kgkm21989EBS10665481.1641989EBS10693221.1641989EBS10430002.353"
  },
  {
    "objectID": "content/foss-api-r.html#ex.-7-visualize-cpue-data-in-distribution-map",
    "href": "content/foss-api-r.html#ex.-7-visualize-cpue-data-in-distribution-map",
    "title": "Access via API and R",
    "section": "Ex. 7: Visualize CPUE data in distribution map",
    "text": "Ex. 7: Visualize CPUE data in distribution map\nPacific cod catch-per-unit-effort estimates for NBS in 2021 and map constructed using akgfmaps.\n\n# res &lt;- httr::GET(\n#   url = paste0(api_link, \"?offset=0&limit=10000\"), \n#   query = list(year = 2021, srvy = \"EBS\", species_code = 30060))\nres &lt;- httr::GET(\n  url = paste0(api_link, '?q={\"year\":2021,\"srvy\":\"NBS\",\"species_code\":21720}'))\ndata_catch &lt;- jsonlite::fromJSON(base::rawToChar(res$content))$items %&gt;% \n  dplyr::select(stratum, station, cpue_kgkm2) \n\n# zero-fill data (imperfectly, but effective for this example)\nres &lt;- httr::GET(\n  url = paste0(api_link, '?q={\"year\":2021,\"srvy\":\"NBS\"}offset=0&limit=10000'))\ndata_haul &lt;- jsonlite::fromJSON(base::rawToChar(res$content))$items %&gt;% \n  dplyr::select(stratum, station, latitude_dd, longitude_dd) %&gt;%\n  dplyr::mutate(across(where(is.numeric), round, 3)) %&gt;% \n  dplyr::distinct()\n\ndata &lt;- dplyr::left_join(data_haul, data_catch) %&gt;% \n  dplyr::mutate(cpue_kgkm2 = ifelse(is.na(cpue_kgkm2), 0, cpue_kgkm2), \n                dplyr::across(dplyr::everything(), as.numeric)) \n\nflextable::flextable(data[1:3,]) %&gt;% \n  flextable::theme_zebra() \n\n\nEx. 7: Visualize CPUE data in distribution map.stratumstationlatitude_ddlongitude_ddcpue_kgkm28161.66434-172.26552,895.2588162.33740-173.17021,235.5457062.03713-171.65280.000\n\n\n\n# devtools::install_github(\"afsc-gap-products/akgfmaps\", build_vignettes = TRUE)\nlibrary(akgfmaps)\n\nfigure &lt;- akgfmaps::make_idw_map(\n  CPUE_KGHA = data$cpue_kgkm2, # calculates the same, regardless of units.  \n  LATITUDE = data$latitude_dd, \n  LONGITUDE = data$longitude_dd, \n  region = \"bs.north\", # Predefined EBS area\n  set.breaks = \"jenks\", # Gets Jenks breaks from classint::classIntervals()\n  in.crs = \"+proj=longlat\", # Set input coordinate reference system\n  out.crs = \"EPSG:3338\", # Set output coordinate reference system\n  grid.cell = c(20000, 20000), # 20x20km grid\n  key.title = \"Pacific Ocean perch\") # Include in the legend title\n\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n\nfigure$plot + \n  ggplot2::guides(fill=guide_legend(title = \"Pacific cod\\nCPUE (kg/km2)\"))\n\n\n\n\nEx. 7: Visualize CPUE data in distribution map."
  },
  {
    "objectID": "content/foss-api-py.html",
    "href": "content/foss-api-py.html",
    "title": "Access via API and Python",
    "section": "",
    "text": "{afscgap} Library Installation\n\nauthor: Sam Pottinger (sam.pottinger@berkeley.edu; GitHub::sampottinger) date: May 13, 2023\n\nThe third-party afscgap Python package interfaces with FOSS to access AFSC GAP data. It can be installed via pip:\n\n#The reticulate package provides a comprehensive set of tools for interoperability between Python and R. \nlibrary(reticulate)\n\n\npip install afscgap\npip install git+https://github.com/SchmidtDSE/afscgap.git@main\n\nFor more information on installation and deployment, see the library documentation.\n\n\nBasic query\nThis first example queries for Pacific glass shrimp (Pasiphaea pacifica) in the Gulf of Alaska in 2021. The library will automatically generate HTTP queries, converting from Python types to ORDS query syntax.\n\nimport afscgap\n\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\n\nresults = query.execute()\n\nThe results variable in this example is an iterator that will automatically perform pagination behind the scenes.\n\n\nIterating with a for loop\nThe easiest way to interact with results is a simple for loop. This next example determines the frequency of different catch per unit effort where Pacific glass shrimp were reported:\n\nimport afscgap\n\n# Mapping from CPUE to count\ncount_by_cpue = {}\n\n# Build query\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nresults = query.execute()\n\n# Iterate through results and count\nfor record in results:\n  cpue = record.get_cpue_weight(units='kg/ha')\n  cpue_rounded = round(cpue)\n  count = count_by_cpue.get(cpue_rounded, 0) + 1\n  count_by_cpue[cpue_rounded] = count\n\n# Print the result\nprint(count_by_cpue)\n\nNote that, in this example, only records with Pacific glass shrimp are included (“presence-only” data). See zero catch inference below. In other words, it reports on CPUE only for hauls in which Pacific glass shrimp were recorded, excluding some hauls like those in which Pacific glass shrimp were not found at all.\n\n\nIterating with functional programming\nA for loop is not the only option for iterating through results. List comprehensions and other functional programming methods can be used as well.\n\nimport statistics\n\nimport afscgap\n\n# Build query\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nresults = query.execute()\n\n# Get temperatures in Celsius\ntemperatures = [record.get_bottom_temperature(units='c') for record in results]\n\n# Take the median\nprint(statistics.median(temperatures))\n\nThis example reports the median temperature in Celcius for when Pacific glass shrimp was reported.\n\n\nLoad into Pandas\nThe results from the afscgap package are serializable and can be loaded into other tools like Pandas. This example loads Pacific glass shrimp from 2021 Gulf of Alaska into a data frame.\n\nimport pandas\n\nimport afscgap\n\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nresults = query.execute()\n\npandas.DataFrame(results.to_dicts())\n\nSpecifically, to_dicts provides an iterator over a dictionary form of the data that can be read into tools like Pandas.\n\n\nAdvanced filtering\nQueries so far have focused on filters requiring equality but range queries can be built as well.\n\nimport afscgap\n\n# Build query\nquery = afscgap.Query()\nquery.filter_year(min_val=2015, max_val=2019)   # Note min/max_val\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nresults = query.execute()\n\n# Sum weight\nweights = map(lambda x: x.get_weight(units='kg'), results)\ntotal_weight = sum(weights)\nprint(total_weight)\n\nThis example queries for Pacific glass shrimp data between 2015 and 2019, summing the total weight caught. Note that most users will likely take advantage of built-in Python to ORDS query generation which dictates how the library communicates with the API service. However, users can provide raw ORDS queries as well using manual filtering.\n\n\nZero-catch inference\nUntil this point, these examples use presence-only data. However, the afscgap package can infer negative or “zero catch” records as well.\n\nimport afscgap\n\n# Mapping from CPUE to count\ncount_by_cpue = {}\n\n# Build query\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nquery.set_presence_only(False)  # Added to earlier example\nresults = query.execute()\n\n# Iterate through results and count\nfor record in results:\n  cpue = record.get_cpue_weight(units='kg/ha')\n  cpue_rounded = round(cpue)\n  count = count_by_cpue.get(cpue_rounded, 0) + 1\n  count_by_cpue[cpue_rounded] = count\n\n# Print the result\nprint(count_by_cpue)\n\nThis example revisits the earlier snippet for CPUE counts but set_presence_only(False) directs the library to look at additional data on hauls, determining which hauls did not have Pacific glass shrimp. This lets the library return records for hauls in which Pacific glass shrimp were not found. This can be seen in differences in counts reported:\n\n\n\n\n\n\n\n\nRounded CPUE\nCount with set_presence_only(True)\nCount with set_presence_only(False)\n\n\n\n\n0 kg/ha\n44\n521\n\n\n1 kg/ha\n7\n7\n\n\n2 kg/ha\n1\n1\n\n\n\nPut simply, while the earlier example showed CPUE counts for hauls in which Pacific glass shrimp were seen, this revised example reports for all hauls in the Gulf of Alaska in 2021.\n\n\nMore information\nPlease see the API documentation for the Python library for additional details."
  },
  {
    "objectID": "content/foss-oracle-r.html",
    "href": "content/foss-oracle-r.html",
    "title": "Access via Oracle and R (AFSC only)",
    "section": "",
    "text": "If the user has access to the AFSC Oracle database, the user can use SQL developer to view and pull the FOSS public data directly from the GAP_PRODUCTS Oracle schema.\n\nConnect to Oracle from R\nMany users will want to access the data from Oracle using R. The user will need to install the RODBC R package and ask OFIS (IT) connect R to Oracle. Then, use the following code in R to establish a connection from R to Oracle:\nHere, the user can write in their username and password directly into the RODBC connect function. Never save usernames or passwords in scripts that may be intentionally or unintentionally shared with others. If no username and password is entered in the function, pop-ups will appear on the screen asking for the username and password.\n\n #' Define RODBC connection to ORACLE\n #'\n #' @param schema default = 'AFSC'. \n #'\n #' @return oracle channel connection\n #' @export\n #'\n #' @examples\n #' # Not run\n #' # channel &lt;- oracle_connect()\noracle_connect &lt;- function(\n    schema='AFSC', \n    username = NULL, \n    passowrd = NULL){(echo=FALSE)\n  \n  library(\"RODBC\")\n  library(\"getPass\")\n  if (is.null(username)) {\n    username &lt;- getPass(msg = \"Enter your ORACLE Username: \")\n  }\n  if (is.null(password)) {\n    password &lt;- getPass(msg = \"Enter your ORACLE Password: \")\n  }\n  channel  &lt;- RODBC::odbcConnect(\n    paste(schema),\n    paste(username),\n    paste(password), \n    believeNRows=FALSE)\n  return(channel)\n}\n\nchannel &lt;- oracle_connect()\n\n\n\nEx. 1: Join data\nTo join these tables in Oracle, you may use a variant of the following code:\n\nSELECT \nhh.YEAR,\nhh.SRVY,                 \nhh.SURVEY,\nhh.SURVEY_DEFINITION_ID,\nhh.SURVEY_NAME,\nhh.CRUISE,\nhh.CRUISEJOIN,           \nhh.HAUL,\nhh.HAULJOIN,\nhh.STRATUM,\nhh.STATION,\nhh.VESSEL_ID,\nhh.VESSEL_NAME,          \nhh.DATE_TIME,\nhh.LATITUDE_DD_START, \nhh.LONGITUDE_DD_START, \nhh.LATITUDE_DD_END,\nhh.LONGITUDE_DD_END, \nhh.BOTTOM_TEMPERATURE_C,\nhh.SURFACE_TEMPERATURE_C,\nhh.DEPTH_M,\ncc.SPECIES_CODE,\nss.ITIS,\nss.WORMS,\nss.COMMON_NAME,     \nss.SCIENTIFIC_NAME,\nss.ID_RANK,\nCASE WHEN cc.CPUE_KGKM2 IS NULL THEN 0 ELSE cc.CPUE_KGKM2 END AS CPUE_KGKM2,\nCASE WHEN cc.CPUE_NOKM2 IS NULL THEN 0 ELSE cc.CPUE_NOKM2 END AS CPUE_NOKM2,\nCASE WHEN cc.COUNT IS NULL THEN 0 ELSE cc.COUNT END AS COUNT,\nCASE WHEN cc.WEIGHT_KG IS NULL THEN 0 ELSE cc.WEIGHT_KG END AS WEIGHT_KG,\nCASE WHEN cc.TAXON_CONFIDENCE IS NULL THEN NULL ELSE cc.TAXON_CONFIDENCE END AS TAXON_CONFIDENCE,\nhh.AREA_SWEPT_KM2,       \nhh.DISTANCE_FISHED_KM,\nhh.DURATION_HR,          \nhh.NET_WIDTH_M,\nhh.NET_HEIGHT_M,\nhh.PERFORMANCE \nFROM GAP_PRODUCTS.FOSS_SURVEY_SPECIES sv\nFULL OUTER JOIN GAP_PRODUCTS.FOSS_SPECIES ss\nON sv.SPECIES_CODE = ss.SPECIES_CODE\nFULL OUTER JOIN GAP_PRODUCTS.FOSS_HAUL hh\nON sv.SURVEY_DEFINITION_ID = hh.SURVEY_DEFINITION_ID\nFULL OUTER JOIN GAP_PRODUCTS.FOSS_CATCH cc\nON sv.SPECIES_CODE = cc.SPECIES_CODE\nAND hh.HAULJOIN = cc.HAULJOIN\n\n\n\nEx. 2: Subset data\nOnce connected, pull and save (if needed) the tables into the R environment.\nTo pull a small subset of the data (especially since files like GAP_PRODUCTS.FOSS_CPUE_ZEROFILLED are so big), use a variation of the following code. Here, we are pulling EBS Pacific cod from 2010 - 2021:\n\n# Pull data\na &lt;- RODBC::sqlQuery(\nchannel = channel, \nquery = \n\"SELECT * FROM GAP_PRODUCTS.FOSS_CATCH cc\nJOIN GAP_PRODUCTS.FOSS_HAUL hh\nON cc.HAULJOIN = hh.HAULJOIN\nWHERE SRVY = 'EBS' \nAND SPECIES_CODE = 21720 -- 'Pacific cod' \nAND YEAR &gt;= 2010 \nAND YEAR &lt; 2021\")\n# Save table to local directory\nwrite.csv(x = a, file = \"ebs_pcod_2010-2020.csv\")"
  },
  {
    "objectID": "content/other-intro.html",
    "href": "content/other-intro.html",
    "title": "Product Outputs",
    "section": "",
    "text": "To accompany these data, we also produce data products to make using our data more accessible and straightforward.\n\n\n\nSurvey of products developed by GAPProductPoint of ContactGOA/AIPoint of ContactBSDescriptionDataFinalized bottom trawl dataNed LamanDuane StevensonNOAA-NMFS-AFSC-RACE-GAP bottom trawl data that has completed the post-survey internal QAQC process.Data requestsNancy RobersonNancy RobersonTo request a subset of the NOAA-NMFS-AFSC-RACE-GAP bottom trawl raw data or a data product.Species codebookNancy RobersonChris AndersonList of codes used for fish and invertebrates identified in NOAA-NMFS-AFSC-RACE-GAP Division surveys. Survey protocolsNancy RobersonNancy RobersonDocumentation of NOAA-NMFS-AFSC-RACE-GAP groundfish bottom trawl survey protocols.AnalysisDesign-based indices for target speciesNed LamanRebecca HaehnStandard design-based indices of biomass and abundance from NOAA-NMFS-AFSC-RACE-GAP bottom trawl survey data.Design-based age or length compositionNed LamanRebecca HaehnStandard design-based indices of size and age composition from NOAA-NMFS-AFSC-RACE-GAP bottom trawl survey data.Model-based indices, age comps (stock assessment), area occupied, and COG (ESP)Cecilia O'Leary Lewis BarnettSpatiotemporal model-based biomass indices, abundance indices, and age composition from NOAA-NMFS-AFSC-RACE-GAP bottom trawl survey data.Annual bottom and surface temperature summary (ESR, stock assessment)Cecilia O'LearySean Rohan &Lewis BarnettSummary metrics for bottom trawl bottom and surface temperatures relative to historical baseline.Salinity indicator (ESR in 2024)-Sean Rohan &Ned CokeletDeveloping salinity indicators (available in 2024).Bering Sea cold pool index and temperature data products (ESR, ESP, stock assessment)-Sean Rohan &Lewis BarnettCreate annual temperature rasters for the EBS, calculate the EBS cold pool index and temperature data products, and produce visualizations.Annual fish condition (ESR)Cecilia O'LearyBianca Prohaska &Sean RohanGroundfish morphometric condition for fish in the Bering Sea, Aleutian Islands, and Gulf of Alaska.Rockfish indices vs environmental gradients (ESR)Alexandra Dowlin-GOA/AI survey trends in distribution and abundance of 6 rockfishes across 3 environmental gradients in the North Pacific.Structure-Forming Invertebrates-Habitat Areas of Particular Concern (SFI-HAPC) (ESR)Ned Laman-Relative abundance of sponges, hydrocorals, soft corals, Gorgonians, anemones, and Pennatulaceans in GOA and AI surveys.Forage fishes (ESR)Ned Laman-Relative abundance of capelin, eulachon, sandfish, sand lance, and prickelbacks in GOA and AI surveys.Miscellaneous species (ESR)Ned LamanThaddeus BuserRelative abundance of echinoderms, poachers, shrimp and eelpouts in GOA and AI surveys.Jellies (ESR)Ned LamanThaddeus BuserRelative abundance of sea jellies in GOA and AI surveys.Essential fish habitatMegsie Siple Sean RohanHabitat maps for groundfish and crab based on species distribution models. Updated every five years.Visualization ToolsAlaska groundfish maps (CPUE, etc.)-Sean RohanVisualization tool for the Alaska survey regions.CommunicationAnnual survey data reportMegsie Siple &Bethany RiggleEmily Markowitz, Liz Dawson &Chris AndersonAlaska Fisheries Science Center NOAA Technical Memorandum summary of the survey progress and findings. These are available online and the latest publications for each survey are listed below (https://repository.library.noaa.gov/). ADF&G report of research activitiesAlexandra DowlinNicole Charriere &Rebecca HaehnReport on AI and GOA trawl survey fishing activity inside and outside of Alaska State waters.IPHC Report-Rebecca HaehnPlan team survey results presentationNed LamanDuane StevensonNOAA-NMFS-AFSC-RACE-GAP present their findings to the North Pacific Groundfish Plan Team; presentations, recordings, and attachments located here: https://www.npfmc.org/about-the-council/plan-teams/bsai-and-goa-groundfish/. Community highlights reportTBDEmily MarkowitzCompilation of NOAA-NMFS-AFSC-RACE-GAP survey findings for communities around Alaska. Bottom Trawl Survey Temperature and Progress MapsNed LamanEmily Markowitz, Liz Dawson &Chris AndersonNear real-time survey progress and ocean temperatures recorded during the Aleutian Islands, Gulf of Alaska, and Bering Sea Bottom Trawl Surveys."
  },
  {
    "objectID": "content/other-pkgs.html#r-packages",
    "href": "content/other-pkgs.html#r-packages",
    "title": "Open source code",
    "section": "R Packages",
    "text": "R Packages\n\nakgfmaps R package\nBttom trawl survey maps layers and plotting examples. POC: Sean Rohan\n\n\ncoldpool R package\nCold pool area and temperature data products for the Bering Sea. POC: Sean Rohan\n\n\nakfishcondition R package\nGroundfish morphometric condition indicators for fish in the Bering Sea, Aleutian Islands, and Gulf of Alaska. POC: Sean Rohan\n\n\ngapindex R package\nCalculation of Design-Based Indices of Abundance and Composition for AFSC GAP Bottom Trawl Surveys. POC: Zack Oyafuso and Margaret Siple"
  },
  {
    "objectID": "content/end-contact-us.html#suggestions-and-comments",
    "href": "content/end-contact-us.html#suggestions-and-comments",
    "title": "Contact us",
    "section": "Suggestions and comments",
    "text": "Suggestions and comments\nIf the data or metadata can be improved, please create a pull request, submit an issue to the GitHub organization or submit an issue to the code’s repository."
  },
  {
    "objectID": "content/end-run-notes.html",
    "href": "content/end-run-notes.html",
    "title": "Production run notes",
    "section": "",
    "text": "R Version Metadata\n\n\nR version 4.3.1 (2023-06-16 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.6   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.25    knitr_1.44        jsonlite_1.8.7    xfun_0.40        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.22    \n\n\n\nNOAA README\nThis repository is a scientific product and is not official communication of the National Oceanic and Atmospheric Administration, or the United States Department of Commerce. All NOAA GitHub project code is provided on an ‘as is’ basis and the user assumes responsibility for its use. Any claims against the Department of Commerce or Department of Commerce bureaus stemming from the use of this GitHub project will be governed by all applicable Federal law. Any reference to specific commercial products, processes, or services by service mark, trademark, manufacturer, or otherwise, does not constitute or imply their endorsement, recommendation or favoring by the Department of Commerce. The Department of Commerce seal and logo, or the seal and logo of a DOC bureau, shall not be used in any manner to imply endorsement of any commercial product or activity by DOC or the United States Government.\n\n\nNOAA License\nSoftware code created by U.S. Government employees is not subject to copyright in the United States (17 U.S.C. §105). The United States/Department of Commerce reserve all rights to seek and obtain copyright protection in countries other than the United States for Software authored in its entirety by the Department of Commerce. To this end, the Department of Commerce hereby grants to Recipient a royalty-free, nonexclusive license to use, copy, and create derivative works of the Software outside of the United States."
  },
  {
    "objectID": "content/end-data-constraints.html",
    "href": "content/end-data-constraints.html",
    "title": "Data constraints",
    "section": "",
    "text": "Access Constraints\nThere are no legal restrictions on access to the data. They reside in public domain and can be freely distributed.\nUser Constraints: Users must read and fully comprehend the metadata prior to use. Data should not be used beyond the limits of the source scale. Acknowledgement of AFSC Groundfish Assessment Program, as the source from which these data were obtained, in any publications and/or other representations of these data, is suggested."
  },
  {
    "objectID": "content/end-data-constraints.html#cite-this-data",
    "href": "content/end-data-constraints.html#cite-this-data",
    "title": "Data constraints",
    "section": "Cite this data",
    "text": "Cite this data\nUse the below bibtext citations, as cited in our group’s citation repository for citing the data created and maintained in this repo. Add “note = {Accessed: mm/dd/yyyy}” to append the day this data was accessed. Included here are AFSC RACE Groundfish and Shellfish Assessment Program’s:\n\nDesign-Based Production Data internal.\nAFSC RACE Groundfish Data for AKFIN.\nPublic Data hosted on the Fisheries One Stop Shop (FOSS) Data Platform.\n\n\n\n\\n@misc{GAPProducts,\\n  author = {{NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program}},\\n  year = {2023}, \\n  title = {AFSC Goundfish Assessment Program Design-Based Production Data},\\n  howpublished = {https://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys},\\n  publisher = {{U.S. Dep. Commer.}},\\n  copyright = {Public Domain} \\n}\\n\\n@misc{FOSSAFSCData,\\n  author = {{NOAA Fisheries Alaska Fisheries Science Center}},\\n  year = {2023}, \\n  title = {Fisheries One Stop Shop Public Data: RACE Division Bottom Trawl Survey Data Query},\\n  howpublished = {https://www.fisheries.noaa.gov/foss},\\n  publisher = {{U.S. Dep. Commer.}},\\n  copyright = {Public Domain} \\n}\\n\\n@misc{GAPakfin,\\n  author = {{Alaska Fisheries Information Network (AKFIN)}}, \\n  institution = {{NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program}},\\n  year = {2023}, \\n  title = {AFSC Goundfish Assessment Program Design-Based Production Data},\\n  howpublished = {https://www.psmfc.org/program/alaska-fisheries-information-network-akfin},\\n  publisher = {{U.S. Dep. Commer.}},\\n  copyright = {Public Domain} \\n}"
  },
  {
    "objectID": "content/end-acknowledgements.html",
    "href": "content/end-acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "Community Acknowledgments\nWe would like to thank the many communities of Alaska and their members who have helped contribute to this body of work. The knowledge, experiences, and insights have been instrumental in expanding the scope of our science and knowledge to encompass the many issues that face this important ecosystem. We appreciate feedback from those residing in the region that are willing to share their insights and participation in an open dialog about how we can improve our collective knowledge of the ecosystem and the region.\nThis quarto book is based off the NOAA-quarto-book GitHub repo designed by Eli Holmes.\nThis repo and GitHub Action was based on the tutorial by Openscapes quarto-website-tutorial by Julia Lowndes and Stefanie Butland."
  },
  {
    "objectID": "content/end-acknowledgements.html#partners",
    "href": "content/end-acknowledgements.html#partners",
    "title": "Acknowledgments",
    "section": "Partners",
    "text": "Partners\nScientists from the Alaska Fisheries Science Center conduct these bottom trawl surveys with participation from the Alaska Department of Fish & Game (ADF&G), the International Pacific Halibut Commission (IPHC), and universities. This research is conducted on chartered fishing vessels."
  },
  {
    "objectID": "content/end-acknowledgements.html#collaborators",
    "href": "content/end-acknowledgements.html#collaborators",
    "title": "Acknowledgments",
    "section": "Collaborators",
    "text": "Collaborators\nOur data are used in many annual publications, including but not limited to the list below:\n\nAlaska Stock Assessments\nNorth Pacific Groundfish Stock Assessment and Fishery Evaluation Reports\nGroundfish Economic Status Reports for the Gulf of Alaska and Bering Sea and Aleutian Islands\nAlaska Marine Ecosystem Status Report Database\nSoutheast Alaska Coastal Monitoring Survey Reports\nAlaska Fisheries Life History Database\nEssential Fish Habitat Research Plan in Alaska"
  },
  {
    "objectID": "content/end-refs.html",
    "href": "content/end-refs.html",
    "title": "References",
    "section": "",
    "text": "Alaska Fisheries Information Network (AKFIN). (2023). AFSC goundfish\nassessment program design-based production data. NOAA\nFisheries Alaska Fisheries Science Center, Goundfish Assessment\nProgram;\nhttps://www.psmfc.org/program/alaska-fisheries-information-network-akfin;\nU.S. Dep. Commer.\n\n\nHoff, G. R. (2016). Results of the 2016 eastern Bering\nSea upper continental slope survey of groundfishes and\ninvertebrate resources (NOAA Tech. Memo. NOAA-AFSC-339). U.S.\nDep. Commer. https://doi.org/10.7289/V5/TM-AFSC-339\n\n\nMarkowitz, E. H., Dawson, E. J., Anderson, A. B., Rohan, S. K.,\nCharriere, N. E., Prohaska, B. K., and Stevenson, D. E. (2023).\nResults of the 2022 eastern and northern Bering Sea\ncontinental shelf bottom trawl survey of groundfish and invertebrate\nfauna (NOAA Tech. Memo. NMFS-AFSC-469; p. 213). U.S. Dep.\nCommer.\n\n\nNOAA Fisheries Alaska Fisheries Science Center. (2023). Fisheries\none stop shop public data: RACE division bottom trawl survey data\nquery. https://www.fisheries.noaa.gov/foss; U.S. Dep.\nCommer.\n\n\nNOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment\nProgram. (2023). AFSC goundfish assessment program design-based\nproduction data.\nhttps://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys;\nU.S. Dep. Commer.\n\n\nVon Szalay, P. G., and Raring, N. W. (2018). Data report: 2017 Gulf of Alaska bottom trawl survey (NOAA\nTech. Memo. NMFS-AFSC-374). U.S. Dep. Commer. https://doi.org/10.7289/V5/TM-AFSC-374\n\n\nVon Szalay, P. G., and Raring, N. W. (2020). Data report: 2018\nAleutian Islands bottom trawl survey (NOAA Tech. Memo.\nNMFS-AFSC-409). U.S. Dep. Commer. https://doi.org/10.25923/qe5v-fz70"
  }
]