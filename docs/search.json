[
  {
    "objectID": "index.html#afsc-bottom-trawl-surveys",
    "href": "index.html#afsc-bottom-trawl-surveys",
    "title": "GAP Production Data Documentation",
    "section": "AFSC Bottom Trawl Surveys",
    "text": "AFSC Bottom Trawl Surveys\nAFSC bottom trawl surveys are conducted by the AFSC’s Groundfish Assessment Program and Shellfish Assessment Program and are conducted in the Gulf of Alaska, Aleutian Islands, Eastern Bering Sea Slope, Eastern Bering Sea Shelf, and Northern Bering Sea. Each survey is a multispecies survey that collects data on the distribution, abundance, and biological characteristics of fish, crab, and other resources to inform groundfish stock assessment and management. These fishery-independent surveys are conducted in the summer aboard contracted commercial fishing vessels. Specifics regarding each of the surveys can be found below.\n\n\n\nSorting and weighing fish on deck on the 2022 Bering Sea groundfish survey aboard the F/V Alaska Knight. Credit: Emily Markowitz/NOAA Fisheries."
  },
  {
    "objectID": "index.html#documentation-objective",
    "href": "index.html#documentation-objective",
    "title": "GAP Production Data Documentation",
    "section": "Documentation Objective",
    "text": "Documentation Objective\nAs part of our commitment to open science, reproducibility, and transparency, we provide this metadata guide to compliment our public-domain data.\n\nPlease consider this resource to be a Living Document. The code in this repository is regularly being updated and improved. Please refer to releases for finalized products and project milestones.\n\n\nAt this time, these master production and AKFIN tables are provisional and we are welcoming feedback before the 2024 survey season. We look forward to hearing from you. Do not hesitate to reach out (to us at either nmfs.afsc.gap.metadata@noaa.gov or GitHub issues, especially if you find discrepancies in the data or want to suggest improvements to infrastructure. Thank you in advance for your collaboration and partnership with us as we develop our future data universe."
  },
  {
    "objectID": "index.html#user-resources",
    "href": "index.html#user-resources",
    "title": "GAP Production Data Documentation",
    "section": "User Resources",
    "text": "User Resources\n\nGroundfish Assessment Program Bottom Trawl Surveys\nAFSC’s Resource Assessment and Conservation Engineering Division\nAll AFSC Research Surveys\nSurvey code books\nPublications and Data Reports\nResearch Surveys conducted at AFSC"
  },
  {
    "objectID": "index.html#cite-this-data",
    "href": "index.html#cite-this-data",
    "title": "GAP Production Data Documentation",
    "section": "Cite this data",
    "text": "Cite this data\nUse the below bibtext citations, as cited in our group’s citation repository for citing the data created and maintained in this repo. Add “note = {Accessed: mm/dd/yyyy}” to append the day this data was accessed. Included here are AFSC RACE Groundfish and Shellfish Assessment Program’s:\n\nDesign-Based Production Data (internal) (NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program, 2024).\n\nAFSC RACE Groundfish Data for AKFIN (Alaska Fisheries Information Network (AKFIN), 2024).\nPublic Data hosted on the Fisheries One Stop Shop (FOSS) Data Platform (NOAA Fisheries Alaska Fisheries Science Center, 2024).\n\n\n\n\n@misc{GAPProducts,\n  author = {{NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program}},\n  year = {2023}, \n  title = {AFSC Goundfish Assessment Program Design-Based Production Data},\n  howpublished = {https://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys},\n  publisher = {{U.S. Dep. Commer.}},\n  copyright = {Public Domain} \n}\n\n@misc{FOSSAFSCData,\n  author = {{NOAA Fisheries Alaska Fisheries Science Center}},\n  year = {2023}, \n  title = {Fisheries One Stop Shop Public Data: RACE Division Bottom Trawl Survey Data Query},\n  howpublished = {https://www.fisheries.noaa.gov/foss},\n  publisher = {{U.S. Dep. Commer.}},\n  copyright = {Public Domain} \n}\n\n@misc{GAPakfin,\n  author = {{Alaska Fisheries Information Network (AKFIN)}}, \n  institution = {{NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program}},\n  year = {2023}, \n  title = {AFSC Goundfish Assessment Program Design-Based Production Data},\n  howpublished = {https://www.psmfc.org/program/alaska-fisheries-information-network-akfin},\n  publisher = {{U.S. Dep. Commer.}},\n  copyright = {Public Domain} \n}"
  },
  {
    "objectID": "index.html#access-constraints",
    "href": "index.html#access-constraints",
    "title": "GAP Production Data Documentation",
    "section": "Access Constraints",
    "text": "Access Constraints\nThere are no legal restrictions on access to the data. They reside in public domain and can be freely distributed.\nUser Constraints: Users must read and fully comprehend the metadata and code of conduct prior to use. Data should not be used beyond the limits of the source scale. Acknowledgement of AFSC Groundfish Assessment Program, as the source from which these data were obtained, in any publications and/or other representations of these data, is suggested."
  },
  {
    "objectID": "index.html#suggestions-and-comments",
    "href": "index.html#suggestions-and-comments",
    "title": "GAP Production Data Documentation",
    "section": "Suggestions and comments",
    "text": "Suggestions and comments\nIf the data or metadata can be improved, please create a pull request, submit an issue to the GitHub organization or submit an issue to the code’s repository."
  },
  {
    "objectID": "index.html#noaa-readme",
    "href": "index.html#noaa-readme",
    "title": "GAP Production Data Documentation",
    "section": "NOAA README",
    "text": "NOAA README\nThis repository is a scientific product and is not official communication of the National Oceanic and Atmospheric Administration, or the United States Department of Commerce. All NOAA GitHub project code is provided on an ‘as is’ basis and the user assumes responsibility for its use. Any claims against the Department of Commerce or Department of Commerce bureaus stemming from the use of this GitHub project will be governed by all applicable Federal law. Any reference to specific commercial products, processes, or services by service mark, trademark, manufacturer, or otherwise, does not constitute or imply their endorsement, recommendation or favoring by the Department of Commerce. The Department of Commerce seal and logo, or the seal and logo of a DOC bureau, shall not be used in any manner to imply endorsement of any commercial product or activity by DOC or the United States Government."
  },
  {
    "objectID": "index.html#noaa-license",
    "href": "index.html#noaa-license",
    "title": "GAP Production Data Documentation",
    "section": "NOAA License",
    "text": "NOAA License\nSoftware code created by U.S. Government employees is not subject to copyright in the United States (17 U.S.C. §105). The United States/Department of Commerce reserve all rights to seek and obtain copyright protection in countries other than the United States for Software authored in its entirety by the Department of Commerce. To this end, the Department of Commerce hereby grants to Recipient a royalty-free, nonexclusive license to use, copy, and create derivative works of the Software outside of the United States.\n\n\n\n\nAlaska Fisheries Information Network (AKFIN). (2024). AFSC goundfish assessment program design-based production data. NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program; https://akfinbi.psmfc.org/analytics/; U.S. Dep. Commer. https://www.psmfc.org/program/alaska-fisheries-information-network-akfin\n\n\nNOAA Fisheries Alaska Fisheries Science Center. (2024). Fisheries one stop shop public data: RACE division bottom trawl survey data query. https://www.fisheries.noaa.gov/foss; U.S. Dep. Commer.\n\n\nNOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program. (2024). AFSC goundfish assessment program design-based production data. https://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys; U.S. Dep. Commer."
  },
  {
    "objectID": "content/intro-survey-background.html#what-we-do",
    "href": "content/intro-survey-background.html#what-we-do",
    "title": "Survey Background",
    "section": "What we do",
    "text": "What we do"
  },
  {
    "objectID": "content/intro-survey-background.html#who-is-conducting-the-research",
    "href": "content/intro-survey-background.html#who-is-conducting-the-research",
    "title": "Survey Background",
    "section": "Who is conducting the research?",
    "text": "Who is conducting the research?\nScientists from the Alaska Fisheries Science Center’s Groundfish Assessment Program (GAP) conduct these bottom trawl surveys with participation from the Alaska Department of Fish & Game (ADF&G), the International Pacific Halibut Commission (IPHC), universities, and other organizations. This research is conducted primarily on chartered fishing vessels."
  },
  {
    "objectID": "content/intro-survey-background.html#what-is-the-research-objective",
    "href": "content/intro-survey-background.html#what-is-the-research-objective",
    "title": "Survey Background",
    "section": "What is the research objective?",
    "text": "What is the research objective?\nLearn more about the program. The objectives of these surveys are to:\n\nmonitor the population and environmental trends in the marine ecosystem of the Bering Sea, Aleutian Islands, and Gulf of Alaska,\nproduce fishery-independent biomass (weight) and abundance (number) estimates for commercially important fish and crab species, and\ncollect other biological and environmental data for use in ecosystem-based fishery management."
  },
  {
    "objectID": "content/intro-survey-background.html#who-is-conducting-the-research-1",
    "href": "content/intro-survey-background.html#who-is-conducting-the-research-1",
    "title": "Survey Background",
    "section": "Who is conducting the research?",
    "text": "Who is conducting the research?\nScientists from the Alaska Fisheries Science Center conduct these bottom trawl surveys with participation from the Alaska Department of Fish & Game (ADF&G), the International Pacific Halibut Commission (IPHC), and universities. This research is conducted on chartered fishing vessels."
  },
  {
    "objectID": "content/intro-survey-background.html#bottom-trawl-surveys-and-regions",
    "href": "content/intro-survey-background.html#bottom-trawl-surveys-and-regions",
    "title": "Survey Background",
    "section": "Bottom trawl surveys and regions",
    "text": "Bottom trawl surveys and regions\n\nEach survey conducted by the Groundfish Assessment Program are multispecies bottom trawl surveys. We collect environmental and biological data to assess how climate variability and loss of sea ice are affecting bottom-dwelling marine life on the Bering Sea shelf. We monitor trends in the distribution (location and movement patterns) and abundance of groundfish and crab species as well as oceanographic data (e.g., water temperature, depth). We collect biological information such as organism weight, length, stomachs to learn about diets, and otoliths to determine fish ages. We use this information in annual stock assessments and to assess the state of the ecosystem. This research is conducted on fishing industry contract vessels.\n\n\n\nSurvey summary statsSurveySurvey Definition IDYearsDepth (m)Area (km2)# Statistical Areas# Possible StationsAleutian Islands Bottom Trawl Survey522022 - 1980 (16)1 - 50064,415.0801,312Eastern Bering Sea Slope Bottom Trawl Survey782016 - 2002 (6)201 - 1,20032,861.337Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey982023 - 1982 (41)1 - 200492,989.928515Gulf of Alaska Bottom Trawl Survey472023 - 1984 (18)1 - 1,000313,784.9376,939Northern Bering Sea Crab/Groundfish Survey - Eastern Bering Sea Shelf Survey Extension1432023 - 2010 (6)1 - 100198,866.84144\n\n\n\nAleutian Islands\n(Von Szalay et al., 2023)\n\nUpper Continental Slope of the Aleutian Islands from Unimak Pass to Stalemate Bank\nTriennial (1990s)/Biennial since 2000 in even years, since 1992\nModified Index-Stratified Random of Successful Stations Survey Design\nImportant commercial fish species include Atka mackerel, Pacific ocean perch, walleye pollock, Pacific cod, sablefish, and other rockfish species.\n\n\n\nGulf of Alaska\n(Von Szalay and Raring, 2018)\n\nContinental Shelf and Upper Slope of the Gulf of Alaska extending from the Islands of Four Mountains 2,300 km east to Dixon Entrance\nTriennial (1990s)/Biennial since 2001 in odd years, since 1991\nStratified Random Survey Design\nImportant commercial species in the Gulf of Alaska include Pacific ocean perch, walleye pollock, Pacific cod, flatfish, and other rockfish species.\n\n\n\nEastern Bering Sea Shelf\n(Markowitz et al., 2023)\n\nThe continental shelf of the eastern Bering Sea from the Aleutian Islands to the Bering Strait\nConducted annually since 1982.\nUses a stratified systematic sampling survey design with fixed stations at center of 20 x 20 nm grid.\nSimilar in design to the northern Bering Sea shelf bottom trawl survey.\nFocus species for the Bering Sea include walleye pollock, Pacific cod, Greenland turbot, yellowfin sole, northern rock sole, red king crab, and snow and Tanner crabs.\n\n\n\n\n\n\nStrata used in the Eastern Bering Sea Survey.\n\n\n\n\n\n\nNorthern Bering Sea\n(Markowitz et al., 2023)\n\nThe continental shelf of the northern Bering Sea, including the area north of St. Lawrence Island and Norton Sound\nBiennial/Annual; conducted intermittently since 2010\nUses a stratified systematic sampling survey design with fixed stations at center of 20 x 20 nm grid.\nSimilar in design to the eastern Bering Sea shelf bottom trawl survey.\n\n\n\nEastern Bering Sea Upper Continental Slope\n(Hoff, 2016)\n\nThe eastern Bering Sea upper continental slope survey area extends from Unalaska and Akutan Islands to the U.S.-Russian Maritime Boundary at 61° N near the International Date Line (166° E to 180° W) at depths from 200 to 1,200 m\nConducted intermittently since 2002 (funding dependent)\nModified Index-Stratified Random of Successful Stations Survey Design\nFocus species for the Bering Sea slope include giant grenadier, Pacific ocean perch, popeye grenadier, walleye pollock, and arrowtooth flounder.\n\n\n\n\n\n\nStrata used in the Bering Sea Slope Survey.\n\n\n\n\n\n\n\n\nHoff, G. R. (2016). Results of the 2016 eastern Bering Sea upper continental slope survey of groundfishes and invertebrate resources (NOAA Tech. Memo. NOAA-AFSC-339). U.S. Dep. Commer. https://doi.org/10.7289/V5/TM-AFSC-339\n\n\nMarkowitz, E. H., Dawson, E. J., Anderson, A. B., Rohan, S. K., Charriere, N. E., Prohaska, B. K., and Stevenson, D. E. (2023). Results of the 2022 eastern and northern Bering Sea continental shelf bottom trawl survey of groundfish and invertebrate fauna (NOAA Tech. Memo. NMFS-AFSC-469; p. 213). U.S. Dep. Commer.\n\n\nVon Szalay, P. G., and Raring, N. W. (2018). Data report: 2017 Gulf of Alaska bottom trawl survey (NOAA Tech. Memo. NMFS-AFSC-374). U.S. Dep. Commer. https://doi.org/10.7289/V5/TM-AFSC-374\n\n\nVon Szalay, P. G., Raring, N. W., Siple, M. C., Dowlin, A. N., Riggle, B. C., and Laman, E. A. and. (2023). Data report: 2022 Aleutian Islands bottom trawl survey (AFSC Processed Rep. No. 2023-07; p. 230). U.S. Dep. Commer. https://doi.org/10.25923/85cy-g225"
  },
  {
    "objectID": "content/intro-workflow.html#operational-product-development-timeline",
    "href": "content/intro-workflow.html#operational-product-development-timeline",
    "title": "Workflow",
    "section": "Operational Product Development Timeline",
    "text": "Operational Product Development Timeline\nOver the course of the year, the survey team is developing a variety of different data products. Planning and preparation for surveys happens in the late winter and spring, surveys occur in the summer, data validation takes place over the course of the survey and after the survey, and data products are produced through fall and late winter.\n\n\n\nOperational product development timeline. JanuaryFebruaryMarchAprilMayJuneJulyAugustSeptemberOctoberNovemberDecemberSurveys1111Planning1111111Development11111111Deployment (survey deliverables)1111Deployment (survey operations)1111Triage (fixing bugs and errors)111111111111User feedback and brainstorming111111111111"
  },
  {
    "objectID": "content/intro-workflow.html#data-workflow-from-boat-to-production",
    "href": "content/intro-workflow.html#data-workflow-from-boat-to-production",
    "title": "Workflow",
    "section": "Data workflow from boat to production",
    "text": "Data workflow from boat to production\nOrganisms first need to be collected aboard the vessel before data can be entered into tablets.\n\n\n\n\n\n\nflowchart \n  A1[Net and catch\\ntotal weight/volume] --&gt; A2\n  A1 --&gt; |Catch tablet|BB\n  A2[Fish are collected and\\ndumped on the table] --&gt; A3[Initial on deck\\nsampling decisions\\n and sort by\\nspecies and mix]\n  P1[Specimen bag and tag] --&gt; P5[Observer collections]\n  P1 --&gt; P6[Museum collections]\n  P1 --&gt; P7[Research samples]\n  P2[SAT/PAT fish and crab tagging]\n  P3[Species condition]\n  P4[Genetics]\n  A3 --&gt; C1[Crab:\\nSex, weight]\n  A3 --&gt; C2[Fish, size varying:\\nWeight, sex, length]\n  A3 --&gt; |Catch tablet|C3[Fish, small:\\nWeight, sex]\n  A3 --&gt; C4[Invertebrates, colonial:\\nWeight]\n  A3 --&gt; C5[Invertebrates, other:\\nWeight, count]\n  C1 --&gt; |Crab tablet|S1[Length, width, weight, \\nshell condition]\n  C2 --&gt; |Specimen tablet|S2[Otolith, length, width, \\nweight, sex]\n  C2 --&gt; |Length tablet|S3[Length, sex]\n  C2 --&gt; |Stomach tablet|S4[Diet/stomach samples]\n  V1[Fish collections in formalin 10%]\n  V2[Invertebrate collections in ethanol]\n  subgraph AA[Net on deck]\n  A1\n  A2\n  A3\n  subgraph BB[Benthic bag]\n  B[Identify,\\npresence/absence]\n  end\n  end\n  subgraph CC[Bag composition data]\n  C1\n  C2\n  C3\n  C4\n  C5\n  subgraph VV[Voucher collections]\n  V1\n  V2\n  end\n  end\n  subgraph SS[Individual specimen data]\n  S1\n  S2\n  S3\n  S4\n  subgraph PP[Non-core science project requests]\n  P1\n  P2\n  P3\n  P4\n  P5\n  P6\n  P7\n  end\n  end\n  style AA fill:white,::\n  style SS fill:beige,::\n  style BB fill:beige,::\n  style CC fill:beige,::\n  style PP fill:white,::\n  style VV fill:white,::\n\n\nFigure 2.1: Simplified boat deck processing workflow.\n\n\n\n\nThe objective of this process is to take raw data, QA/QC and clean these data, curate standard data products for these survey. Please note, through this process we are not providing “data” (what we consider lower level data material; see the data levels section below) but “data products”, which is intended to facilitate the most fool-proof standard interpretation of the data. These data products only use data from standard and validated hauls, and has undergone careful review.\nOnce survey data collected on the vessel has been checked and validated, the gap_products/code/run.R script is used to orchestrate a sequence of programs that calculate the standard data products resulting from the NOAA AFSC GAP bottom trawl surveys. Standard data products are the CPUE, BIOMASS, SIZECOMP, and AGECOMP tables in the GAP_PRODUCTS Oracle schema. The tables are slated to be updated twice a year: once after the survey season following finalization of that summer’s bottom trawl survey data to incorporate the new catch, size, and effort data and once prior to an upcoming survey to incorporate new age data that were processed after the prior summer’s survey season ended. This second pre-survey production run will also incorporate changes in the data due to the specimen voucher process as well as other post-hoc changes in the survey data.\n\nThe data from these surveys constitute a living data set so we can continue to provide the best available data to all partners, stakeholders, and fellow scientists.\n\n\n\n\n\n\n\nflowchart LR\n  A([Catch data\\ndeck tablet]) --&gt; B1[METIS Biological\\ndata editing\\nsoftware]\n  A1([Length data\\ndeck tablets]) --&gt; B1\n  A2([Specimen data\\ndeck tablet]) --&gt; B1\n  A3([Haul performance w/ Marport sensors]) --&gt; B2[Wheelhouse &\\nCalyposo \\nhaul data] \n  A4([CTD]) --&gt; B2\n  A5([sea state\\nobersvations]) --&gt; B2\n  A6([HOBO bottom\\ncontact sensor]) --&gt; B2\n  A7{{navmaps\\nR package\\nfor navigation}} --&gt; B2\n  B1 --&gt; C[GIDES &\\nRACE_EDIT\\nOracle schema\\n& whole-survey\\nreview &\\ndata checking]\n  B2 --&gt; C\n  C --&gt; D[RACEBASE\\nand RACE_DATA\\nOracle schemata]\n  D1{{gapindex R package}} --&gt; F[Public Data Product:\\ntables in\\nGAP_PRODUCTS\\nOracle schema]\n  D2{{gap_products\\nR scripts}} --&gt; F\n  D --&gt; D1\n  D1 --&gt; D2\n  D --&gt; F\n  subgraph AA[Data Level 0: Raw]\n  A\n  A1\n  A2\n  A3\n  A4\n  A5\n  A6\n  A7\n  end\n  subgraph BB[Data Level 1:\\nQA/QC'ed data]\n  B1\n  B2\n  end\n  subgraph CC[Data Level 2:\\nAnalysis ready product for internal use]\n  C\n  D\n  end\n  subgraph FF[Data Level 3:\\nAnalysis ready product\\nfor external/public use]\n  F\n  end\n  style AA fill:beige,::\n  style BB fill:white,::\n  style CC fill:beige,::\n  style FF fill:white,::\n\n\nFigure 2.2: Simplified data workflow from boat to production.\n\n\n\n\nDuring each data product run cycle:\n\nVersions of the tables in GAP_PRODUCTS are locally imported within the gap_products repository to compare with the updated production tables. Any changes to a production table will be compared and checked to make sure those changes are intentional and documented.\nUse the gapindex R package to calculate the four major standard data products: CPUE, BIOMASS, SIZECOMP, AGECOMP. These tables are compared and checked to their respective locally saved copies and any changes to the tables are vetted and documented. These tables are then uploaded to the GAP_PRODUCTS Oracle schema.\nCalculate the various materialized views for AKFIN and FOSS purposes. Since these are derivative of the tables in GAP_PRODUCTS as well as other base tables in RACEBASE and RACE_DATA, it is not necessary to check these views in addition to the data checks done in the previous steps.\n\n\n\n\n\n\n\nflowchart\n  subgraph AA[Data Level 4]\n  A[GAP_PRODUCTS\\nOracle data\\nproduct tables] --&gt; C[Data process\\nreports &\\npresentations]\n  A --&gt; G3{{esrindex R package}}\n  G3 --&gt; G1[ESP: Ecosystem\\nStatus Reports]\n  G3 --&gt; G2[ESR: Ecosystem\\nand Socioeconomic\\nProfiles]\n  G3 --&gt; C\n  G3 --&gt; G4[Stock assessment\\nrisk assessment\\ntables]\n  A --&gt; D[Outreach]\n  D --&gt; E[Plan Team\\nPresentations]\n  D --&gt; F[Community\\nHighlight\\nDocuments]\n  D --&gt; H[Survey progress\\n& temperature maps]\n  A --&gt; I[Data Platforms]\n  I --&gt; J[AKFIN: Alaska\\nFisheries\\nInformation\\nNetwork]\n  I --&gt; K[FOSS: Fisheries One\\nStop Shop]\n  I --&gt; L{{afscgap\\nPython package}}\n  A --&gt; M[Model-Based\\nIndices]\n  M --&gt; N{{VAST/tinyVAST}}\n  M --&gt; O{{sdmTMB}}\n  M --&gt; P[EFH: Essential\\nFish Habitat]\n  F\n  end\n  style AA fill:beige,::\n\n\n\nFigure 2.3: Major end-users of the GAP data product tables."
  },
  {
    "objectID": "content/intro-workflow.html#data-levels",
    "href": "content/intro-workflow.html#data-levels",
    "title": "Workflow",
    "section": "Data levels",
    "text": "Data levels\nGAP produces numerous data products that are subjected to different levels of processing, ranging from raw to highly-derived. The suitability of these data products for analysis varies and there is ambiguity about which data products can be used for which purpose. This ambiguity can create challenges in communicating about data products and potentially lead to misunderstanding and misuse of data. One approach to communicating about the level of processing applied to data products and their suitability for analysis is to describe data products using a Data Processing Level system. Data Processing Level systems are widely used in earth system sciences to characterize the extent of processing that has been applied to data products. For example, the NOAA National Centers for Environmental Information (NCEI) Satellite Program uses a Data Processing Level system to describe data on a scale of 0-4, where Level 0 is raw data and Level 4 is model output or results from analysis. Example of how NASA remote sensing data products are shared through a public data portal with levels of data processing and documentation.\nFor more information, see Sean Rohan’s October 2022 SCRUGS presentation on the topic.\n\nLevel 0: Raw and unprocessed data. Ex: Data on the G drive, some tables in RACE_DATA\nLevel 1: Data products with QA/QC applied that may or may not be expanded to analysis units, but either not georeferenced or does not include full metadata. Ex: Some tables in RACE_DATA and RACEBASE\nLevel 2: Analysis-ready data products that are derived for a standardized extent and account for zeros and missing/bad data. Ex: CPUE tables, some data products in public-facing archives and repositories\nLevel 3: Data products that are synthesized across a standardized extent, often inputs in a higher-level analytical product. Ex: Abundance indices, some data products in public-facing archives and repositories\nLevel 4: Analytically generated data products that are derived from lower-level data, often to inform management. Ex: Biological reference points from stock assessments, Essential Fish Habitat layers, indicators in Ecosystem Status Reports and Ecosystem and Socioeconomic Profiles"
  },
  {
    "objectID": "content/intro-news.html#newschange-logs",
    "href": "content/intro-news.html#newschange-logs",
    "title": "News",
    "section": "News/change logs",
    "text": "News/change logs\n– GAP_PRODUCTS ChangeLog (last produced on 2024-02-29) using gapindex v2.2.0: A new version of gapindex 2.2.0 was used for this production run and now accesses taxonomic information from RACEBASE.SPECIES instead of GAP_PRODUCTS.TAXONOMIC_CLASSIFICATION. As a result, there will be some SPECIES_CODE values that are supported due to slight differences between the two tables. Discussion in this github issue #54. As a result there are new cpue records for SPECIES_CODE values 22290 and 22292 and removed cpue records for SPECIES_CODE values 21345, 22200 and 69326.\n– GAP_PRODUCTS ChangeLog (last produced on 2024-01-09) using gapindex v2.1.3: A new version of gapindex (v2.1.3) was used to produced these data. Data for SPECIES_CODE 68590 (Chionoecetes hybrids) are now removed, per this issue (https://github.com/afsc-gap-products/gap_products/issues/3). New read otolith data were incorporated into the age compositions. GOA depth subareas are now included in the size comps, and there were some modifications with EBS skate length data that are now incorporated into the length compositions.\n– GAP_PRODUCTS ChangeLog (last produced on 2023-11-17) using gapindex v2.1.2: A new version of gapindex (v2.1.2) was used to produced these data. There was a slight change to how subarea biomass totals are calculated that was not fully addressed in v2.1.1. The modified biomass records reflect this change.\n– GAP_PRODUCTS ChangeLog (last produced on 2023-11-14) using gapindex v2.1.1: A new version of gapindex (v2.1.1) was used to produced these data. There was a slight change to how subarea biomass totals are calculated. The modified biomass records reflect this change. New 2022 otolith data were available since the last iteration of the GAP_PRODUCTS for Aleutian Island Pacific ocean perch and northern rockifsh and Eastern Bering Sea northern rock sole. Zero-filled CPUE records for four GOA species codes (SPECIES_CODE: 21210, 30010, 30360, 77102, 98101) were added due to how the 1990 data were integrated in the last production run of GAP_PRODUCTS. Two Arctic cod (SPECIES_CODE: 21725) and one plain sculpin (SPECIES_CODE: 21371) count records were modified in the NBS data, which changes the numerical CPUE estimates for those hauls which changes the estimated population abundance and size composition for those species.\n– Groundfish Assessment Program Survey Data Serving and Data Improvements: Initial data changes brief distributed to SSMA and other partners by Ned Laman, Zack Oyafuso, and Emily Markowitz\n– Run 2023-06-01 gapindex v2.1.0: Initial compiling and planning notes"
  },
  {
    "objectID": "content/intro-code-of-conduct.html",
    "href": "content/intro-code-of-conduct.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "NOAA Fisheries Open Science Code of Conduct\nThis code of conduct was developed and adapted from the Atom code of conduct in October 2021."
  },
  {
    "objectID": "content/intro-code-of-conduct.html#what-are-codes-of-conduct",
    "href": "content/intro-code-of-conduct.html#what-are-codes-of-conduct",
    "title": "Code of Conduct",
    "section": "What are Codes of Conduct?",
    "text": "What are Codes of Conduct?\nCodes of Conduct are voluntary sets of rules that assist creators, developers, and users of code and data with data protection compliance and accountability in specific sectors or relating to particular processing operations.\nCodes can help organizations to ensure all participants follow best practices and rules designed specifically for their sector or processing operations, thus enhancing compliance and collaboration. They are developed and managed by an association or other body (the ‘Code Owner’) which is representative of a sector (or category of data controllers or processors), with the expert and sectoral knowledge of how to enhance data protection in their area.\n\nCode of Conduct from the nmfs-opensci GitHub."
  },
  {
    "objectID": "content/intro-code-of-conduct.html#our-pledge",
    "href": "content/intro-code-of-conduct.html#our-pledge",
    "title": "Code of Conduct",
    "section": "Our Pledge",
    "text": "Our Pledge\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation."
  },
  {
    "objectID": "content/intro-code-of-conduct.html#our-standards",
    "href": "content/intro-code-of-conduct.html#our-standards",
    "title": "Code of Conduct",
    "section": "Our Standards",
    "text": "Our Standards\nExamples of behavior that contributes to creating a positive environment include:\n\nUsing welcoming and inclusive language\nBeing respectful of differing viewpoints and experiences\nGracefully accepting constructive criticism\nFocusing on what is best for the community\nShowing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\nThe use of sexualized language or imagery and unwelcome sexual attention or advances\nTrolling, insulting/derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or electronic address, without explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "content/intro-code-of-conduct.html#our-responsibilities",
    "href": "content/intro-code-of-conduct.html#our-responsibilities",
    "title": "Code of Conduct",
    "section": "Our Responsibilities",
    "text": "Our Responsibilities\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful."
  },
  {
    "objectID": "content/intro-code-of-conduct.html#scope",
    "href": "content/intro-code-of-conduct.html#scope",
    "title": "Code of Conduct",
    "section": "Scope",
    "text": "Scope\nThis Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers."
  },
  {
    "objectID": "content/intro-code-of-conduct.html#enforcement",
    "href": "content/intro-code-of-conduct.html#enforcement",
    "title": "Code of Conduct",
    "section": "Enforcement",
    "text": "Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. Further details of specific enforcement policies may be posted separately."
  },
  {
    "objectID": "content/intro-code-of-conduct.html#attribution",
    "href": "content/intro-code-of-conduct.html#attribution",
    "title": "Code of Conduct",
    "section": "Attribution",
    "text": "Attribution\nThis Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://contributor-covenant.org/version/1/4"
  },
  {
    "objectID": "content/product-intro.html#data-description",
    "href": "content/product-intro.html#data-description",
    "title": "GAP Production Data",
    "section": "Data Description",
    "text": "Data Description\nThe Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC) conducts fisheries-independent bottom trawl surveys to monitor the condition of the demersal fish and crab stocks of Alaska. These data are developed to describe the temporal distribution and abundance of commercially and ecologically important groundfish species, examine the changes in the species composition of the fauna over time and space, and describe the physical environment of the groundfish habitat. These data are created using the gapindex R package v2.1.0.\nUsers must read and fully comprehend the metadata prior to use. Data should not be used beyond the limits of the source scale. Acknowledgement of NOAA, as the source from which these data were obtained, in any publications and/or other representations of these data, is suggested. These data are compiled and approved annually after each summer survey season. The data from previous years are unlikely to change substantially once published. Some survey data are excluded, such as non-standard stations, surveys completed in earlier years using different/non-standard gear, and special tows and non-standard data collections."
  },
  {
    "objectID": "content/product-intro.html#cite-this-data",
    "href": "content/product-intro.html#cite-this-data",
    "title": "GAP Production Data",
    "section": "Cite this data",
    "text": "Cite this data\nUse the below bibtext citations, as cited in our group’s citation repository for citing the data created and maintained in this repo (NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program, 2024). Add “note = {Accessed: mm/dd/yyyy}” to append the day this data was accessed.\n\n\n@misc{GAPProducts,\n  author = {{NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program}},\n  year = {2023}, \n  title = {AFSC Goundfish Assessment Program Design-Based Production Data},\n  howpublished = {https://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys},\n  publisher = {{U.S. Dep. Commer.}},\n  copyright = {Public Domain} \n}\n\n\n\n\n\n\nNOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program. (2024). AFSC goundfish assessment program design-based production data. https://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys; U.S. Dep. Commer."
  },
  {
    "objectID": "content/product-metadata.html#data-tables",
    "href": "content/product-metadata.html#data-tables",
    "title": "Data description",
    "section": "Data tables",
    "text": "Data tables\n\nAGECOMP\nRegion-level age compositions by sex/length bin.\nNumber of rows: 662,289\nNumber of columns: 10\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAGE\n\n\nTaxon age bin (yrs)\n\n\ninteger\n\n\nNUMBER(38,0)\n\n\nAge bin of taxon. Age bin of a taxon in years estimated by the age comp estimate.\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nArea ID key code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nAREA_ID_FOOTPRINT\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\nLENGTH_MM_MEAN\n\n\nMean length at age weighted by numbers at length\n\n\nnumeric\n\n\nNUMBER(38,3)\n\n\nMean length (millimeters)\n\n\n\n\nLENGTH_MM_SD\n\n\nStandard deviation of length at age weighted by numbers at length\n\n\nnumeric\n\n\nNUMBER(38,3)\n\n\nVariance of mean length.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nAREA\nThis table contains all of the information related to the various strata, subareas, INPFC and NMFS management areas, and regions for the Aleutian Islands, Gulf of Alaska, and Bering Sea shelf and slope bottom trawl surveys. These tables are created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated February 29, 2024. There are no legal restrictions on access to the data. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).\nNumber of rows: 385\nNumber of columns: 10\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nArea ID key code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nAREA_KM2\n\n\nArea (km2)\n\n\nkilometers squared\n\n\nNUMBER(38,3)\n\n\nArea in square kilometers.\n\n\n\n\nAREA_NAME\n\n\nArea ID name\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescriptive name of each AREA_ID. These names often identify the region, depth ranges, or other regional information for the area ID.\n\n\n\n\nAREA_TYPE\n\n\nArea ID type description\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nThe type of stratum that AREA_ID represents. Types include: STRATUM (the smallest building-block unit of area in these surveys), REGION, DEPTH, SUBAREA, INPFC BY DEPTH, INPFC, SUBAREA BY DEPTH, REGULATORY AREA, NMFS STATISTICAL AREA.\n\n\n\n\nCRS\n\n\nCoordinate reference system\n\n\nID key code\n\n\nVARCHAR2(255 BYTE)\n\n\nThe coordinate reference system (CRS) that shapefiles were created in or areas (like AREA_KM2) are calculated in, as defined by https://spatialreference.org/ (e.g., “+proj=longlat”, “EPSG:3338”).\n\n\n\n\nDEPTH_MAX_M\n\n\nArea ID maximum depth (m)\n\n\nmeters\n\n\nNUMBER(38,3)\n\n\nMaximum depth (meters).\n\n\n\n\nDEPTH_MIN_M\n\n\nArea ID minimum depth (m)\n\n\nmeters\n\n\nNUMBER(38,3)\n\n\nMinimum depth (meters).\n\n\n\n\nDESCRIPTION\n\n\nDescription\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescription of row observation.\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\n\n\n\nBIOMASS\nStratum/subarea/region-level mean CPUE (weight and numbers), total biomass, and total abundance with associated variances.\nNumber of rows: 4,720,693\nNumber of columns: 16\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nArea ID key code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nBIOMASS_MT\n\n\nEstimated biomass\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated total biomass.\n\n\n\n\nBIOMASS_VAR\n\n\nEstimated biomass variance\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated variance associated with the total biomass.\n\n\n\n\nCPUE_KGKM2_MEAN\n\n\nMean weight CPUE\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).\n\n\n\n\nCPUE_KGKM2_VAR\n\n\nVariance of the mean weight CPUE\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe variance of mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).\n\n\n\n\nCPUE_NOKM2_MEAN\n\n\nMean numeric CPUE\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe mean of numerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2_VAR\n\n\nVariance of the mean numeric CPUE\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe variance of mean numerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nN_COUNT\n\n\nHauls with taxon counts\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with positive count data.\n\n\n\n\nN_HAUL\n\n\nValid hauls\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls.\n\n\n\n\nN_LENGTH\n\n\nHauls with taxon lengths\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with length data.\n\n\n\n\nN_WEIGHT\n\n\nHauls with catch\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with positive catch biomass.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nPOPULATION_VAR\n\n\nEstimated population variance\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated population variance caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nCPUE\nHaul-level zero-filled weight and numerical catch-per-unit-effort.\nNumber of rows: 39,016,999\nNumber of columns: 7\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_SWEPT_KM2\n\n\nArea swept (km)\n\n\nkilometers\n\n\nNUMBER(38,6)\n\n\nThe area the net covered while the net was fishing (kilometers squared), defined as the distance fished times the net width.\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul or samples collected.\n\n\n\n\nCPUE_KGKM2\n\n\nWeight CPUE (kg/km2)\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nCatch weight (kilograms) per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2\n\n\nNumber CPUE (no/km2)\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nNumerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\n\n\n\nSURVEY_DESIGN\nThis table contains for a given survey (via SURVEY_DEFINITION_ID) and survey year (YEAR), which version (DESIGN_YEAR) of the AREA_IDs that were used to calculate the various standard data products. These tables are created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated February 29, 2024. There are no legal restrictions on access to the data. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).\nNumber of rows: 87\nNumber of columns: 3\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nMETADATA_TABLE\nThese columns provide the table metadata for all of the tables and views in GAP_PRODUCTS. These tables are created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated March 03, 2024. There are no legal restrictions on access to the data. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).\nNumber of rows: 8\nNumber of columns: 3\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nMETADATA_SENTENCE\n\n\nSentence\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nTable metadata sentence.\n\n\n\n\nMETADATA_SENTENCE_NAME\n\n\nMetadata sentence name\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nName of table metadata sentence.\n\n\n\n\nMETADATA_SENTENCE_TYPE\n\n\nSentence type\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nType of sentence to have in table metadata.\n\n\n\n\n\n\n\nSTRATUM_GROUPS\nThis table contains all of strata that are contained within a given subarea, INPFC or NMFS management area, or region for the Aleutian Islands, Gulf of Alaska, and Bering Sea shelf and slope bottom trawl surveys. These tables are created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated February 29, 2024. There are no legal restrictions on access to the data. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).\nNumber of rows: 768\nNumber of columns: 4\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nArea ID key code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID key code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\n\n\n\nSIZECOMP\nStratum/subarea/region-level size compositions by sex. This table was created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated March 03, 2024.\nNumber of rows: 3,194,244\nNumber of columns: 7\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nArea ID key code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nLENGTH_MM\n\n\nLength of a specimen\n\n\nmillimeters\n\n\nNUMBER(10,0)\n\n\nLength bin in millimeters.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected."
  },
  {
    "objectID": "content/akfin-intro.html#the-alaska-fisheries-information-network",
    "href": "content/akfin-intro.html#the-alaska-fisheries-information-network",
    "title": "AKFIN",
    "section": "The Alaska Fisheries Information Network",
    "text": "The Alaska Fisheries Information Network\nThe Alaska Fisheries Information Network (AKFIN) is a regional program that consolidates and supports the processing, analysis, and reporting of fisheries data for Alaskan fisheries. AKFIN integrates this information into a single data management system using consistent methods and standardized formats. The resulting data enables fishery managers, scientists, and associated agencies to supervise fisheries resources more effectively and efficiently. The AKFIN database contains much of the data needed to complete stock assessments, including GAP trawl survey data. ."
  },
  {
    "objectID": "content/akfin-intro.html#data-access-options",
    "href": "content/akfin-intro.html#data-access-options",
    "title": "AKFIN",
    "section": "Data Access Options",
    "text": "Data Access Options\nDirect database connection If you are an AFSC employee you may access the AKFIN oracle database directly while on the NOAA network or VPN. Note that this is a separate database from the AFSC oracle database referenced above, and requires separate credentials. If you do not already have an AKFIN account you can request one here. NOAA IT will need to add AKFIN access to your tnsnames.ora file (They do this frequently). Once your connection is established data may be accessed through SQL queries using SQL developer, R, or python."
  },
  {
    "objectID": "content/akfin-intro.html#akfin-answers",
    "href": "content/akfin-intro.html#akfin-answers",
    "title": "AKFIN",
    "section": "AKFIN Answers",
    "text": "AKFIN Answers\n(AKFIN Answers)[https://akfin.psmfc.org/akfin-answers/] is an Oracle BI tool used for distributing data to stock assessors and other users. Usernames and passwords are distinct from AKFIN direct database credentials. The distribution of GAP_PRODUCTS on AKFIN Answers is planned but not yet implemented. The RACE Survey tab on the stock assessment dashboard contains reports generated from now depreciated tables that predated the GAP_PRODUCTS tables. AKFIN will keep these reports for reference but they will not be updated 2024 onward.\n\n\n\n\n\nAKFIN platfrom."
  },
  {
    "objectID": "content/akfin-intro.html#web-service",
    "href": "content/akfin-intro.html#web-service",
    "title": "AKFIN",
    "section": "Web Service",
    "text": "Web Service\nAKFIN has developed web services (apis) to distribute GAP data. Like the GAP_PRODUCTS schema, these are under active development. These do not require VPN or an oracle connection but they are protected by Oracle authentication, please contact matt.callahan@noaa.gov for information on how to get an api token to use this option.\nThe url structure is “https://apex.psmfc.org/akfin/data_marts/gap_products/gap_[base table name]” . For example “https://apex.psmfc.org/akfin/data_marts/gap_products/gap_biomass” is the base url to get data from the akfin_biomass table. Web services linked to large tables have mandatory parameters to reduce data download size. For example to get agecomp data for Bering Sea pollock in area_id 10 in 2022 you would use “https://apex.psmfc.org/akfin/data_marts/gap_products/gap_biomass?survey_definition_id=98&area_id=10&species_code=21740&start_year=2022&end_year=2022”.\nIf you’re using R to pull data through web services you might find the akfingapdata (pronounced akfin-gap-data not ak-eff-ing-app-data) R package helpful."
  },
  {
    "objectID": "content/akfin-intro.html#cite-this-data",
    "href": "content/akfin-intro.html#cite-this-data",
    "title": "AKFIN",
    "section": "Cite this data",
    "text": "Cite this data\nUse the below bibtext citations, as cited in our group’s citation repository for citing the data created and maintained in this repo (Alaska Fisheries Information Network (AKFIN), 2024). Add “note = {Accessed: mm/dd/yyyy}” to append the day this data was accessed.\n\n\n@misc{GAPakfin,\n  author = {{Alaska Fisheries Information Network (AKFIN)}}, \n  institution = {{NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program}},\n  year = {2023}, \n  title = {AFSC Goundfish Assessment Program Design-Based Production Data},\n  howpublished = {https://www.psmfc.org/program/alaska-fisheries-information-network-akfin},\n  publisher = {{U.S. Dep. Commer.}},\n  copyright = {Public Domain} \n}\n\n\n\n\n\n\nAlaska Fisheries Information Network (AKFIN). (2024). AFSC goundfish assessment program design-based production data. NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program; https://akfinbi.psmfc.org/analytics/; U.S. Dep. Commer. https://www.psmfc.org/program/alaska-fisheries-information-network-akfin"
  },
  {
    "objectID": "content/akfin-metadata.html#data-tables",
    "href": "content/akfin-metadata.html#data-tables",
    "title": "Data description",
    "section": "Data tables",
    "text": "Data tables\n\nAKFIN_AGECOMP\nThis table is a copy of GAP_PRODUCTS.AGECOMP and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated March 03, 2024.\nNumber of rows: 662,289\nNumber of columns: 10\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAGE\n\n\nTaxon age bin (yrs)\n\n\ninteger\n\n\nNUMBER(38,0)\n\n\nAge bin of taxon. Age bin of a taxon in years estimated by the age comp estimate.\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nArea ID key code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nAREA_ID_FOOTPRINT\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\nLENGTH_MM_MEAN\n\n\nMean length at age weighted by numbers at length\n\n\nnumeric\n\n\nNUMBER(38,3)\n\n\nMean length (millimeters)\n\n\n\n\nLENGTH_MM_SD\n\n\nStandard deviation of length at age weighted by numbers at length\n\n\nnumeric\n\n\nNUMBER(38,3)\n\n\nVariance of mean length.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nAKFIN_AREA\nThis table is a copy of GAP_PRODUCTS.AREA and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated March 03, 2024.\nNumber of rows: 385\nNumber of columns: 10\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nArea ID key code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nAREA_KM2\n\n\nArea (km2)\n\n\nkilometers squared\n\n\nNUMBER(38,3)\n\n\nArea in square kilometers.\n\n\n\n\nAREA_NAME\n\n\nArea ID name\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescriptive name of each AREA_ID. These names often identify the region, depth ranges, or other regional information for the area ID.\n\n\n\n\nAREA_TYPE\n\n\nArea ID type description\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nThe type of stratum that AREA_ID represents. Types include: STRATUM (the smallest building-block unit of area in these surveys), REGION, DEPTH, SUBAREA, INPFC BY DEPTH, INPFC, SUBAREA BY DEPTH, REGULATORY AREA, NMFS STATISTICAL AREA.\n\n\n\n\nCRS\n\n\nCoordinate reference system\n\n\nID key code\n\n\nVARCHAR2(255 BYTE)\n\n\nThe coordinate reference system (CRS) that shapefiles were created in or areas (like AREA_KM2) are calculated in, as defined by https://spatialreference.org/ (e.g., “+proj=longlat”, “EPSG:3338”).\n\n\n\n\nDEPTH_MAX_M\n\n\nArea ID maximum depth (m)\n\n\nmeters\n\n\nNUMBER(38,3)\n\n\nMaximum depth (meters).\n\n\n\n\nDEPTH_MIN_M\n\n\nArea ID minimum depth (m)\n\n\nmeters\n\n\nNUMBER(38,3)\n\n\nMinimum depth (meters).\n\n\n\n\nDESCRIPTION\n\n\nDescription\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescription of row observation.\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\n\n\n\nAKFIN_BIOMASS\nThis table is a copy of GAP_PRODUCTS.BIOMASS and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated March 04, 2024.\nNumber of rows: 4,720,693\nNumber of columns: 16\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nArea ID key code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nBIOMASS_MT\n\n\nEstimated biomass\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated total biomass.\n\n\n\n\nBIOMASS_VAR\n\n\nEstimated biomass variance\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated variance associated with the total biomass.\n\n\n\n\nCPUE_KGKM2_MEAN\n\n\nMean weight CPUE\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).\n\n\n\n\nCPUE_KGKM2_VAR\n\n\nVariance of the mean weight CPUE\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe variance of mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).\n\n\n\n\nCPUE_NOKM2_MEAN\n\n\nMean numeric CPUE\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe mean of numerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2_VAR\n\n\nVariance of the mean numeric CPUE\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe variance of mean numerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nN_COUNT\n\n\nHauls with taxon counts\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with positive count data.\n\n\n\n\nN_HAUL\n\n\nValid hauls\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls.\n\n\n\n\nN_LENGTH\n\n\nHauls with taxon lengths\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with length data.\n\n\n\n\nN_WEIGHT\n\n\nHauls with catch\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with positive catch biomass.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nPOPULATION_VAR\n\n\nEstimated population variance\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated population variance caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nAKFIN_CATCH\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_CATCH\nNumber of rows: 989,351\nNumber of columns: 6\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCATCHJOIN\n\n\nCatch observation ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nUnique integer ID assigned to each survey, vessel, year, and catch observation combination.\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul or samples collected.\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nUnique integer ID assigned to each survey, vessel, and year combination.\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\n\n\n\nAKFIN_CPUE\nThis table is a copy of GAP_PRODUCTS.CPUE and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated March 04, 2024.\nNumber of rows: 39,016,999\nNumber of columns: 7\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_SWEPT_KM2\n\n\nArea swept (km)\n\n\nkilometers\n\n\nNUMBER(38,6)\n\n\nThe area the net covered while the net was fishing (kilometers squared), defined as the distance fished times the net width.\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul or samples collected.\n\n\n\n\nCPUE_KGKM2\n\n\nWeight CPUE (kg/km2)\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nCatch weight (kilograms) per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2\n\n\nNumber CPUE (no/km2)\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nNumerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\n\n\n\nAKFIN_CRUISE\nThis is the cruise data table. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated March 03, 2024.\nNumber of rows: 187\nNumber of columns: 10\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCRUISE\n\n\nCruise Name\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a six-digit integer identifying the cruise number of the form: YYYY99 (where YYYY = year of the cruise; 99 = 2-digit number and is sequential; 01 denotes the first cruise that vessel made in this year, 02 is the second, etc.).\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nUnique integer ID assigned to each survey, vessel, and year combination.\n\n\n\n\nDATE_END\n\n\nEnd date\n\n\nYYYY-MM-DD\n\n\nDATE\n\n\nThe date (YYYY-MM-DD) of the end of the event (e.g., cruise).\n\n\n\n\nDATE_START\n\n\nStart date\n\n\nYYYY-MM-DD\n\n\nDATE\n\n\nThe date (YYYY-MM-DD) of the beginning of the event (e.g., cruise).\n\n\n\n\nSPONSOR_ACRONYM\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nSURVEY_NAME\n\n\nSurvey name official\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLong name of the survey conducted\n\n\n\n\nVESSEL_ID\n\n\nVessel ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nID number of the vessel used to collect data for that haul. The column ‘vessel_id’ is associated with the ‘vessel_name’ column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID key codes, review the code books.\n\n\n\n\nVESSEL_NAME\n\n\nVessel name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName of the vessel used to collect data for that haul. The column ‘vessel_name’ is associated with the ‘vessel_id’ column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID key codes, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nAKFIN_HAUL\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_HAUL\nNumber of rows: 36,114\nNumber of columns: 25\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nACCESSORIES\n\n\nType of gear accessories used on the net\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nType of accessories used on net. For a complete list of accessories ID key codes, review the code books.\n\n\n\n\nBOTTOM_TYPE\n\n\nSeafloor bottom type code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nBottom type on sea floor at haul location. For a complete list of bottom type ID key codes, review the code books.\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nUnique integer ID assigned to each survey, vessel, and year combination.\n\n\n\n\nDATE_TIME_START\n\n\nStart date and time\n\n\nMM/DD/YYYY HH::MM\n\n\nTIMESTAMP\n\n\nThe date (MM/DD/YYYY) and time (HH:MM) of the beginning of the haul. All dates and times are in Alaska time (AKDT) of Anchorage, AK, USA (UTC/GMT -8 hours).\n\n\n\n\nDEPTH_GEAR_M\n\n\nDepth of gear (m)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nDepth of gear (meters).\n\n\n\n\nDEPTH_M\n\n\nDepth (m)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nBottom depth (meters).\n\n\n\n\nDISTANCE_FISHED_KM\n\n\nDistance fished (km)\n\n\ndegrees Celsius\n\n\nNUMBER(38,3)\n\n\nDistance the net fished (thousands of kilometers).\n\n\n\n\nDURATION_HR\n\n\nTow duration (decimal hr)\n\n\nhours\n\n\nNUMBER(38,1)\n\n\nThis is the elapsed time between start and end of a haul (decimal hours).\n\n\n\n\nGEAR\n\n\nType of gear used on the net\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nType of gear used on net. For a complete list of gear ID key codes, review the code books.\n\n\n\n\nGEAR_TEMPERATURE_C\n\n\nGear temperature (degrees Celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nTemperature recorded by net gear (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nHAUL\n\n\nHaul number\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a sampling event (haul) within a cruise. It is a sequential number, in chronological order of occurrence.\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nHAUL_TYPE\n\n\nHaul sampling type\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nType of haul sampling method. For a complete list of haul type ID key codes, review the code books.\n\n\n\n\nLATITUDE_DD_END\n\n\nEnd latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nLATITUDE_DD_START\n\n\nStart latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nLONGITUDE_DD_END\n\n\nEnd longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nLONGITUDE_DD_START\n\n\nStart longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nNET_HEIGHT_M\n\n\nNet height (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between footrope and headrope of the trawl.\n\n\n\n\nNET_MEASURED\n\n\nNet measured during haul\n\n\nlogical\n\n\nBINARY_DOUBLE\n\n\nLogical, describing if the net was measured (TRUE) or not (FALSE) by wheelhouse and marport programs during the haul.\n\n\n\n\nNET_WIDTH_M\n\n\nNet width (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between wingtips of the trawl.\n\n\n\n\nPERFORMANCE\n\n\nHaul performance code\n\n\ncategory\n\n\nNUMBER(38,0)\n\n\nThis denotes what, if any, issues arose during the haul. For more information, review the code books.\n\n\n\n\nSTATION\n\n\nStation ID\n\n\nID key code\n\n\nVARCHAR2(255 BYTE)\n\n\nAlpha-numeric designation for the station established in the design of a survey.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID key code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\nSURFACE_TEMPERATURE_C\n\n\nSurface temperature (degrees Celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nSurface temperature (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nWIRE_LENGTH_M\n\n\nTrawl wire length\n\n\nmeters\n\n\nNUMBER(38,0)\n\n\nLength of wire deployed during a given haul in meters.\n\n\n\n\n\n\n\nAKFIN_LENGTH\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_LENGTH\nNumber of rows: 4,601,111\nNumber of columns: 7\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nFREQUENCY\n\n\nCount of observation\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nFrequency, or count, of an observation.\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nLENGTH_MM\n\n\nLength of a specimen\n\n\nmillimeters\n\n\nNUMBER(10,0)\n\n\nLength bin in millimeters.\n\n\n\n\nLENGTH_TYPE\n\n\nLength type\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nHow the taxon was measured (e.g., fork length, carapace width). For a complete list of length_type ID key codes, review the code books.\n\n\n\n\nSAMPLE_TYPE\n\n\nSample type\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSampling information on how the taxon was sampled. For a complete list of length_type ID key codes, review the code books.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\n\n\n\nAKFIN_METADATA_COLUMN\nThis table is a copy of GAP_PRODUCTS.METADATA_COLUMN and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated March 03, 2024.\nNumber of rows: 161\nNumber of columns: 5\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nMETADATA_COLNAME\n\n\nColumn name\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nName of the column in a table.\n\n\n\n\nMETADATA_COLNAME_DESC\n\n\nColumn description\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescription of the column.\n\n\n\n\nMETADATA_COLNAME_LONG\n\n\nColumn name spelled out\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nLong name for the column.\n\n\n\n\nMETADATA_DATATYPE\n\n\nOracle datatype code\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nOracle data type of data column.\n\n\n\n\nMETADATA_UNITS\n\n\nUnits\n\n\ncategory\n\n\nVARCHAR2(4000 BYTE)\n\n\nUnits of the column.\n\n\n\n\n\n\n\nAKFIN_SIZECOMP\nThis table is a copy of GAP_PRODUCTS.SIZECOMP and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated March 04, 2024.\nNumber of rows: 3,194,244\nNumber of columns: 7\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nArea ID key code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nLENGTH_MM\n\n\nLength of a specimen\n\n\nmillimeters\n\n\nNUMBER(10,0)\n\n\nLength bin in millimeters.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nAKFIN_SPECIMEN\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_SPECIMEN\nNumber of rows: 634,835\nNumber of columns: 12\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAGE\n\n\nTaxon age bin (yrs)\n\n\ninteger\n\n\nNUMBER(38,0)\n\n\nAge bin of taxon. Age bin of a taxon in years estimated by the age comp estimate.\n\n\n\n\nAGE_DETERMINATION_METHOD\n\n\nAging method\n\n\nID key code\n\n\nNUMBER(10,0)\n\n\nNumeric code corresponding to the method of age determination. For a complete list of age determination codes, review the code books.\n\n\n\n\nGONAD_G\n\n\nWeight of gonads (g)\n\n\ngrams\n\n\nNUMBER(38,1)\n\n\nWeight of specimen gonads (grams).\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nLENGTH_MM\n\n\nLength of a specimen\n\n\nmillimeters\n\n\nNUMBER(10,0)\n\n\nLength bin in millimeters.\n\n\n\n\nMATURITY\n\n\nSpecimen maturity code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe maturity code or the condition identified by the maturity code.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSPECIMEN_ID\n\n\nSpecimen unique ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nEach individual examined must have a number assigned to it that is unique within each haul (0001 to 9999), though specimen numbers may be repeated between hauls\n\n\n\n\nSPECIMEN_SAMPLE_TYPE\n\n\nSpecimen sample type\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe specimen sample type ID key code as defined in the RACE_DATA.SPECIMEN_SAMPLE_TYPES table. For a complete list of Specimen sample type ID key codes, review the code books.\n\n\n\n\nSPECIMEN_SUBSAMPLE_METHOD\n\n\nSpecimen subsample method\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nFor a complete list of specimen subsample method ID key codes, review the code books.\n\n\n\n\nWEIGHT_G\n\n\nSpecimen weight (g)\n\n\ngrams\n\n\nNUMBER(38,1)\n\n\nWeight of specimen (grams).\n\n\n\n\n\n\n\nAKFIN_STRATUM_GROUPS\nThis table is a copy of GAP_PRODUCTS.STRATUM_GROUPS and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated March 03, 2024.\nNumber of rows: 768\nNumber of columns: 4\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nArea ID key code for each statistical area used to produce production estimates (e.g., biomass, population, age comps, length comps). Each area ID is unique within each survey.\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID key code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\n\n\n\nAKFIN_SURVEY_DESIGN\nThis table is a copy of GAP_PRODUCTS.SURVEY_DESIGN and does not have any other object dependencies. These data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated March 03, 2024.\nNumber of rows: 87\nNumber of columns: 3\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nAKFIN_TAXONOMIC_CLASSIFICATION\nNAThese data are produced by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. These data were last updated March 03, 2024.\nNumber of rows: 2,699\nNumber of columns: 19\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCLASS_TAXON\n\n\nClass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of class of a given species.\n\n\n\n\nCOMMON_NAME\n\n\nTaxon common name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe common name of the marine organism associated with the ‘scientific_name’ and ‘species_code’ columns. For a complete species list, review the code books.\n\n\n\n\nDATABASE\n\n\nDatabase source\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nTaxonomic database source, either ITIS or WoRMS.\n\n\n\n\nDATABASE_ID\n\n\nSpecies ID in database\n\n\nID key code\n\n\nVARCHAR2(255 BYTE)\n\n\nSpecies ID key code of a species in the taxonomic “DATABASE” source.\n\n\n\n\nFAMILY_TAXON\n\n\nFamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of family of a given species.\n\n\n\n\nGENUS_TAXON\n\n\nGenus phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of genus of a given species.\n\n\n\n\nID_RANK\n\n\nLowest taxonomic rank\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLowest taxonomic rank of a given species entry.\n\n\n\n\nKINGDOM_TAXON\n\n\nKingdom phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of kingdom of a given species.\n\n\n\n\nORDER_TAXON\n\n\nOrder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of order of a given species.\n\n\n\n\nPHYLUM_TAXON\n\n\nPhylum phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of phylum of a given species.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSPECIES_NAME\n\n\nScientific name of species\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nScientific name of species.\n\n\n\n\nSUBCLASS_TAXON\n\n\nSubclass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subclass of a given species.\n\n\n\n\nSUBFAMILY_TAXON\n\n\nSubfamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subfamily of a given species.\n\n\n\n\nSUBORDER_TAXON\n\n\nSuborder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of suborder of a given species.\n\n\n\n\nSUBPHYLUM_TAXON\n\n\nSubphylum phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subphylum of a given species.\n\n\n\n\nSUPERCLASS_TAXON\n\n\nSuperclass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superclass of a given species.\n\n\n\n\nSUPERFAMILY_TAXON\n\n\nSuperfamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superfamily of a given species.\n\n\n\n\nSUPERORDER_TAXON\n\n\nSuperorder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superorder of a given species."
  },
  {
    "objectID": "content/akfin-oracle-sql-r.html#access-data-via-oracle-afsc-only",
    "href": "content/akfin-oracle-sql-r.html#access-data-via-oracle-afsc-only",
    "title": "Access data",
    "section": "Access data via Oracle (AFSC only)",
    "text": "Access data via Oracle (AFSC only)\nAFSC Oracle users can access the database via SQL developer to view and pull the production data directly from the GAP_PRODUCTS Oracle schema. The user can also use SQL developer to view and pull the GAP Products data directly from the GAP_PRODUCTS Oracle schema.\n\n7.0.1 Connect to Oracle from R\nMany users will want to access the data from Oracle using R. The user will need to install the RODBC R package and ask OFIS (IT) connect R to Oracle. Then, use the following code in R to establish a connection from R to Oracle:\nHere, the user can establish the oracle connection by entering their username and password in the channel &lt;- gapindex::oracle_connect() function. Never save usernames or passwords in scripts that may be intentionally or unintentionally shared with others. If no username and password is entered in the function, pop-ups will appear on the screen asking for the username and password.\nAfter you connect to VPN, you’ll be able to log into Oracle.\n\nlibrary(RODBC)\nchannel &lt;- gapindex::get_connected()"
  },
  {
    "objectID": "content/akfin-oracle-sql-r.html#data-sql-query-examples",
    "href": "content/akfin-oracle-sql-r.html#data-sql-query-examples",
    "title": "Access data",
    "section": "Data SQL Query Examples:",
    "text": "Data SQL Query Examples:\n\nlibrary(gapindex)\nlibrary(RODBC)\nlibrary(flextable)\nlibrary(ggplot2)\nlibrary(magrittr)\nlibrary(dplyr)\n\n\n7.0.2 Ex. Select all data from tables\nYou can download all of the tables locally using a variation of the code below. Once connected, pull and save the tables of interest into the R environment.\n\nlocations &lt;- c(\n  \"GAP_PRODUCTS.AKFIN_AGECOMP\", \n  \"GAP_PRODUCTS.AKFIN_AREA\", \n  \"GAP_PRODUCTS.AKFIN_BIOMASS\", \n  \"GAP_PRODUCTS.AKFIN_CATCH\", \n  \"GAP_PRODUCTS.AKFIN_CPUE\", \n  \"GAP_PRODUCTS.AKFIN_CRUISE\", \n  \"GAP_PRODUCTS.AKFIN_HAUL\", \n  \"GAP_PRODUCTS.AKFIN_LENGTH\", \n  \"GAP_PRODUCTS.AKFIN_METADATA_COLUMN\", \n  \"GAP_PRODUCTS.AKFIN_SIZECOMP\", \n  \"GAP_PRODUCTS.AKFIN_SPECIMEN\", \n  \"GAP_PRODUCTS.AKFIN_STRATUM_GROUPS\", \n  \"GAP_PRODUCTS.AKFIN_SURVEY_DESIGN\", \n  \"GAP_PRODUCTS.AKFIN_TAXONOMIC_CLASSIFICATION\"\n)\n\nfor (i in 1:length(locations)) {\n  print(locations[i])\n  a &lt;- RODBC::sqlQuery(channel, paste0(\"SELECT * FROM \", locations[i]))\n  write.csv(x = a, file = here::here(\"data\", paste0(locations[i], \".csv\")))\n}\n\n\nlibrary(odbc)\nlibrary(RODBC)\nlibrary(dbplyr)\n\nmy_spp_codes &lt;- c(\n30010, #    Sebastolobus sp.    thornyhead unid.\n30020, #    Sebastolobus alascanus  shortspine thornyhead\n30025, #    Sebastolobus macrochir  broadfin thornyhead\n30330, #    Sebastes melanops   black rockfish\n30430, #    Sebastes proriger   redstripe rockfish\n30470, #    Sebastes ruberrimus yelloweye rockfish\n30475, #    Sebastes babcocki   redbanded rockfish\n30535, #    Sebastes variegatus harlequin rockfish\n30560, # Sebastes zacentrus sharpchin rockfish\n30600, # Sebastes reedi yellowmouth rockfish\n30030, # Sebastolobus altivelis longspine thornyhead\n30040, # Sebastes sp.   rockfish unid.\n30100, # Sebastes brevispinis   silvergray rockfish\n30150, # NA dusky and dark rockfishes unid.\n30152, # Sebastes variabilis    dusky rockfish\n30170, # Sebastes crameri   darkblotched rockfish\n30270) # Sebastes helvomaculatus    rosethorn rockfish\n\na &lt;- dplyr::tbl(channel, dplyr::sql('gap_products.akfin_biomass')) %&gt;% \n  dplyr::rename_all(tolower) %&gt;% \n  dplyr::select(survey_definition_id, area_id, species_code, year, biomass_mt, biomass_var) %&gt;% \n  dplyr::filter(species_code %in% my_spp_codes & \n                  area_id %in% 99904 & \n                  year &gt;= 1991) %&gt;% \n  dplyr::collect() \n\nflextable::flextable(head(a)) %&gt;% \n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra()\n\n\n\n7.0.3 Ex. CPUE for all EBS and NBS stations with associated haul, cruise, and species information.\n\na &lt;- RODBC::sqlQuery(channel = channel, # NOT RACEBASE.HAUL\n                     query = paste0(\n                       \"\n-- Select columns for output data\nSELECT\ncr.CRUISEJOIN,\ncr.CRUISE,\ncr.YEAR,\ncr.SURVEY_DEFINITION_ID,\ncr.SURVEY_NAME,\ncr.VESSEL_ID,\ncr.VESSEL_NAME,\ncp.HAULJOIN,\ncp.SPECIES_CODE,\ntt.SPECIES_NAME,\ntt.COMMON_NAME,\ncp.WEIGHT_KG,\ncp.COUNT,\ncp.AREA_SWEPT_KM2,\ncp.CPUE_KGKM2,\ncp.CPUE_NOKM2,\nhh.HAUL,\nhh.STATION\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_HAUL hh\nLEFT JOIN GAP_PRODUCTS.AKFIN_CRUISE cr\nON hh.CRUISEJOIN = cr.CRUISEJOIN\nLEFT JOIN GAP_PRODUCTS.AKFIN_CPUE cp\nON hh.HAULJOIN = cp.HAULJOIN\nLEFT JOIN GAP_PRODUCTS.TAXONOMIC_CLASSIFICATION tt\nON cp.SPECIES_CODE = tt.SPECIES_CODE\n\n-- Filter for EBS and NBS observations\nWHERE SURVEY_DEFINITION_ID IN (143, 98) -- 143 NBS, 98 EBS\nAND tt.SURVEY_SPECIES = 1\n\n-- Only return the first 3 rows because otherwise this would be a huge table!\nFETCH FIRST 3 ROWS ONLY;\")) \n\nflextable::flextable(head(a[,2:8])) %&gt;% \n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra()\n\n\nEx.: CPUE for all EBS and NBS stations with associated haul, cruise,\nand species information.CRUISEYEARSURVEY_DEFINITION_IDSURVEY_NAMEVESSEL_IDVESSEL_NAMEHAULJOIN198,2031,98298Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey1CHAPMAN877198,2031,98298Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey1CHAPMAN877198,2031,98298Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey1CHAPMAN877\n\n\n\n\n7.0.4 Ex. CPUE for all stations contained in the INPFC Shumagin region (AREA_ID = 919) for Pacific cod.\n\ndat &lt;- RODBC::sqlQuery(channel = channel,\n                       query =\n                         \"\n-- Select columns for output data\nSELECT \nHAULJOIN, \nSPECIES_CODE, \nSTRATUM, \nLATITUDE_DD_START, \nLONGITUDE_DD_START,\nCPUE_KGKM2, \nGEAR_TEMPERATURE_C\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_CPUE cpue\nLEFT JOIN GAP_PRODUCTS.AKFIN_HAUL haul\nUSING (HAULJOIN) \n\n-- Filter for P. Cod observations\nWHERE SPECIES_CODE IN (21720)\n\n-- Select all stratum within the area_id 919 (INPFC Shumagin region)\nAND haul.STRATUM IN\n(\nSELECT \nSTRATUM\nFROM GAP_PRODUCTS.AKFIN_STRATUM_GROUPS \nWHERE AREA_ID = 919\n);\")\n\n\ndat &lt;- dat %&gt;% \n  dplyr::select(HAULJOIN, STRATUM, SPECIES_CODE, LATITUDE_DD_START, LONGITUDE_DD_START, CPUE_KGKM2, GEAR_TEMPERATURE_C) %&gt;% \n  dplyr::mutate(SPECIES_CODE = as.character(SPECIES_CODE), \n                STRATUM = as.character(STRATUM)) %&gt;% \n  dplyr::arrange(SPECIES_CODE)\n\nflextable::flextable(head(dat)) %&gt;%   \n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra()\n\n\nEx. 8: CPUE for all stations contained in the Shumagin region\n(AREA_ID = 919).HAULJOINSTRATUMSPECIES_CODELATITUDE_DD_STARTLONGITUDE_DD_STARTCPUE_KGKM2GEAR_TEMPERATURE_C-22,2711122172055.22129-159.15381,263.83774.1-22,270132172055.11515-159.3512209.28994.3-22,269132172054.93934-159.6317400.31355.4-22,272132172055.10890-159.1346156.69614.1-22,268132172055.04646-159.9590813.92674.9-22,155112172054.07980-163.0046307.54664.5\n\n\n\n\n7.0.5 Ex. EBS Pacific Ocean perch CPUE and akgfmaps map\nPacific Ocean perch catch-per-unit-effort estimates for EBS in 2021 from GAP_PRODUCTS.AKFIN_CPUE and map constructed using akgfmaps. Here, we’ll use AKFIN HAUL and CRUISES data also included in this repo, for convenience, though they are very similar to their RACEBASE analogs.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n                         \"\n-- Select columns for output data\nSELECT \n(cp.CPUE_KGKM2/100) CPUE_KGHA, -- akgfmaps is expecting hectares\nhh.LATITUDE_DD_START LATITUDE,\nhh.LONGITUDE_DD_START LONGITUDE\n\n-- Use HAUL data to obtain LATITUDE & LONGITUDE and connect to cruisejoin\nFROM GAP_PRODUCTS.AKFIN_CPUE cp\nLEFT JOIN GAP_PRODUCTS.AKFIN_HAUL hh\nON cp.HAULJOIN = hh.HAULJOIN\n\n-- Use CRUISES data to obtain YEAR and SURVEY_DEFINITION_ID\nLEFT JOIN GAP_PRODUCTS.AKFIN_CRUISE cc\nON hh.CRUISEJOIN = cc.CRUISEJOIN\n\n-- Filter data\nWHERE cp.SPECIES_CODE = 30060 \nAND cc.SURVEY_DEFINITION_ID = 98 \nAND cc.YEAR = 2021;\")\n\n\ndat %&gt;% \n  dplyr::arrange(desc(CPUE_KGHA)) %&gt;% \n  head() %&gt;% \n  flextable::flextable() %&gt;%  \n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra()\n\n\nEx. 6: EBS Pacific Ocean perch CPUE and akgfmaps\nmap.CPUE_KGHALATITUDELONGITUDE10.176896557.64871-173.37356.273447056.36952-169.46043.025203456.66253-171.95491.821462857.98912-173.48160.553567255.65865-168.18040.281353357.32545-173.3217\n\n\n\n# devtools::install_github(\"afsc-gap-products/akgfmaps\", build_vignettes = TRUE)\nlibrary(akgfmaps)\n\nfigure &lt;- akgfmaps::make_idw_map(\n  x = dat, # Pass data as a data frame\n  region = \"bs.south\", # Predefined EBS area\n  set.breaks = \"jenks\", # Gets Jenks breaks from classint::classIntervals()\n  in.crs = \"+proj=longlat\", # Set input coordinate reference system\n  out.crs = \"EPSG:3338\", # Set output coordinate reference system\n  grid.cell = c(20000, 20000), # 20x20km grid\n  key.title = \"Pacific Ocean perch\") # Include in the legend title\n\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n\nfigure$plot + \n  ggplot2::guides(fill=guide_legend(title = \"Pacific Ocean perch\\nCPUE (kg/km2)\"))  |&gt;   \n  change_fill_color(new.scheme = \"grey\", show.plot = FALSE)\n\n\n\n\nEx. 6: EBS Pacific Ocean perch CPUE and akgfmaps map.\n\n\n\n\n\n\n7.0.6 Ex. GOA Pacific Ocean perch biomass and abundance\nBiomass and abundance for Pacific Ocean perch from 1990 – 2023 for the western/central/eastern GOA management areas as well as for the entire region.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n                         \"\n-- Manipulate data to join to\nWITH FILTERED_STRATA AS (\nSELECT AREA_ID, DESCRIPTION FROM GAP_PRODUCTS.AKFIN_AREA\nWHERE AREA_TYPE in ('REGULATORY_AREA', 'REGION') \nAND SURVEY_DEFINITION_ID = 47)\n\n-- Select columns for output data\nSELECT \nBIOMASS_MT,\nPOPULATION_COUNT, \nYEAR, \nDESCRIPTION\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_BIOMASS BIOMASS\nJOIN FILTERED_STRATA STRATA \nON STRATA.AREA_ID = BIOMASS.AREA_ID\n\n-- Filter data results\nWHERE BIOMASS.SPECIES_CODE = 30060\")\n\n\ndat0 &lt;- dat %&gt;% \n  janitor::clean_names() %&gt;% \n  dplyr::select(biomass_mt, population_count, year, area = description) %&gt;%\n  pivot_longer(cols = c(\"biomass_mt\", \"population_count\"), \n               names_to = \"var\", \n               values_to = \"val\") %&gt;% \n  dplyr::mutate(\n    val = ifelse(var == \"biomass_mt\", val/1e6, val/1e9), \n    var = ifelse(var == \"biomass_mt\", \"Biomass (Mmt)\", \"Population (B)\"), \n    area = gsub(x = area, pattern = \" - \", replacement = \"\\n\"), \n    area = gsub(x = area, pattern = \": \", replacement = \"\\n\"), \n    type = sapply(X = strsplit(x = area, split = \"\\n\", fixed = TRUE), `[[`, 2))  %&gt;% \n  dplyr::arrange(type) %&gt;% \n  dplyr::mutate(\n    area = factor(area, levels = unique(area), labels = unique(area), ordered = TRUE))\n\nflextable::flextable(head(dat)) %&gt;% \n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra() %&gt;%\n  flextable::colformat_num(x = ., j = \"YEAR\", big.mark = \"\")\n\n\nEx. 1: GOA Pacific Ocean perch biomass and abundance.BIOMASS_MTPOPULATION_COUNTYEARDESCRIPTION157,295.1317,129,4081990GOA Region: All Strata157,295.1317,129,4081990GOA Region: All Strata483,622.6833,902,1611993GOA Region: All Strata483,622.6833,902,1611993GOA Region: All Strata771,412.81,252,616,6031996GOA Region: All Strata771,412.81,252,616,6031996GOA Region: All Strata\n\n\n\n# install.packages(\"scales\")\nlibrary(scales)\nfigure &lt;- ggplot2::ggplot(\n  dat = dat0, \n  mapping = aes(x = year, y = val, color = type)) +\n  ggplot2::geom_point(size = 3) + \n  ggplot2::facet_grid(cols = vars(area), rows = vars(var), scales = \"free_y\") + \n  ggplot2::scale_x_continuous(name = \"Year\", n.breaks = 3) +\n  ggplot2::scale_y_continuous(name = \"Estimate\", labels = comma) +\n  ggplot2::labs(title = 'GOA Pacific Ocean perch biomass and abundance 1990 – 2023')  + \n  ggplot2::guides(color=guide_legend(title = \"Region Type\"))+\n  ggplot2::scale_color_grey() +\n  ggplot2::theme_bw() +\n  ggplot2::theme(legend.direction = \"horizontal\", \n                 legend.position = \"bottom\")\n\nfigure\n\n\n\n\nEx. 1: GOA Pacific Ocean perch biomass and abundance.\n\n\n\n\n\n\n7.0.7 Ex. AI rock sole size compositions and ridge plot\nNorthern and Southern rock sole size composition data from 1991 – 2022 for the Aleutian Islands, with Ridge plot from ggridges.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n                         \"\n-- Manipulate data to join to\nWITH FILTERED_STRATA AS (\nSELECT \nAREA_ID, \nDESCRIPTION\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_AREA\nWHERE AREA_TYPE = 'REGION' \nAND SURVEY_DEFINITION_ID = 52)\n\n-- Select columns for output data\nSELECT \nLENGTH_MM, \nYEAR\nFROM GAP_PRODUCTS.AKFIN_SIZECOMP SIZECOMP\nJOIN FILTERED_STRATA STRATA \nON STRATA.AREA_ID = SIZECOMP.AREA_ID\n\n-- Filter data results\nWHERE SIZECOMP.SURVEY_DEFINITION_ID IN 52 \nAND SIZECOMP.SPECIES_CODE IN (10261, 10262)\")\n\n\ndat0 &lt;- dat %&gt;% \n  janitor::clean_names() %&gt;% \n  dplyr::mutate(length_cm = length_mm/10) %&gt;% \n  head() %&gt;% \n  flextable::flextable() %&gt;% \n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra() %&gt;%\n  flextable::colformat_num(x = ., j = \"year\", big.mark = \"\")\ndat0\n\n\nEx. 2: AI Rock sole size compositions and ridge plot.length_mmyearlength_cm110199711130199713140199714150199715160199716170199717\n\n\n\n# install.packages(\"ggridges\")\nlibrary(ggridges)\nfigure &lt;- \n  ggplot2::ggplot(\n    data = dat, \n    mapping = aes(x = LENGTH_MM, y = as.factor(YEAR), fill = stat(x))) +\n  ggridges::theme_ridges(center_axis_labels = TRUE) + \n  ggridges::geom_density_ridges_gradient(scale = 4, show.legend = FALSE) + \n  ggplot2::scale_y_discrete(name = \"Year\", expand = c(0.01, 0)) +\n  ggplot2::scale_x_continuous(name = \"Length (cm)\", expand = c(0.01, 0)) +\n  # ggplot2::scale_fill_grey() +\n  ggplot2::labs(title = 'AI Rock sole Size Compositions 1991 – 2022') \n\nfigure\n\n\n\n\nEx. 2: AI Rock sole size compositions and ridge plot.\n\n\n\n\n\n\n7.0.8 Ex. EBS Walleye Pollock Age Compositions and Age Pyramid\nWalleye pollock age composition for the EBS Standard Area from 1982 – 2022 and the EBS + NW Area from 1987 – 2022, with age pyramid plot.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n                         \"\n-- Manipulate data to join to\nWITH FILTERED_STRATA AS (\nSELECT \nAREA_ID, \nDESCRIPTION \nFROM GAP_PRODUCTS.AKFIN_AREA\nWHERE AREA_TYPE = 'REGION' AND \nSURVEY_DEFINITION_ID = 98)\n\n-- Select columns for output data\nSELECT \nAGECOMP.AGE, \nAGECOMP.POPULATION_COUNT, \nAGECOMP.SEX\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_AGECOMP AGECOMP\nJOIN FILTERED_STRATA STRATA \nON STRATA.AREA_ID = AGECOMP.AREA_ID\n\n-- Filter data results\nWHERE SPECIES_CODE = 21740\nAND AGE &gt;= 0\")\n\n\ndat0 &lt;- dat %&gt;% \n  janitor::clean_names() %&gt;% \n  dplyr::filter(sex %in% c(1,2)) %&gt;%\n  dplyr::mutate(\n    sex = ifelse(sex == 1, \"M\", \"F\"),\n    population_count = # change male population to negative\n      ifelse(sex==\"M\", population_count*(-1), population_count*1)/1e9) \n\nflextable::flextable(head(dat)) %&gt;% \n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra()\n\n\nEx. 3: EBS Walleye Pollock Age Compositions and Age Pyramid.AGEPOPULATION_COUNTSEX201,4423158,027,6511291,836,65513219,430,675141,355,902,25615280,394,1471\n\n\n\nfigure &lt;- ggplot2::ggplot(\n  data = dat0, \n  mapping = \n    aes(x = age,\n        y = population_count, \n        fill = sex)) +\n  ggplot2::scale_fill_grey() +\n  ggplot2::geom_bar(stat = \"identity\") +\n  ggplot2::coord_flip() +\n  ggplot2::scale_x_continuous(name = \"Age\") +\n  ggplot2::scale_y_continuous(name = \"Population (billions)\", labels = abs) +\n  ggplot2::ggtitle(label = \"EBS Walleye Pollock Age Compositions 1982 – 2022\")  + \n  ggplot2::guides(fill = guide_legend(title = \"Sex\"))+\n  ggplot2::theme_bw()\n\nfigure\n\n\n\n\nEx. 3: EBS Walleye Pollock Age Compositions and Age Pyramid.\n\n\n\n\n\n\n7.0.9 Ex. NBS Pacific cod biomass and abundance\nPacific cod biomass and abundance data for the NBS by stratum.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n                         \"\n-- Manipulate data to join to\nWITH FILTERED_STRATA AS (\nSELECT \nAREA_ID, \nAREA_NAME, \nDESCRIPTION \nFROM GAP_PRODUCTS.AKFIN_AREA\nWHERE AREA_TYPE in ('STRATUM') AND \nSURVEY_DEFINITION_ID = 143) \n\n-- Select columns for output data\nSELECT \nBIOMASS.BIOMASS_MT, \nBIOMASS.POPULATION_COUNT, \nBIOMASS.YEAR, \nSTRATA.AREA_NAME\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_BIOMASS BIOMASS \nJOIN FILTERED_STRATA STRATA \nON STRATA.AREA_ID = BIOMASS.AREA_ID\n\n-- Filter data results\nWHERE BIOMASS.SURVEY_DEFINITION_ID IN 143 \nAND BIOMASS.SPECIES_CODE = 21720\")\n\n\ndat0 &lt;- dat %&gt;% \n  janitor::clean_names() %&gt;% \n  dplyr::select(biomass_mt, population_count, year, area = area_name) %&gt;%\n  pivot_longer(cols = c(\"biomass_mt\", \"population_count\"), \n               names_to = \"var\", \n               values_to = \"val\") %&gt;% \n  dplyr::mutate(\n    val = ifelse(var == \"biomass_mt\", val/1e6, val/1e9), \n    var = ifelse(var == \"biomass_mt\", \"Biomass (Mmt)\", \"Population (B)\"), \n    area = factor(area, levels = unique(area), labels = unique(area), ordered = TRUE))\nflextable::flextable(head(dat)) %&gt;% \n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra() %&gt;%\n  flextable::colformat_num(x = ., j = \"YEAR\", big.mark = \"\")\n\n\nEx. 4: NBS Pacific cod biomass and abundance.BIOMASS_MTPOPULATION_COUNTYEARAREA_NAME107,096.730102,734,1422019Inner Domain76,708.43339,605,8602023Inner Domain132,490.15266,187,2452017Inner Domain96,500.69760,433,1352022Inner Domain7,462.5594,724,1532010Inner Domain95,849.98368,767,4982021Inner Domain\n\n\n\nfigure &lt;- ggplot2::ggplot(\n  dat = dat0, \n  mapping = aes(y = val, x = year, fill = area))  + \n  ggplot2::geom_bar(position=\"stack\", stat=\"identity\") +  \n  ggplot2::facet_grid(rows = vars(var), scales = \"free_y\") +\n  ggplot2::scale_y_continuous(name = \"Estimate\", labels = comma) +\n  ggplot2::scale_x_continuous(name = \"Year\", breaks = unique(dat0$year)) +\n  ggplot2::labs(title = 'NBS Pacific cod biomass and abundance by stratum')  + \n  ggplot2::guides(fill=guide_legend(title = \"Region Type\"))+\n  ggplot2::scale_fill_grey() +\n  ggplot2::theme_bw() +\n  ggplot2::theme(legend.direction = \"horizontal\", \n                 legend.position = \"bottom\")\n\nfigure\n\n\n\n\nEx. 4: NBS Pacific cod biomass and abundance.\n\n\n\n\n\n\n7.0.10 Ex. GOA Pacific Ocean perch biomass and line plot\nPacific Ocean perch biomass totals for GOA between 1984-2021 from GAP_PRODUCTS.AKFIN_BIOMASS\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n                         \"\n-- Select columns for output data\nSELECT \nSURVEY_DEFINITION_ID, \nBIOMASS_MT, \nBIOMASS_VAR, \nYEAR\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_BIOMASS\n\n-- Filter data results\nWHERE SPECIES_CODE = 30060 \nAND SURVEY_DEFINITION_ID = 47 \nAND AREA_ID = 99903 \nAND YEAR BETWEEN 1984 AND 2023;\") %&gt;% \n  janitor::clean_names() %&gt;% \n  dplyr::mutate(biomass_kmt = biomass_mt/1000, \n                # **approximate** 95% confidence interval\n                biomass_kci_up = (biomass_mt + (2*sqrt(biomass_var)))/1000, \n                biomass_kci_dw = (biomass_mt - (2*sqrt(biomass_var)))/1000) \n\n\nflextable::flextable(head(dat)) %&gt;%\n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra() %&gt;%\n  flextable::colformat_num(x = ., j = \"year\", big.mark = \"\")\n\n\nEx. 5: GOA Pacific Ocean perch biomass and line plot.survey_definition_idbiomass_mtbiomass_varyearbiomass_kmtbiomass_kci_upbiomass_kci_dw47157,295.12,221,176,9681990157.2951251.553863.0363847483,622.611,803,384,7871993483.6226700.9093266.3358147771,412.841,434,152,2021996771.41281,178.5204364.3051547727,063.5150,983,542,1781999727.06351,504.1955-50.0685447673,155.149,285,342,9222001673.15511,117.1611229.1490147457,421.65,186,126,5292003457.4216601.4511313.39204\n\n\n\na_mean &lt;- dat %&gt;% \n  dplyr::group_by(survey_definition_id) %&gt;% \n  dplyr::summarise(biomass_kmt = mean(biomass_kmt, na.rm = TRUE), \n                   minyr = min(year, na.rm = TRUE), \n                   maxyr = max(year, na.rm = TRUE)) \n\nfigure &lt;-\n  ggplot(data = dat, \n         mapping = aes(x = year, \n                       y = biomass_kmt)) +\n  ggplot2::geom_point(size = 2.5, color = \"grey40\") + \n  ggplot2::scale_x_continuous(\n    name = \"Year\", \n    labels = scales::label_number(\n      accuracy = 1, \n      big.mark = \"\"))   +\n  ggplot2::scale_y_continuous(\n    name = \"Biomass (Kmt)\", \n    labels = comma) +\n  ggplot2::geom_segment(\n    data = a_mean,\n    mapping = aes(x = minyr, \n                  xend = maxyr, \n                  y = biomass_kmt, \n                  yend = biomass_kmt),\n    linetype = \"dashed\", \n    linewidth = 2) +\n  ggplot2::geom_errorbar(\n    mapping = aes(ymin = biomass_kci_dw, ymax = biomass_kci_up),\n    position = position_dodge(.9),\n    alpha = 0.5, width=.2) +\n  ggplot2::ggtitle(\n    label = \"GOA Pacific Ocean Perch Biomass 1984-2021\", \n    subtitle = paste0(\"Mean = \", \n                      formatC(x = a_mean$biomass_kmt, \n                              digits = 2, \n                              big.mark = \",\", \n                              format = \"f\"), \n                      \" Kmt\")) +\n  ggplot2::theme_bw()\n\nfigure\n\n\n\n\nEx. 5: GOA Pacific Ocean perch biomass and line plot."
  },
  {
    "objectID": "content/akfin-api-r.html#ex.-direct-database-query-in-r-using-the-akfingapdata-readmehttpsgithub.commattcallahan-noaaakfingapdatablobmainreadme.rmd-r-package",
    "href": "content/akfin-api-r.html#ex.-direct-database-query-in-r-using-the-akfingapdata-readmehttpsgithub.commattcallahan-noaaakfingapdatablobmainreadme.rmd-r-package",
    "title": "Access API data using R",
    "section": "8.1 Ex. Direct database query in R using the (akfingapdata readme)[https://github.com/MattCallahan-NOAA/akfingapdata/blob/main/README.Rmd] R package:",
    "text": "8.1 Ex. Direct database query in R using the (akfingapdata readme)[https://github.com/MattCallahan-NOAA/akfingapdata/blob/main/README.Rmd] R package:\n\n# load packages\nlibrary(odbc)\nlibrary(getPass)\nlibrary(tidyverse)\n\n# connect to AKFIN Oracle database\ncon &lt;- dbConnect(odbc::odbc(), \"akfin\", UID=getPass(msg=\"USER NAME\"), PWD=getPass())\n\n\n# define species code for pollock\nmy_species &lt;- 21740\n\n#query database\ndata&lt;- dbFetch(dbSendQuery(con,\n                           paste0(\"select * from gap_products.akfin_biomass \nwhere species_name = \", my_species, \n\" and survey_definition_id = 98, \nand area_id = 10\"))) %&gt;%\nrename_with(tolower) # everyone likes lower case letters better\n\nhead(data)"
  },
  {
    "objectID": "content/akfin-api-r.html#ex.-direct-database-query-in-r-using-the-akfingapdata-readmehttpsgithub.commattcallahan-noaaakfingapdatablobmainreadme.rmd-r-package-1",
    "href": "content/akfin-api-r.html#ex.-direct-database-query-in-r-using-the-akfingapdata-readmehttpsgithub.commattcallahan-noaaakfingapdatablobmainreadme.rmd-r-package-1",
    "title": "Access API data using R",
    "section": "8.2 Ex. Direct database query in R using the (akfingapdata readme)[https://github.com/MattCallahan-NOAA/akfingapdata/blob/main/README.Rmd] R package:",
    "text": "8.2 Ex. Direct database query in R using the (akfingapdata readme)[https://github.com/MattCallahan-NOAA/akfingapdata/blob/main/README.Rmd] R package:\n\nlibrary(akfingapdata)\n\n# Sign into akfin with token (need to request token from AKFIN)\ntoken &lt;- akfingapdata::create_token(file = paste0(dirname(here::here()), \"/akfin_token.txt\"))\n\nakfingapdata::get_gap_catch()[,1:6] %&gt;% \n  head() %&gt;% \n  flextable::flextable() %&gt;%\n  flextable::theme_zebra()\n\n\nEx. 2: Load catch data with {akfingapdata}.cruisejoinhauljoincatchjoinspecies_codeweight_kgcount-611-13,626-374,39721,740189.590450-611-13,632-374,64321,740134.830151-611-13,501-370,28321,74032.06044-611-13,545-371,70121,7401,154.0241,345-611-13,577-372,79521,740963.0701,273-611-13,677-376,14621,7401,618.5892,814"
  },
  {
    "objectID": "content/foss-intro.html",
    "href": "content/foss-intro.html",
    "title": "Public Data (FOSS)",
    "section": "",
    "text": "Collaborators and data users\nBelow are a few packages and products currently using this data. If you have developed a product, performed an analysis, or exhibited this data in any way, reach out so we can showcase your hard work."
  },
  {
    "objectID": "content/foss-intro.html#access-constraints",
    "href": "content/foss-intro.html#access-constraints",
    "title": "Public Data (FOSS)",
    "section": "Access Constraints",
    "text": "Access Constraints\nUser Constraints: Users must read and fully comprehend the metadata prior to use. Data should not be used beyond the limits of the source scale. Acknowledgment of AFSC Groundfish Assessment Program, as the source from which these data were obtained, in any publications and/or other representations of these data, is suggested.\nGeneral questions and more specific data requests can be sent to nmfs.afsc.gap.metadata@noaa.gov or submitted as an issue on our GitHub Organization. The version of this data used for stock assessments can be found through the Alaska Fisheries Information Network (AKFIN). For questions about the eastern Bering Sea surveys, contact Duane Stevenson (Duane.Stevenson@noaa.gov). For questions about the Gulf of Alaska or Aleutian Islands surveys, contact Ned Laman (Ned.Laman@noaa.gov). For questions specifically about crab data in any region, contact Mike Litzow (Mike.Litzow@noaa.gov), the Shellfish Assessment Program lead.\nFor questions, comments, and concerns specifically about the Fisheries One Stop Shop (FOSS) platform, please contact us using the Comments page on the FOSS webpage."
  },
  {
    "objectID": "content/foss-intro.html#cite-this-data",
    "href": "content/foss-intro.html#cite-this-data",
    "title": "Public Data (FOSS)",
    "section": "Cite this data",
    "text": "Cite this data\nUse the below bibtext citations, as cited in our group’s citation repository for citing the data created and maintained in this repo (NOAA Fisheries Alaska Fisheries Science Center, 2024). Add “note = {Accessed: mm/dd/yyyy}” to append the day this data was accessed.\n\n\n@misc{FOSSAFSCData,\n  author = {{NOAA Fisheries Alaska Fisheries Science Center}},\n  year = {2023}, \n  title = {Fisheries One Stop Shop Public Data: RACE Division Bottom Trawl Survey Data Query},\n  howpublished = {https://www.fisheries.noaa.gov/foss},\n  publisher = {{U.S. Dep. Commer.}},\n  copyright = {Public Domain} \n}\n\n\n\n\n\n\nNOAA Fisheries Alaska Fisheries Science Center. (2024). Fisheries one stop shop public data: RACE division bottom trawl survey data query. https://www.fisheries.noaa.gov/foss; U.S. Dep. Commer."
  },
  {
    "objectID": "content/foss-metadata.html#data-tables",
    "href": "content/foss-metadata.html#data-tables",
    "title": "Data description",
    "section": "Data tables",
    "text": "Data tables\n\nFOSS_CATCH\nThese datasets, FOSS_CATCH, FOSS_CPUE_PRESONLY, FOSS_HAUL, and FOSS_SPECIES, when full joined by the HAULJOIN variable, includes zero-filled (presence and absence) observations and catch-per-unit-effort (CPUE) estimates for all identified species at for index stations. These tables were created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated March 04, 2024.\nNumber of rows: 939,197\nNumber of columns: 7\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul or samples collected.\n\n\n\n\nCPUE_KGKM2\n\n\nWeight CPUE (kg/km2)\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nCatch weight (kilograms) per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2\n\n\nNumber CPUE (no/km2)\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nNumerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nTAXON_CONFIDENCE\n\n\nTaxon confidence rating\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nConfidence in the ability of the survey team to correctly identify the taxon to the specified level, based solely on identification skill (e.g., not likelihood of a taxon being caught at that station on a location-by-location basis). Quality codes follow: ‘High’: High confidence and consistency. Taxonomy is stable and reliable at this level, and field identification characteristics are well known and reliable. ‘Moderate’: Moderate confidence. Taxonomy may be questionable at this level, or field identification characteristics may be variable and difficult to assess consistently. ‘Low’: Low confidence. Taxonomy is incompletely known, or reliable field identification characteristics are unknown. Documentation: Species identification confidence in the eastern Bering Sea shelf survey (1982-2008), Species identification confidence in the eastern Bering Sea slope survey (1976-2010), and Species identification confidence in the Gulf of Alaska and Aleutian Islands surveys (1980-2011).\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\n\n\n\nFOSS_HAUL\nThese datasets, FOSS_CATCH, FOSS_CPUE_PRESONLY, FOSS_HAUL, and FOSS_SPECIES, when full joined by the HAULJOIN variable, includes zero-filled (presence and absence) observations and catch-per-unit-effort (CPUE) estimates for all identified species at for index stations. These tables were created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated March 04, 2024.\nNumber of rows: 33,334\nNumber of columns: 27\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_SWEPT_KM2\n\n\nArea swept (km)\n\n\nkilometers\n\n\nNUMBER(38,6)\n\n\nThe area the net covered while the net was fishing (kilometers squared), defined as the distance fished times the net width.\n\n\n\n\nBOTTOM_TEMPERATURE_C\n\n\nBottom temperature (degrees Celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nBottom temperature (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nCRUISE\n\n\nCruise Name\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a six-digit integer identifying the cruise number of the form: YYYY99 (where YYYY = year of the cruise; 99 = 2-digit number and is sequential; 01 denotes the first cruise that vessel made in this year, 02 is the second, etc.).\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nUnique integer ID assigned to each survey, vessel, and year combination.\n\n\n\n\nDATE_TIME\n\n\nDate and time\n\n\nMM/DD/YYYY HH::MM\n\n\nDATE\n\n\nThe date (MM/DD/YYYY) and time (HH:MM) of the haul. All dates and times are in Alaska time (AKDT) of Anchorage, AK, USA (UTC/GMT -8 hours).\n\n\n\n\nDEPTH_M\n\n\nDepth (m)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nBottom depth (meters).\n\n\n\n\nDISTANCE_FISHED_KM\n\n\nDistance fished (km)\n\n\ndegrees Celsius\n\n\nNUMBER(38,3)\n\n\nDistance the net fished (thousands of kilometers).\n\n\n\n\nDURATION_HR\n\n\nTow duration (decimal hr)\n\n\nhours\n\n\nNUMBER(38,1)\n\n\nThis is the elapsed time between start and end of a haul (decimal hours).\n\n\n\n\nHAUL\n\n\nHaul number\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a sampling event (haul) within a cruise. It is a sequential number, in chronological order of occurrence.\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nLATITUDE_DD_END\n\n\nEnd latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nLATITUDE_DD_START\n\n\nStart latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nLONGITUDE_DD_END\n\n\nEnd longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nLONGITUDE_DD_START\n\n\nStart longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nNET_HEIGHT_M\n\n\nNet height (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between footrope and headrope of the trawl.\n\n\n\n\nNET_WIDTH_M\n\n\nNet width (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between wingtips of the trawl.\n\n\n\n\nPERFORMANCE\n\n\nHaul performance code\n\n\ncategory\n\n\nNUMBER(38,0)\n\n\nThis denotes what, if any, issues arose during the haul. For more information, review the code books.\n\n\n\n\nSRVY\n\n\nSurvey abbreviation\n\n\ntext abbreviated\n\n\nVARCHAR2(255 BYTE)\n\n\nAbbreviated survey names. The column ‘srvy’ is associated with the ‘survey’ and ‘survey_definition_id’ columns. Northern Bering Sea (NBS), Southeastern Bering Sea (EBS), Bering Sea Slope (BSS), Gulf of Alaska (GOA), Aleutian Islands (AI).\n\n\n\n\nSTATION\n\n\nStation ID\n\n\nID key code\n\n\nVARCHAR2(255 BYTE)\n\n\nAlpha-numeric designation for the station established in the design of a survey.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID key code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\nSURFACE_TEMPERATURE_C\n\n\nSurface temperature (degrees Celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nSurface temperature (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nSURVEY\n\n\nSurvey name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName and description of survey. The column ‘survey’ is associated with the ‘srvy’ and ‘survey_definition_id’ columns.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\nSURVEY_NAME\n\n\nSurvey name official\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLong name of the survey conducted\n\n\n\n\nVESSEL_ID\n\n\nVessel ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nID number of the vessel used to collect data for that haul. The column ‘vessel_id’ is associated with the ‘vessel_name’ column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID key codes, review the code books.\n\n\n\n\nVESSEL_NAME\n\n\nVessel name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName of the vessel used to collect data for that haul. The column ‘vessel_name’ is associated with the ‘vessel_id’ column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID key codes, review the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\n\n\n\nFOSS_SPECIES\nThese datasets, FOSS_CATCH, FOSS_CPUE_PRESONLY, FOSS_HAUL, and FOSS_SPECIES, when full joined by the HAULJOIN variable, includes zero-filled (presence and absence) observations and catch-per-unit-effort (CPUE) estimates for all identified species at for index stations. These tables were created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated March 04, 2024.\nNumber of rows: 1,894\nNumber of columns: 6\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCOMMON_NAME\n\n\nTaxon common name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe common name of the marine organism associated with the ‘scientific_name’ and ‘species_code’ columns. For a complete species list, review the code books.\n\n\n\n\nID_RANK\n\n\nLowest taxonomic rank\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLowest taxonomic rank of a given species entry.\n\n\n\n\nITIS\n\n\nIntegrated taxonomic information system (ITIS) serial number\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSpecies code as identified in the Integrated Taxonomic Information System (https://itis.gov/).\n\n\n\n\nSCIENTIFIC_NAME\n\n\nTaxon scientific name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe scientific name of the organism associated with the ‘common_name’ and ‘species_code’ columns. For a complete taxon list, review the code books.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nWORMS\n\n\nWorld register of marine species (WoRMS) taxonomic serial number\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSpecies code as identified in the World Register of Marine Species (WoRMS) (https://www.marinespecies.org/).\n\n\n\n\n\n\n\nFOSS_SURVEY_SPECIES\nThis reference dataset contains the full list of species by survey to be used to zero-fill FOSS_CATCH and FOSS_HAUL for each survey. These tables were created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated March 04, 2024.\nNumber of rows: 5,030\nNumber of columns: 2\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code uniquely identifies a survey/survey design. The column ‘survey_definition_id’ is associated with the ‘srvy’ and ‘survey’ columns. For a complete list of surveys, review the code books.\n\n\n\n\n\n\n\nFOSS_TAXON_GROUP\nThis reference dataset contains suggested search groups for simplifying species selection in the FOSS data platform so users can better search through FOSS_CATCH. These tables were created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). There are legal restrictions on access to the data. These data are not intended for public dissemination and should not be shared without the explicit written consent of the data managers and owners (NOAA Fisheries). The GitHub repository for the scripts that created this code can be found at https://github.com/afsc-gap-products/gap_products. For more information about codes used in the tables, please refer to the survey code books (https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual). These data were last updated March 04, 2024.\nNumber of rows: 33,721\nNumber of columns: 3\n\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCLASSIFICATION\n\n\nTaxonomic classification rank group\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic classification group rank for a given species.\n\n\n\n\nRANK_ID\n\n\nTaxonomic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nThe taxonomic rank of a taxon identification.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the ‘common_name’ and ‘scientific_name’ columns. For a complete species list, review the code books."
  },
  {
    "objectID": "content/foss-platform.html#select-and-filter",
    "href": "content/foss-platform.html#select-and-filter",
    "title": "Using the FOSS platform",
    "section": "Select and filter",
    "text": "Select and filter\nSelect, filter, and package this and other NOAA Fisheries data from the Fisheries One Stop Shop (FOSS) platform. A user guide for the FOSS platform can be found here. To begin a report, select options from the boxes what you need data for.\nFor a given box, select one or a few options from the “options box” (list on the left) to query by highlighting them. To select multiple options, hold down the CTRL key while clicking on the options of interest, or click and drag down the list. Once the options you wish to be included in your query are highlighted, click the right-pointing arrow (&gt;) to move them into the “selection box” (list on the right). If you accidentally select an option that you do not want to query, simply select the unwanted option from the selection box and click the left-pointing arrow (&lt;).\nIf you wish to select all options from the options box and send them to the selection box, simply click the double right-pointing arrow (&gt;&gt;). If you want to unselect all options from the selection box, use the double left-pointing arrow (&lt;&lt;) or the reset icon.\nTo find a specific species or group more quickly you can use the Search Species option to quickly narrow the options. Search for parts of species common names in the Search Species box by entering a term and clicking the search button. The platform will return a shorter list in the Speices options box of only species that contain a match to that search term.\nUse the Reset All Parameters button to reset all parameters for entire form.\n\n\n\n\n\nDiagram of selection and search tools available on the FOSS platfrom.\n\n\n\n\nFilter options:\n\nSurvey: Each survey has different in design, time series, and history. More information on each survey and their designs can be found in our annual data reports.\nYear: Surveys are not conducted in all years, so only data from the years for which the survey was conducted will be returned.\nSpecies: Common name of all species ever encountered in the survey. Find more information about these species in our survey code books.\n\n\nIn this example, we’ll select for 2022 eastern Bering Sea Pacific cod data. Here, we used the Search Species box to search for species with the term “cod” in their common names and selected “Pacific cod” from that shortened list.\n\n\n\n\n\n\nDiagram of selection and search tools available on the FOSS platofrom."
  },
  {
    "objectID": "content/foss-platform.html#select-data-format",
    "href": "content/foss-platform.html#select-data-format",
    "title": "Using the FOSS platform",
    "section": "Select data format",
    "text": "Select data format\nSelect from the below radio list of pre-designed output tables. Once you run the report, the user can further specify filter data and select columns of interest. The tables below will only include data from the selections made in the previous step.\n\nAll Data Fields: Presence and Absence (zero-filled): The most complete version of the data, including species, catch, haul, and environmental data. This data will include catch data for where species were caught and zeros for where the species were not caught. This is important for calculating catch-per-unit-effort data, preparing distribution plots (e.g., using the akgfmaps R package), and many statistical analyses.\nAll Data Fields: Presence-only (non-zero): The second most complete version of the data, including species, catch, haul, and environmental data. However, this data only includes catch data for where species were caught and does not include zeros for where the species were not caught. This will return smaller, more focused data and can be useful for quickly assessing how many species were caught or how many stations species were caught at.\nCatch data: Presence and Absence (zero-filled): This data set is similar to All Data Fields: Presence and Absence (zero-filled), but only includes catch and species data columns.\nCatch data: Presence-only (non-zero): This data set is similar to All Data Fields: Presence-only (non-zero), but only includes catch and species data columns.\nHaul Data: This data set only includes haul and environmental data collected from the survey. This data will only include one observation per haul event/station.\n\n\nIn this example, we’ll select All Data Fields: Presence and Absence (zero-filled).\n\n\n\n\n\n\nDiagram of the pre-set data format options."
  },
  {
    "objectID": "content/foss-platform.html#run-report",
    "href": "content/foss-platform.html#run-report",
    "title": "Using the FOSS platform",
    "section": "Run report",
    "text": "Run report\nClick the RUN REPORT button. Below the select and filter area, the results of your query will appear below the page in the format you selected. To change the format, make a different selection and run the report again. Further modifications to your results can be made by clicking on the Actions button above your data. Here you can download your data, select columns included in your results, and apply a variety of filters and mathematical tools.\n\n\n\n\n\nExample data returned from running the report."
  },
  {
    "objectID": "content/foss-api-r.html#ex.-1-load-the-first-25-rows-default-of-data",
    "href": "content/foss-api-r.html#ex.-1-load-the-first-25-rows-default-of-data",
    "title": "Access via API and R",
    "section": "Ex. 1: Load the first 25 rows (default) of data",
    "text": "Ex. 1: Load the first 25 rows (default) of data\n\n# install.packages(c(\"httr\", \"jsonlite\"))\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(dplyr)\n\n# link to the API\napi_link &lt;- \"https://apps-st.fisheries.noaa.gov/ods/foss/afsc_groundfish_survey/\"\n\nres &lt;- httr::GET(url = api_link)\n# res # Test connection\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\n# names(data)\ntibble::as_tibble(data$items) %&gt;% \n  dplyr::mutate_if(is.character, type.convert, as.is = TRUE) %&gt;%\n  dplyr::mutate(across(where(is.numeric), round, 3)) %&gt;%\n  head(3) %&gt;%\n  flextable::flextable() %&gt;%\n  flextable::theme_zebra() %&gt;%\n  flextable::colformat_num(x = ., j = c(\"year\", \"cruise\", \"species_code\", \"tsn\", \"ak_survey_id\"), big.mark = \"\")\n\n\nEx. 1: Load the first 25 rows (default) of data.yearsrvysurveysurvey_idcruisehaulstratumstationvessel_namevessel_iddate_timelatitude_ddlongitude_ddspecies_codecommon_namescientific_nametaxon_confidencecpue_kghacpue_kgkm2cpue_kg1000km2cpue_nohacpue_nokm2cpue_no1000km2weight_kgcountbottom_temperature_csurface_temperature_cdepth_mdistance_fished_kmnet_width_mnet_height_marea_swept_haduration_hrtsnak_survey_idlinks2002AIAleutian Islands Bottom Trawl Survey522002016722307-63Vesteraalen9405/17/2002 18:56:5853.737-167.01695020feathery bryozoanEucratea loricataLow0.0171.7491,749.4450.04404.15.31871.56116.1127.252.5150.281558091917453[[data.frame]]2002AIAleutian Islands Bottom Trawl Survey522002016722307-63Vesteraalen9405/17/2002 18:56:5853.737-167.01679000squid unid.DecapodiformesHigh0.0222.2272,226.5673.181318.081318,080.930.05684.15.31871.56116.1127.252.5150.281917454[[data.frame]]2002AIAleutian Islands Bottom Trawl Survey522002016722307-63Vesteraalen9405/17/2002 18:56:5853.737-167.01624191shortfin eelpoutLycodes brevipesHigh0.0363.5783,578.4100.79579.52079,520.230.09024.15.31871.56116.1127.252.5150.281652581917455[[data.frame]]"
  },
  {
    "objectID": "content/foss-api-r.html#ex.-2-load-the-first-10000-rows-of-data",
    "href": "content/foss-api-r.html#ex.-2-load-the-first-10000-rows-of-data",
    "title": "Access via API and R",
    "section": "Ex. 2: Load the first 10000 rows of data",
    "text": "Ex. 2: Load the first 10000 rows of data\n\n# Not run because too big:\nres &lt;- httr::GET(url = paste0(api_link, \"?offset=0&limit=10000\"))\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\nprint(paste0(\"rows: \", dim(data$items)[1], \"; cols: \", dim(data$items)[2]))\n\n[1] \"rows: 10000; cols: 36\""
  },
  {
    "objectID": "content/foss-api-r.html#ex.-3-filter-by-year",
    "href": "content/foss-api-r.html#ex.-3-filter-by-year",
    "title": "Access via API and R",
    "section": "Ex. 3: Filter by Year",
    "text": "Ex. 3: Filter by Year\nShow all the data greater than the year 2020.\n\nres &lt;- httr::GET(url = paste0(api_link, '?q={\"year\":{\"$gt\":2020}}'))\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\n\nas_tibble(data$items) %&gt;% \n  mutate_if(is.character, type.convert, as.is = TRUE) %&gt;%\n  head(3) %&gt;%\n  dplyr::mutate(across(where(is.numeric), round, 3)) %&gt;%\n  dplyr::select(year, srvy, stratum, species_code, cpue_kgkm2) %&gt;%\n  flextable::flextable() %&gt;%\n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra() %&gt;%\n  flextable::colformat_num(x = ., j = c(\"year\", \"species_code\"), big.mark = \"\") \n\n\nEx. 3: Filter by Year.yearsrvystratumspecies_codecpue_kgkm22022AI793805400.3612022AI7934010.9032022AI793200061.661"
  },
  {
    "objectID": "content/foss-api-r.html#ex.-4-filter-by-species-name",
    "href": "content/foss-api-r.html#ex.-4-filter-by-species-name",
    "title": "Access via API and R",
    "section": "Ex. 4: Filter by species name",
    "text": "Ex. 4: Filter by species name\nShow all the data where the product name contains pollock Please note that here the word pollock is case sensitive.\nThe notation for finding a string is to use % around it. Since % is a reserved character in a URL, you have to replace % with %25.\n\nres &lt;- httr::GET(\n  url = paste0(api_link, '?q={\"common_name\":{\"$like\":\"%25pollock%25\"}}'))\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\n\nas_tibble(data$items) %&gt;% \n  mutate_if(is.character, type.convert, as.is = TRUE) %&gt;%\n  head(3) %&gt;%\n  dplyr::mutate(across(where(is.numeric), round, 3)) %&gt;%\n  dplyr::select(year, srvy, stratum, species_code, cpue_kgkm2) %&gt;%\n  flextable::flextable() %&gt;%\n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra() %&gt;%\n  flextable::colformat_num(x = ., j = c(\"year\", \"species_code\"), big.mark = \"\") \n\n\nEx. 4: Filter by species name.yearsrvystratumspecies_codecpue_kgkm22002AI72221740775.3222002AI7222174010,685.8062002AI721217400.640"
  },
  {
    "objectID": "content/foss-api-r.html#ex.-5-combination-of-year-and-name-filters",
    "href": "content/foss-api-r.html#ex.-5-combination-of-year-and-name-filters",
    "title": "Access via API and R",
    "section": "Ex. 5: Combination of year and name filters",
    "text": "Ex. 5: Combination of year and name filters\nShow all the data where years &gt; 2020 and the product name contains pollock\n\nres &lt;- httr::GET(\n  url = paste0(api_link, \n               '?q={\"year\":{\"$gt\":2020},\"common_name\":{\"$like\":\"%25pollock%25\"}}'))\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\n\nas_tibble(data$items) %&gt;% \n  mutate_if(is.character, type.convert, as.is = TRUE) %&gt;%\n  head(3) %&gt;%\n  dplyr::mutate(across(where(is.numeric), round, 3)) %&gt;%\n  dplyr::select(year, srvy, stratum, species_code, cpue_kgkm2) %&gt;%\n  flextable::flextable() %&gt;%\n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra() %&gt;%\n  flextable::colformat_num(x = ., j = c(\"year\", \"species_code\"), big.mark = \"\") \n\n\nEx. 5: Combination of year and name filters.yearsrvystratumspecies_codecpue_kgkm22022AI793217407,853.6322022AI721217407,235.0102022AI7222174022,754.334"
  },
  {
    "objectID": "content/foss-api-r.html#ex.-6-combination-of-year-srvy-stratum",
    "href": "content/foss-api-r.html#ex.-6-combination-of-year-srvy-stratum",
    "title": "Access via API and R",
    "section": "Ex. 6: Combination of year, srvy, stratum",
    "text": "Ex. 6: Combination of year, srvy, stratum\nShow all the data where year = 1989, srvy = “EBS”, and stratum is not equal to 81\n\nres &lt;- httr::GET(\n  url = paste0(api_link, '?q={\"year\":1989,\"srvy\":\"EBS\",\"stratum\":{\"$ne\":\"81\"}}'))\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\n\nas_tibble(data$items) %&gt;% \n  mutate_if(is.character, type.convert, as.is = TRUE) %&gt;%\n  head(3) %&gt;%\n  dplyr::mutate(across(where(is.numeric), round, 3)) %&gt;%\n  dplyr::select(year, srvy, stratum, species_code, cpue_kgkm2) %&gt;%\n  flextable::flextable() %&gt;%\n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra() %&gt;%\n  flextable::colformat_num(x = ., j = c(\"year\", \"species_code\"), big.mark = \"\") \n\n\nEx. 6: Combination of year, srvy, stratum.yearsrvystratumspecies_codecpue_kgkm21989EBS10665481.1641989EBS10693221.1641989EBS10430002.353"
  },
  {
    "objectID": "content/foss-api-r.html#ex.-7-visualize-cpue-data-in-distribution-map",
    "href": "content/foss-api-r.html#ex.-7-visualize-cpue-data-in-distribution-map",
    "title": "Access via API and R",
    "section": "Ex. 7: Visualize CPUE data in distribution map",
    "text": "Ex. 7: Visualize CPUE data in distribution map\nPacific cod catch-per-unit-effort estimates for NBS in 2021 and map constructed using akgfmaps.\n\n# res &lt;- httr::GET(\n#   url = paste0(api_link, \"?offset=0&limit=10000\"), \n#   query = list(year = 2021, srvy = \"EBS\", species_code = 30060))\nres &lt;- httr::GET(\n  url = paste0(api_link, '?q={\"year\":2021,\"srvy\":\"NBS\",\"species_code\":21720}'))\ndata_catch &lt;- jsonlite::fromJSON(base::rawToChar(res$content))$items %&gt;% \n  dplyr::select(stratum, station, cpue_kgkm2) \n\n# zero-fill data (imperfectly, but effective for this example)\nres &lt;- httr::GET(\n  url = paste0(api_link, '?q={\"year\":2021,\"srvy\":\"NBS\"}offset=0&limit=10000'))\ndata_haul &lt;- jsonlite::fromJSON(base::rawToChar(res$content))$items %&gt;% \n  dplyr::select(stratum, station, latitude_dd, longitude_dd) %&gt;%\n  dplyr::mutate(across(where(is.numeric), round, 3)) %&gt;% \n  dplyr::distinct()\n\ndata &lt;- dplyr::left_join(data_haul, data_catch) %&gt;% \n  dplyr::mutate(cpue_kgkm2 = ifelse(is.na(cpue_kgkm2), 0, cpue_kgkm2), \n                dplyr::across(dplyr::everything(), as.numeric)) \n\nflextable::flextable(data[1:3,]) %&gt;% \n  flextable::fit_to_width(max_width = 6) %&gt;% \n  flextable::theme_zebra() \n\n\nEx. 7: Visualize CPUE data in distribution map.stratumstationlatitude_ddlongitude_ddcpue_kgkm28161.66434-172.26552,895.2588162.33740-173.17021,235.5457062.03713-171.65280.000\n\n\n\n# devtools::install_github(\"afsc-gap-products/akgfmaps\", build_vignettes = TRUE)\nlibrary(akgfmaps)\n\nfigure &lt;- akgfmaps::make_idw_map(\n  CPUE_KGHA = data$cpue_kgkm2, # calculates the same, regardless of units.  \n  LATITUDE = data$latitude_dd, \n  LONGITUDE = data$longitude_dd, \n  region = \"bs.north\", # Predefined EBS area\n  set.breaks = \"jenks\", # Gets Jenks breaks from classint::classIntervals()\n  in.crs = \"+proj=longlat\", # Set input coordinate reference system\n  out.crs = \"EPSG:3338\", # Set output coordinate reference system\n  grid.cell = c(20000, 20000))$plot + # 20x20km grid\n  ggplot2::guides(fill=guide_legend(title = \"Pacific cod\\nCPUE (kg/km2)\"))\n\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n\nfigure\n\n\n\n\nEx. 7: Visualize CPUE data in distribution map."
  },
  {
    "objectID": "content/foss-api-py.html",
    "href": "content/foss-api-py.html",
    "title": "Access via API and Python",
    "section": "",
    "text": "{afscgap} Library Installation\n\nauthor: Sam Pottinger (sam.pottinger@berkeley.edu; GitHub::sampottinger) date: May 13, 2023\n\nThe third-party afscgap Python package interfaces with FOSS to access AFSC GAP data. It can be installed via pip:\n\n#The reticulate package provides a comprehensive set of tools for interoperability between Python and R. \nlibrary(reticulate)\n\n\npip install afscgap\npip install git+https://github.com/SchmidtDSE/afscgap.git@main\n\nFor more information on installation and deployment, see the library documentation.\n\n\nBasic query\nThis first example queries for Pacific glass shrimp (Pasiphaea pacifica) in the Gulf of Alaska in 2021. The library will automatically generate HTTP queries, converting from Python types to ORDS query syntax.\n\nimport afscgap\n\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\n\nresults = query.execute()\n\nThe results variable in this example is an iterator that will automatically perform pagination behind the scenes.\n\n\nIterating with a for loop\nThe easiest way to interact with results is a simple for loop. This next example determines the frequency of different catch per unit effort where Pacific glass shrimp were reported:\n\nimport afscgap\n\n# Mapping from CPUE to count\ncount_by_cpue = {}\n\n# Build query\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nresults = query.execute()\n\n# Iterate through results and count\nfor record in results:\n  cpue = record.get_cpue_weight(units='kg/ha')\n  cpue_rounded = round(cpue)\n  count = count_by_cpue.get(cpue_rounded, 0) + 1\n  count_by_cpue[cpue_rounded] = count\n\n# Print the result\nprint(count_by_cpue)\n\nNote that, in this example, only records with Pacific glass shrimp are included (“presence-only” data). See zero catch inference below. In other words, it reports on CPUE only for hauls in which Pacific glass shrimp were recorded, excluding some hauls like those in which Pacific glass shrimp were not found at all.\n\n\nIterating with functional programming\nA for loop is not the only option for iterating through results. List comprehensions and other functional programming methods can be used as well.\n\nimport statistics\n\nimport afscgap\n\n# Build query\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nresults = query.execute()\n\n# Get temperatures in Celsius\ntemperatures = [record.get_bottom_temperature(units='c') for record in results]\n\n# Take the median\nprint(statistics.median(temperatures))\n\nThis example reports the median temperature in Celcius for when Pacific glass shrimp was reported.\n\n\nLoad into Pandas\nThe results from the afscgap package are serializable and can be loaded into other tools like Pandas. This example loads Pacific glass shrimp from 2021 Gulf of Alaska into a data frame.\n\nimport pandas\n\nimport afscgap\n\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nresults = query.execute()\n\npandas.DataFrame(results.to_dicts())\n\nSpecifically, to_dicts provides an iterator over a dictionary form of the data that can be read into tools like Pandas.\n\n\nAdvanced filtering\nQueries so far have focused on filters requiring equality but range queries can be built as well.\n\nimport afscgap\n\n# Build query\nquery = afscgap.Query()\nquery.filter_year(min_val=2015, max_val=2019)   # Note min/max_val\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nresults = query.execute()\n\n# Sum weight\nweights = map(lambda x: x.get_weight(units='kg'), results)\ntotal_weight = sum(weights)\nprint(total_weight)\n\nThis example queries for Pacific glass shrimp data between 2015 and 2019, summing the total weight caught. Note that most users will likely take advantage of built-in Python to ORDS query generation which dictates how the library communicates with the API service. However, users can provide raw ORDS queries as well using manual filtering.\n\n\nZero-catch inference\nUntil this point, these examples use presence-only data. However, the afscgap package can infer negative or “zero catch” records as well.\n\nimport afscgap\n\n# Mapping from CPUE to count\ncount_by_cpue = {}\n\n# Build query\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nquery.set_presence_only(False)  # Added to earlier example\nresults = query.execute()\n\n# Iterate through results and count\nfor record in results:\n  cpue = record.get_cpue_weight(units='kg/ha')\n  cpue_rounded = round(cpue)\n  count = count_by_cpue.get(cpue_rounded, 0) + 1\n  count_by_cpue[cpue_rounded] = count\n\n# Print the result\nprint(count_by_cpue)\n\nThis example revisits the earlier snippet for CPUE counts but set_presence_only(False) directs the library to look at additional data on hauls, determining which hauls did not have Pacific glass shrimp. This lets the library return records for hauls in which Pacific glass shrimp were not found. This can be seen in differences in counts reported:\n\n\n\n\n\n\n\n\nRounded CPUE\nCount with set_presence_only(True)\nCount with set_presence_only(False)\n\n\n\n\n0 kg/ha\n44\n521\n\n\n1 kg/ha\n7\n7\n\n\n2 kg/ha\n1\n1\n\n\n\nPut simply, while the earlier example showed CPUE counts for hauls in which Pacific glass shrimp were seen, this revised example reports for all hauls in the Gulf of Alaska in 2021.\n\n\nMore information\nPlease see the API documentation for the Python library for additional details."
  },
  {
    "objectID": "content/foss-oracle-r.html",
    "href": "content/foss-oracle-r.html",
    "title": "Access via Oracle and R (AFSC only)",
    "section": "",
    "text": "If the user has access to the AFSC Oracle database, the user can use SQL developer to view and pull the FOSS public data directly from the GAP_PRODUCTS Oracle schema.\n\nConnect to Oracle from R\nMany users will want to access the data from Oracle using R. The user will need to install the RODBC R package and ask OFIS (IT) connect R to Oracle. Then, use the following code in R to establish a connection from R to Oracle:\nHere, the user can write in their username and password directly into the RODBC connect function. Never save usernames or passwords in scripts that may be intentionally or unintentionally shared with others. If no username and password is entered in the function, pop-ups will appear on the screen asking for the username and password.\n\nlibrary(gapindex)\nchannel &lt;- gapindex::get_connected()\n\n\n\nEx. 1: Join data\nTo join these tables in Oracle, you may use a variant of the following code:\n\nSELECT \nhh.YEAR,\nhh.SRVY,                 \nhh.SURVEY,\nhh.SURVEY_DEFINITION_ID,\nhh.SURVEY_NAME,\nhh.CRUISE,\nhh.CRUISEJOIN,           \nhh.HAUL,\nhh.HAULJOIN,\nhh.STRATUM,\nhh.STATION,\nhh.VESSEL_ID,\nhh.VESSEL_NAME,          \nhh.DATE_TIME,\nhh.LATITUDE_DD_START, \nhh.LONGITUDE_DD_START, \nhh.LATITUDE_DD_END,\nhh.LONGITUDE_DD_END, \nhh.BOTTOM_TEMPERATURE_C,\nhh.SURFACE_TEMPERATURE_C,\nhh.DEPTH_M,\ncc.SPECIES_CODE,\nss.ITIS,\nss.WORMS,\nss.COMMON_NAME,     \nss.SCIENTIFIC_NAME,\nss.ID_RANK,\nCASE WHEN cc.CPUE_KGKM2 IS NULL THEN 0 ELSE cc.CPUE_KGKM2 END AS CPUE_KGKM2,\nCASE WHEN cc.CPUE_NOKM2 IS NULL THEN 0 ELSE cc.CPUE_NOKM2 END AS CPUE_NOKM2,\nCASE WHEN cc.COUNT IS NULL THEN 0 ELSE cc.COUNT END AS COUNT,\nCASE WHEN cc.WEIGHT_KG IS NULL THEN 0 ELSE cc.WEIGHT_KG END AS WEIGHT_KG,\nCASE WHEN cc.TAXON_CONFIDENCE IS NULL THEN NULL ELSE cc.TAXON_CONFIDENCE END AS TAXON_CONFIDENCE,\nhh.AREA_SWEPT_KM2,       \nhh.DISTANCE_FISHED_KM,\nhh.DURATION_HR,          \nhh.NET_WIDTH_M,\nhh.NET_HEIGHT_M,\nhh.PERFORMANCE \nFROM GAP_PRODUCTS.FOSS_SURVEY_SPECIES sv\nFULL OUTER JOIN GAP_PRODUCTS.FOSS_SPECIES ss\nON sv.SPECIES_CODE = ss.SPECIES_CODE\nFULL OUTER JOIN GAP_PRODUCTS.FOSS_HAUL hh\nON sv.SURVEY_DEFINITION_ID = hh.SURVEY_DEFINITION_ID\nFULL OUTER JOIN GAP_PRODUCTS.FOSS_CATCH cc\nON sv.SPECIES_CODE = cc.SPECIES_CODE\nAND hh.HAULJOIN = cc.HAULJOIN\n\n\n\nEx. 2: Subset data\nHere, we are pulling EBS Pacific cod from 2010 - 2021:\n\n# Pull data\na &lt;- RODBC::sqlQuery(\nchannel = channel, \nquery = \n\"SELECT * FROM GAP_PRODUCTS.FOSS_CATCH cc\nJOIN GAP_PRODUCTS.FOSS_HAUL hh\nON cc.HAULJOIN = hh.HAULJOIN\nWHERE SRVY = 'EBS' \nAND SPECIES_CODE = 21720 -- 'Pacific cod' \nAND YEAR &gt;= 2010 \nAND YEAR &lt; 2021\")\n\nhead(a)\n\n  HAULJOIN SPECIES_CODE CPUE_KGKM2 CPUE_NOKM2 COUNT WEIGHT_KG TAXON_CONFIDENCE\n1   -19288        21720   449.8301  1876.1759    83     19.90                1\n2   -19252        21720   413.4828   248.0897    12     20.00                1\n3   -18731        21720   946.3481  2592.1327   118     43.08                1\n4   -18165        21720  1053.2723   241.8536    12     52.26                1\n5   -17850        21720   990.1357   152.2616     7     45.52                1\n6   -17715        21720   491.3252   218.1905    11     24.77                1\n  YEAR SRVY             SURVEY SURVEY_DEFINITION_ID\n1 2019  EBS eastern Bering Sea                   98\n2 2019  EBS eastern Bering Sea                   98\n3 2019  EBS eastern Bering Sea                   98\n4 2018  EBS eastern Bering Sea                   98\n5 2018  EBS eastern Bering Sea                   98\n6 2018  EBS eastern Bering Sea                   98\n                                             SURVEY_NAME CRUISE CRUISEJOIN\n1 Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey 201901       -727\n2 Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey 201901       -727\n3 Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey 201901       -726\n4 Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey 201801       -723\n5 Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey 201801       -723\n6 Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey 201801       -723\n  HAULJOIN.1 HAUL STRATUM STATION VESSEL_ID   VESSEL_NAME           DATE_TIME\n1     -19288   96      20    O-18       162 ALASKA KNIGHT 2019-06-29 06:54:00\n2     -19252   76      31    G-03       162 ALASKA KNIGHT 2019-06-24 15:52:02\n3     -18731   11      31    I-13        94   VESTERAALEN 2019-06-04 13:15:57\n4     -18165  172      62    Q-27       162 ALASKA KNIGHT 2018-07-26 07:49:26\n5     -17850  117      32    F-19       162 ALASKA KNIGHT 2018-07-02 09:49:43\n6     -17715   92      20    O-18       162 ALASKA KNIGHT 2018-06-26 17:42:00\n  LATITUDE_DD_START LONGITUDE_DD_START LATITUDE_DD_END LONGITUDE_DD_END\n1          59.68079          -168.6144        59.65546        -168.6178\n2          57.01591          -166.4752        56.99137        -166.4601\n3          57.69052          -160.2580        57.66518        -160.2640\n4          60.31173          -174.7032        60.33716        -174.7090\n5          56.67170          -168.9406        56.67359        -168.8919\n6          59.66752          -168.6701        59.67396        -168.6189\n  BOTTOM_TEMPERATURE_C SURFACE_TEMPERATURE_C DEPTH_M DISTANCE_FISHED_KM\n1                  5.1                   7.8      39              2.821\n2                  4.1                   9.7      74              2.880\n3                  5.5                   7.5      54              2.840\n4                  3.2                  10.1     103              2.845\n5                  4.5                   8.8      99              3.005\n6                  5.9                   5.9      40              2.981\n  DURATION_HR NET_WIDTH_M NET_HEIGHT_M AREA_SWEPT_KM2 PERFORMANCE\n1       0.505      15.682        2.227       0.044239           0\n2       0.528      16.795        2.126       0.048370           0\n3       0.520      16.029        2.200       0.045522           0\n4       0.511      17.440        2.200       0.049617           0\n5       0.525      15.299        2.152       0.045973           0\n6       0.517      16.912        1.736       0.050415           0\n\n\n\n\nEx. 3: Find all species found in the eastern Bering Sea (EBS) survey in 2023\n\n# Pull data\na &lt;- RODBC::sqlQuery(\nchannel = channel, \nquery = \n\"SELECT DISTINCT \nss.COMMON_NAME,\nss.SCIENTIFIC_NAME, \nss.ID_RANK, \nss.WORMS\nFROM GAP_PRODUCTS.FOSS_CATCH cc -- get species codes\nLEFT JOIN GAP_PRODUCTS.FOSS_SPECIES ss -- get species info\nON cc.SPECIES_CODE = ss.SPECIES_CODE\nLEFT JOIN GAP_PRODUCTS.FOSS_HAUL hh -- filter by year and survey\nON cc.HAULJOIN = hh.HAULJOIN\nWHERE hh.YEAR = 2023\nAND hh.SURVEY_DEFINITION_ID = 98 -- EBS survey\nORDER BY COMMON_NAME\")\n\nhead(a)\n\n            COMMON_NAME                 SCIENTIFIC_NAME ID_RANK   WORMS\n1   Alaska great-tellin               Megangulus luteus species  423511\n2         Alaska plaice Pleuronectes quadrituberculatus species  254564\n3          Alaska razor                    Siliqua alta species  413689\n4          Alaska skate             Arctoraja parmifera species 1577324\n5 Alaska skate egg case    Arctoraja parmifera egg case species      NA\n6        Alaskan hermit              Pagurus ochotensis species  366742"
  },
  {
    "objectID": "content/other-intro.html",
    "href": "content/other-intro.html",
    "title": "Data Products & Tools",
    "section": "",
    "text": "To accompany these data, we also produce data products to make using our data more accessible and straightforward.\n\n\n\nSurvey of products developed by GAPProductPoint of ContactGOA/AIPoint of ContactBSDescriptionDataFinalized bottom trawl dataNed LamanDuane StevensonNOAA-NMFS-AFSC-RACE-GAP bottom trawl data that has completed the post-survey internal QAQC process.Data requestsNancy RobersonNancy RobersonTo request a subset of the NOAA-NMFS-AFSC-RACE-GAP bottom trawl raw data or a data product.Species codebookNancy RobersonChris AndersonList of codes used for fish and invertebrates identified in NOAA-NMFS-AFSC-RACE-GAP Division surveys. Survey protocolsNancy RobersonNancy RobersonDocumentation of NOAA-NMFS-AFSC-RACE-GAP groundfish bottom trawl survey protocols.AnalysisDesign-based indices for target speciesNed LamanRebecca HaehnStandard design-based indices of biomass and abundance from NOAA-NMFS-AFSC-RACE-GAP bottom trawl survey data.Design-based age or length compositionNed LamanRebecca HaehnStandard design-based indices of size and age composition from NOAA-NMFS-AFSC-RACE-GAP bottom trawl survey data.Model-based indices, age comps (stock assessment), area occupied, and COG (ESP)Cecilia O'Leary Lewis BarnettSpatiotemporal model-based biomass indices, abundance indices, and age composition from NOAA-NMFS-AFSC-RACE-GAP bottom trawl survey data.Annual bottom and surface temperature summary (ESR, stock assessment)Cecilia O'LearySean Rohan &Lewis BarnettSummary metrics for bottom trawl bottom and surface temperatures relative to historical baseline.Bering Sea cold pool index and temperature data products (ESR, ESP, stock assessment)-Sean Rohan &Lewis BarnettCreate annual temperature rasters for the EBS, calculate the EBS cold pool index and temperature data products, and produce visualizations.Annual fish condition (ESR)Cecilia O'LearyBianca Prohaska &Sean RohanGroundfish morphometric condition for fish in the Bering Sea, Aleutian Islands, and Gulf of Alaska.Rockfish indices vs environmental gradients (ESR)Alexandra Dowlin-GOA/AI survey trends in distribution and abundance of 6 rockfishes across 3 environmental gradients in the North Pacific.Structure-Forming Invertebrates-Habitat Areas of Particular Concern (SFI-HAPC) (ESR)Ned Laman-Relative abundance of sponges, hydrocorals, soft corals, Gorgonians, anemones, and Pennatulaceans in GOA and AI surveys.Forage fishes (ESR)Ned Laman-Relative abundance of capelin, eulachon, sandfish, sand lance, and prickelbacks in GOA and AI surveys.Miscellaneous species (ESR)Ned LamanThaddeus BuserRelative abundance of echinoderms, poachers, shrimp and eelpouts in GOA and AI surveys.Jellies (ESR)Ned LamanThaddeus BuserRelative abundance of sea jellies in GOA and AI surveys.Essential fish habitatMegsie Siple Sean RohanHabitat maps for groundfish and crab based on species distribution models. Updated every five years.Visualization ToolsAlaska groundfish maps (CPUE, etc.)-Sean RohanVisualization tool for the Alaska survey regions.CommunicationAnnual survey data reportMegsie Siple &Bethany RiggleEmily Markowitz, Sophia Wassermann, Nicole Charriere, Chris AndersonAlaska Fisheries Science Center NOAA Technical Memorandum summary of the survey progress and findings. These are available online and the latest publications for each survey are listed below (https://repository.library.noaa.gov/). ADF&G report of research activitiesAlexandra DowlinNicole Charriere &Rebecca HaehnReport on AI and GOA trawl survey fishing activity inside and outside of Alaska State waters.IPHC Report-Rebecca HaehnPlan team survey results presentationNed LamanDuane StevensonNOAA-NMFS-AFSC-RACE-GAP present their findings to the North Pacific Groundfish Plan Team; presentations, recordings, and attachments located here: https://www.npfmc.org/about-the-council/plan-teams/bsai-and-goa-groundfish/. Community highlights reportTBDEmily MarkowitzCompilation of NOAA-NMFS-AFSC-RACE-GAP survey findings for communities around Alaska. Bottom Trawl Survey Temperature and Progress MapsNed LamanEmily MarkowitzNear real-time survey progress and ocean temperatures recorded during the Aleutian Islands, Gulf of Alaska, and Bering Sea Bottom Trawl Surveys."
  },
  {
    "objectID": "content/other-pkgs.html#r-packages",
    "href": "content/other-pkgs.html#r-packages",
    "title": "Open source code",
    "section": "R Packages",
    "text": "R Packages\n\nakgfmaps R package\nBttom trawl survey maps layers and plotting examples. POC: Sean Rohan\n\n\ncoldpool R package\nCold pool area and temperature data products for the Bering Sea. POC: Sean Rohan\n\n\nakfishcondition R package\nGroundfish morphometric condition indicators for fish in the Bering Sea, Aleutian Islands, and Gulf of Alaska. POC: Sean Rohan\n\n\ngapindex R package\nCalculation of Design-Based Indices of Abundance and Composition for AFSC GAP Bottom Trawl Surveys. POC: Zack Oyafuso and Margaret Siple"
  },
  {
    "objectID": "content/end-contact-us.html#this-code-is-primarally-maintained-by",
    "href": "content/end-contact-us.html#this-code-is-primarally-maintained-by",
    "title": "Contact us",
    "section": "This code is primarally maintained by:",
    "text": "This code is primarally maintained by:\nEmily Markowitz (Emily.Markowitz AT noaa.gov; @EmilyMarkowitz-NOAA)\nZack Oyafuso (Zack.Oyafuso AT noaa.gov; @zoyafuso-NOAA)\nSarah Friedman (Sarah.Friedman AT noaa.gov; @SarahFriedman-NOAA)\nAlaska Fisheries Science Center,\nNational Marine Fisheries Service,\nNational Oceanic and Atmospheric Administration,\nSeattle, WA 98195\nGeneral questions and more specific data requests can be sent to nmfs.afsc.gap.metadata@noaa.gov or submitted as an issue on our GitHub Organization. The version of this data used for stock assessments can be found through the Alaska Fisheries Information Network (AKFIN). For questions about the eastern Bering Sea surveys, contact Duane Stevenson (Duane.Stevenson@noaa.gov). For questions about the Gulf of Alaska or Aleutian Islands surveys, contact Ned Laman (Ned.Laman@noaa.gov). For questions specifically about crab data in any region, contact Mike Litzow (Mike.Litzow@noaa.gov), the Shellfish Assessment Program lead.\nFor questions, comments, and concerns specifically about the Fisheries One Stop Shop (FOSS) platform, please contact us using the Comments page on the FOSS webpage."
  },
  {
    "objectID": "content/end-run-notes.html",
    "href": "content/end-run-notes.html",
    "title": "Production run notes",
    "section": "",
    "text": "R Version Metadata\n\n\nR version 4.3.1 (2023-06-16 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.7   rstudioapi_0.15.0 yaml_2.3.8       \n [9] rmarkdown_2.25    knitr_1.45        jsonlite_1.8.8    xfun_0.41        \n[13] digest_0.6.33     rlang_1.1.2       evaluate_0.23    \n\n\n\nNOAA README\nThis repository is a scientific product and is not official communication of the National Oceanic and Atmospheric Administration, or the United States Department of Commerce. All NOAA GitHub project code is provided on an ‘as is’ basis and the user assumes responsibility for its use. Any claims against the Department of Commerce or Department of Commerce bureaus stemming from the use of this GitHub project will be governed by all applicable Federal law. Any reference to specific commercial products, processes, or services by service mark, trademark, manufacturer, or otherwise, does not constitute or imply their endorsement, recommendation or favoring by the Department of Commerce. The Department of Commerce seal and logo, or the seal and logo of a DOC bureau, shall not be used in any manner to imply endorsement of any commercial product or activity by DOC or the United States Government.\n\n\nNOAA License\nSoftware code created by U.S. Government employees is not subject to copyright in the United States (17 U.S.C. §105). The United States/Department of Commerce reserve all rights to seek and obtain copyright protection in countries other than the United States for Software authored in its entirety by the Department of Commerce. To this end, the Department of Commerce hereby grants to Recipient a royalty-free, nonexclusive license to use, copy, and create derivative works of the Software outside of the United States."
  },
  {
    "objectID": "content/end-acknowledgements.html",
    "href": "content/end-acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "Community Acknowledgments\nWe would like to thank the many communities of Alaska and their members who have helped contribute to this body of work. The knowledge, experiences, and insights have been instrumental in expanding the scope of our science and knowledge to encompass the many issues that face this important ecosystem. We appreciate feedback from those residing in the region that are willing to share their insights and participation in an open dialog about how we can improve our collective knowledge of the ecosystem and the region.\nWe would like to thank the many communities of the Bering Strait region and their members who have helped contribute to this document. The knowledge, experiences, and insights of the people of the Bering Strait region have been instrumental in expanding the scope of our science and knowledge to encompass the many issues that face this important ecosystem. We appreciate feedback from those residing in the region that are willing to share their insights, including the local names used for the species covered by this document, identifying species of interest or concern that should be included in this document, and participation in an open dialog about how we can improve our collective knowledge of the ecosystem and the region.\nNOAA Fisheries Alaska Fisheries Science Center’s work is conducted in the waters and along the coastlines of Alaska, which include the traditional home lands and waters of the Inupiat, Yupiit, Siberian Yupiit, Unangax, Alutiiq/Sugpiaq, Eyak, Dena’ina Athabascan, Tlingit, Haida, and Tsimshian who have stewarded their lands and waters since time immemorial. We are indebted to these peoples for their wisdom and knowledge of their lands and waters.\nThis document was prepared in the greater Seattle area, which are the traditional lands of the Coast Salish people, including the Duwamish people, past and present. We are grateful for their continued sharing of vision, wisdom, values, and leadership.\nThis quarto book is based off the NOAA-quarto-book GitHub repo designed by Eli Holmes.\nThis repo and GitHub Action was based on the tutorial by Openscapes quarto-website-tutorial by Julia Lowndes and Stefanie Butland."
  },
  {
    "objectID": "content/end-acknowledgements.html#partners",
    "href": "content/end-acknowledgements.html#partners",
    "title": "Acknowledgments",
    "section": "Partners",
    "text": "Partners\nScientists from the Alaska Fisheries Science Center conduct these bottom trawl surveys with participation from the Alaska Department of Fish & Game (ADF&G), the International Pacific Halibut Commission (IPHC), and universities. This research is conducted on chartered fishing vessels."
  },
  {
    "objectID": "content/end-acknowledgements.html#collaborators",
    "href": "content/end-acknowledgements.html#collaborators",
    "title": "Acknowledgments",
    "section": "Collaborators",
    "text": "Collaborators\nOur data are used in many annual publications, including but not limited to the list below:\n\nAlaska Stock Assessments\nNorth Pacific Groundfish Stock Assessment and Fishery Evaluation Reports\nGroundfish Economic Status Reports for the Gulf of Alaska and Bering Sea and Aleutian Islands\nAlaska Marine Ecosystem Status Report Database\nSoutheast Alaska Coastal Monitoring Survey Reports\nAlaska Fisheries Life History Database\nEssential Fish Habitat Research Plan in Alaska"
  },
  {
    "objectID": "content/end-refs.html",
    "href": "content/end-refs.html",
    "title": "References",
    "section": "",
    "text": "Alaska Fisheries Information Network (AKFIN). (2024). AFSC goundfish\nassessment program design-based production data. NOAA\nFisheries Alaska Fisheries Science Center, Goundfish Assessment\nProgram; https://akfinbi.psmfc.org/analytics/; U.S. Dep.\nCommer. https://www.psmfc.org/program/alaska-fisheries-information-network-akfin\n\n\nHoff, G. R. (2016). Results of the 2016 eastern Bering\nSea upper continental slope survey of groundfishes and\ninvertebrate resources (NOAA Tech. Memo. NOAA-AFSC-339). U.S.\nDep. Commer. https://doi.org/10.7289/V5/TM-AFSC-339\n\n\nMarkowitz, E. H., Dawson, E. J., Anderson, A. B., Rohan, S. K.,\nCharriere, N. E., Prohaska, B. K., and Stevenson, D. E. (2023).\nResults of the 2022 eastern and northern Bering Sea\ncontinental shelf bottom trawl survey of groundfish and invertebrate\nfauna (NOAA Tech. Memo. NMFS-AFSC-469; p. 213). U.S. Dep.\nCommer.\n\n\nNOAA Fisheries Alaska Fisheries Science Center. (2024). Fisheries\none stop shop public data: RACE division bottom trawl survey data\nquery. https://www.fisheries.noaa.gov/foss; U.S. Dep.\nCommer.\n\n\nNOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment\nProgram. (2024). AFSC goundfish assessment program design-based\nproduction data.\nhttps://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys;\nU.S. Dep. Commer.\n\n\nVon Szalay, P. G., and Raring, N. W. (2018). Data report: 2017 Gulf of Alaska bottom trawl survey (NOAA\nTech. Memo. NMFS-AFSC-374). U.S. Dep. Commer. https://doi.org/10.7289/V5/TM-AFSC-374\n\n\nVon Szalay, P. G., Raring, N. W., Siple, M. C., Dowlin, A. N., Riggle,\nB. C., and Laman, E. A. and. (2023). Data report: 2022\nAleutian Islands bottom trawl survey (AFSC Processed\nRep. No. 2023-07; p. 230). U.S. Dep. Commer. https://doi.org/10.25923/85cy-g225"
  }
]